---
title: "PostgreSQL Commands"
output: 
  html_document: 
    toc: yes
    toc_float: true
---

This document explains the installation and configuration of the PostgreSQL database engine.

# Install PostgreSQL

Install PostgreSQL

    sudo apt install postgresql postgresql-client

Debian wiki explains [how to install and set up
PostgreSQL](https://wiki.debian.org/PostgreSql).


# Create a user and a database

Add system users at the regular bash shell before you can add them in
postgresql. I call this user "rdb" because I plan to use R to connect to the
database and "R" cannot be used as a user name according to system policy.

    sudo adduser rdb --disabled-password 

**Login as the postgres user!**

    sudo -i -u postgres

Now logged in as `postgres@machine_name` in the regular bash shell:

1. Create a user with the same name as the system user created above

    createuser --pwprompt rdb
    # Create a user for myself
    createuser paul 

2. Create a database owned by that user

    createdb -O rdb tradeflows
    createdb -O rdb biotrade
    createdb -O paul tradeflows_migrated

Note: createdb is a wrapper around the SQL command `CREATE DATABASE`.

3. Grant rights to another user. First connect to the database
    
        psql -d biotrade -h localhost -U rdb

    Then grand privileges

        GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA raw_comtrade TO paul;


# Connect to a database

## Configuration file .pgpass

This is the prefered way to connect to the database for scripts. Create a
`~/.pgpass` file to store the connection details for that user:

    echo 'localhost:5432:tradeflows:rdb:localhost' >> ~/.pgpass

Secure the file:

    chmod 600 ~/.pgpass


## Connect to the database 

Using the credentials stored in .pgpass

    psql -d tradeflows -h localhost -U rdb
    psql -d biotrade -h localhost -U rdb


## Connect by changing the user at the system level

Login as the user who is the owner of that database

    sudo -i -u rdb

Connect to the database

    psql tradeflows


# Data types


## Character

[Datatype
character](https://www.postgresql.org/docs/8.4/datatype-character.html):

| Name                             | Description                |
| -------------------------------- | -------------------------- |
| character varying(n), varchar(n) | variable-length with limit |
| character(n), char(n)            | fixed-length, blank padded |
| text                             | variable unlimited length  |

Tip: 

> "There is no performance difference among these three types, apart from
> increased storage space when using the blank-padded type, and a few extra CPU
> cycles to check the length when storing into a length-constrained column.
> While character(n) has performance advantages in some other database systems,
> there is no such advantage in PostgreSQL; in fact character(n) is usually the
> slowest of the three because of its additional storage costs. In most
> situations text or character varying should be used instead." 

[SO answer]'https://stackoverflow.com/a/20334221/2641825)

> "Generally, there is no downside to using text in terms of
> performance/memory. On the contrary: text is the optimum. Other types have
> more or less relevant downsides. text is literally the "preferred" type among
> string types in the Postgres type system, which can affect function or
> operator type resolution."

[differences between text and varchar](https://stackoverflow.com/a/4849030/2641825)
> To sum it all up:
>> - char(n) – takes too much space when dealing with values shorter than n
>>   (pads them to n), and can lead to subtle errors because of adding
>>   trailing spaces, plus it is problematic to change the limit 
>> - varchar(n) – it's problematic to change the limit in live environment
>>   (requires exclusive lock while altering table) 
>> - varchar – just like text
>> - text – for me a winner – over (n) data types because it lacks their
>>    problems, and over varchar – because it has distinct name 


In SQLite as well, character(n) doesn't seem to have any performance advantage.

[SQLite data types](https://www.sqlite.org/datatype3.html)

>  Note that numeric arguments in parentheses that following the type name (ex:
>  "VARCHAR(255)") are ignored by SQLite - SQLite does not impose any length
>  restrictions (other than the large global SQLITE_MAX_LENGTH limit) on the
>  length of strings, BLOBs or numeric values. 


# Drop

Delete a database

    postgres=# drop database databasename;

Delete a schema

    psql -d tradeflows -h localhost -U rdb -c "DROP SCHEMA raw_comext"
    ERROR:  cannot drop schema raw_comext because other objects depend on it
    DETAIL:  table raw_comext.monthly depends on schema raw_comext
    HINT:  Use DROP ... CASCADE to drop the dependent objects too.

Delete a schema and all its table with a drop in cascade

    psql -d tradeflows -h localhost -U rdb -c "DROP SCHEMA raw_comext CASCADE"

Drop a table

    drop table raw_comtrade.yearly;


# Dump

Examples copied from `man pg_dump`. To dump a database called mydb into a SQL-script file:

    $ pg_dump mydb > db.sql

To reload such a script into a (freshly created) database named newdb:

    $ psql -d newdb -f db.sql


## Remove statements

The dump contained the following two statements which I removed:

    SET default_tablespace = '';

    SET default_with_oids = false;

I removed default table space because the official documentation for [table
spaces](https://www.postgresql.org/docs/current/manage-ag-tablespaces.html)
says it doesn't make sense to have more than one table space per system.

I removed default_with_oids because [this
posrt](https://dba.stackexchange.com/questions/101281/what-is-the-relevance-of-set-default-with-oids-true-in-a-postgresql-dump)
explains that it's used to enable a legacy feature.


# Help

Help about psql commands:

   \? 

Help about SQL commands:

    \h
    \h select

# Information

## List schemas, tables, columns

List databases

    \l

Connect to a database

    \c db_name

List schemas

    \dn

List tables

    \dt

List tables for a particular schema i[list all tables in
schema](https://dba.stackexchange.com/questions/40045/how-do-i-list-all-schemas-in-postgresql)

    \dt raw_comext.*;
    \dt raw_comtrade.*;


## Describe data types

Describe a table to see column names and data types

    \d raw_comtrade.yearly;


# Load data into the database

## SQL files

Read commands from a file with the `-f` argument:
    
    psql -d biotrade -h localhost -U rdb -f ~/rp/biotrade/biotrade/config_data/comtrade.sql


# MariaDB/MySQL and PostgreSQL 

## Compare commands

Compare common commands between MariaDB and PostgreSQL.

| MariaDB/MySQL    | PostgreSQL   |
| ---------------  | ------------ |
| show databases;  | \\l          |
| connect db_name; | \\c db_name  |
| show tables;     | \\dt         |
|                  |              |
|                  |              |

## Migrate from MySQL into PostgreSQL

* ipostgresql.org [converting from other databases to
  postgreSQL](https://wiki.postgresql.org/wiki/Converting_from_other_Databases_to_PostgreSQL#MySQL)
* [pgloader](https://github.com/dimitri/pgloader)

Transfer data from MySQL to PostgreSQL:

    pgloader mysql://user@localhost/sakila postgresql:///pagila

For my own database I used:

    sudo su postgres
    createdb -O paul tradeflows_migrated
    exit # Go back to user "paul"
    pgloader mysql://paul@localhost/tradeflows postgresql:///tradeflows_migrated

# Query

## SELECT

Connect to the database (with the credentials defined in `~/.pgpass`)

    psql biotrade

postgresql.org the [WHERE
Clause](https://www.postgresql.org/docs/13/queries-table-expressions.html#QUERIES-WHERE)

Here are some examples of WHERE clauses:

    SELECT ... FROM fdt WHERE c1 > 5

    SELECT ... FROM fdt WHERE c1 IN (1, 2, 3)

    SELECT ... FROM fdt WHERE c1 IN (SELECT c1 FROM t2)

    SELECT ... FROM fdt WHERE c1 IN (SELECT c3 FROM t2 WHERE c2 = fdt.c1 + 10)

    SELECT ... FROM fdt WHERE c1 BETWEEN (SELECT c3 FROM t2 WHERE c2 = fdt.c1 + 10) AND 100

    SELECT ... FROM fdt WHERE EXISTS (SELECT c1 FROM t2 WHERE c2 > fdt.c1)

When using string values, single quotes are required (otherwise the `ERROR:
column "02" does not exist` is returned)

    select distinct(reporter) from raw_comtrade.yearly_hs2 where commodity_code = '02';



# Road map

postgresql.org [Roadmap](https://www.postgresql.org/developer/roadmap/)



# Schemas

Create a schema

    create schema raw_comtrade;

List schemas

    \dn

Official documentation postgresql.org
[schemas](https://www.postgresql.org/docs/current/ddl-schemas.html)

> "A database contains one or more named schemas, which in turn contain tables.
> Schemas also contain other kinds of named objects, including data types,
> functions, and operators. The same object name can be used in different
> schemas without conflict; for example, both schema1 and myschema can contain
> tables named mytable. Unlike databases, schemas are not rigidly separated: a
> user can access objects in any of the schemas in the database they are
> connected to, if they have privileges to do so." 

> "There are several reasons why one might want to use schemas:"

* "To allow many users to use one database without interfering with each
  other."
* "To organize database objects into logical groups to make them more manageable."
* "Third-party applications can be put into separate schemas so they do not collide
  with the names of other objects." 

> "Schemas are analogous to directories at the operating system level, except
> that schemas cannot be nested." 


# Tables
 
List tables for a particular schema:

    \dt raw_comtrade.*;


## Export a table structure 

[Export the create statement for an existing
table](https://stackoverflow.com/questions/2593803/how-to-generate-the-create-table-sql-statement-for-an-existing-table-in-postgr)

    pg_dump -t 'raw_comtrade.yearly_2_digit' --schema-only biotrade  >> /tmp/comtrade_yearly.sql


# Blogs and other resources

Dimitri Fontaine 2014 [Why is pgloader faster
?](https://tapoueh.org/blog/2014/05/why-is-pgloader-so-much-faster/)

> "In searching for a modern programming language the best candidate I found was actually Common Lisp."

> "Not only is Common Lisp code compiled to machine code when using most Common
> Lisp Implementations such as SBCL or Clozure Common Lisp; it’s also possible
> to actually benefit from parallel computing and threads in Common Lisp. In
> the pgloader case I’ve been using the lparallel utilities, in particular its
> queuing facility to be able to implement asynchronous IOs where a thread
> reads the source data and preprocess it, fills up a batch at a time in a
> buffer that is then pushed down to the writer thread, that handles the COPY
> protocol and operations. So my current analysis is that the new thread based
> architecture used with a very powerful compiler for the Common Lisp
> high-level language are allowing pgloader to enter a whole new field of data
> loading performances." 


[Wikipedia](https://en.wikipedia.org/wiki/SQL#Standardization_history)
paragraph on the pronunciation 

> "The original standard declared that the official pronunciation for "SQL" was
> an initialism: /ˌɛsˌkjuːˈɛl/ ("ess cue el"). Regardless, many
> English-speaking database professionals (including Donald Chamberlin
> himself) use the acronym-like pronunciation of /ˈsiːkwəl/ ("sequel"),
> mirroring the language's prerelease development name, "SEQUEL"."
