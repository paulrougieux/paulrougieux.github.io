<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Paul Rougieux" />

<meta name="date" content="2017-08-17" />

<title>Python Commands</title>

<script src="site_libs/header-attrs-2.16/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Paul Rougieux</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-wrench"></span>
     
    Tools
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="bash.html">Bash</a>
    </li>
    <li>
      <a href="communication.html">Communication</a>
    </li>
    <li>
      <a href="debian.html">Debian</a>
    </li>
    <li>
      <a href="docker.html">Docker</a>
    </li>
    <li>
      <a href="git.html">Git</a>
    </li>
    <li>
      <a href="lyx.html">Lyx</a>
    </li>
    <li>
      <a href="mysql.html">MySQL</a>
    </li>
    <li>
      <a href="postgresql.html">PostgreSQL</a>
    </li>
    <li>
      <a href="publish.html">Publish</a>
    </li>
    <li>
      <a href="python.html">Python</a>
    </li>
    <li>
      <a href="R.html">R</a>
    </li>
    <li>
      <a href="vim.html">Vim</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-microchip"></span>
     
    Algos
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="clustering.html">Clustering</a>
    </li>
    <li>
      <a href="musical_scales.html">Musical scales</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-line-chart"></span>
     
    Data
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="explore.html">Explore</a>
    </li>
    <li>
      <a href="datasources.html">Sources</a>
    </li>
  </ul>
</li>
<li>
  <a href="events.html">
    <span class="fa fa-users"></span>
     
    Events
  </a>
</li>
<li>
  <a href="publications.html">
    <span class="fa fa-book"></span>
     
    Publications
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Python Commands</h1>
<h4 class="author">Paul Rougieux</h4>
<h4 class="date">17 August 2017</h4>

</div>


<div id="packages" class="section level1">
<h1>Packages</h1>
<div id="install-with-pip" class="section level2">
<h2>Install with Pip</h2>
<p>pypi.org <a href="https://pypi.org/project/pip/">pip</a>:</p>
<blockquote>
<p>“pip is the package installer for Python. You can use pip to install
packages from the Python Package Index and other indexes.”</p>
</blockquote>
<p>Run at the command line or from an ipython prompt:</p>
<pre><code>pip install packagename</code></pre>
<p><a
href="https://stackoverflow.com/questions/7948494/whats-the-difference-between-a-python-module-and-a-python-package">What
is the difference between a python module and a python package</a></p>
<blockquote>
<p>“A package is a collection of modules in directories that give a
package hierarchy.”</p>
</blockquote>
<p><a
href="https://stackoverflow.com/questions/1471994/what-is-setup-py">What
is setup.py?</a></p>
<div id="install-an-old-version" class="section level3">
<h3>Install an old version</h3>
<p>For example to install pandas 0.24.2</p>
<pre><code>python3 -m pip install --user pandas==0.24.2 </code></pre>
<p>or</p>
<pre><code>pip3 install --user pandas==0.24.2</code></pre>
<p>Sometimes you need to overwrite the existing version with I.</p>
<pre><code>pip install -I  package==version</code></pre>
</div>
<div id="install-a-local-version" class="section level3">
<h3>Install a local version</h3>
<p>To <a href="https://stackoverflow.com/a/18021540/2641825">install the
local version of a package with pip</a></p>
<pre><code>pip install -e /develop/MyPackage</code></pre>
<p>According to <code>man pip</code>, the <code>-e</code> option
“installs a project in editable mode (i.e. setuptools”develop mode”)
from a local project path or a VCS url”.</p>
<div id="uninstall-a-local-version" class="section level4">
<h4>Uninstall a local version</h4>
<p>When uninstalling a package installed locally, you might get this
error message:</p>
<pre><code>uninstall localpackage
# Found existing installation: localpackage 0.0.1
# Can&#39;t uninstall &#39;localpackage&#39;. No files were found to uninstall.</code></pre>
<p>You can show the location of the package with</p>
<pre><code>pip show localpackage</code></pre>
<p>Then remove it manually with</p>
<pre><code>rm -rf ~/.local/lib/python3.9/site-packages/localpackage*</code></pre>
<p>And maybe this as well</p>
<pre><code>rm -rf ~/.local/lib/python3.9/site-packages/build/lib/localpackage*</code></pre>
</div>
</div>
<div id="install-from-a-git-repository" class="section level3">
<h3>Install from a git repository</h3>
<p>Install from the dev branch of a private repo on gitlab using ssh</p>
<pre><code>pip install git+ssh://git@gitlab.com/bioeconomy/forobs/biotrade.git@dev</code></pre>
<p>Install from the dev branch of a private repo on gitlab using an <a
href="https://docs.gitlab.com/ee/user/project/deploy_tokens/index.html">authentication
token</a></p>
<pre><code>pip install git+https://gitlab+deploy-token-833444:ByW1T2bJZRtYhWuGrauY@gitlab.com/bioeconomy/forobs/biotrade.git@dev</code></pre>
</div>
</div>
<div id="install-with-anaconda" class="section level2">
<h2>Install with Anaconda</h2>
<p>Use conda update command to check to see if a new update is
available. If conda tells you an update is available, you can then
choose whether or not to install it.</p>
<div id="install" class="section level3">
<h3>Install</h3>
<p>Documentation conda.io <a
href="https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html#installing-packages">installing
packages</a></p>
<blockquote>
<p>To install a specific package such as SciPy into an existing
environment “myenv”:</p>
</blockquote>
<pre><code>conda install --name myenv scipy</code></pre>
<blockquote>
<p>If you do not specify the environment name, which in this example is
done by –name myenv, the package installs into the current
environment:</p>
</blockquote>
<pre><code>conda install scipy</code></pre>
<blockquote>
<p>To install a specific version of a package such as SciPy:</p>
</blockquote>
<pre><code>conda install scipy=0.15.0</code></pre>
<blockquote>
<p>To install multiple packages at once, such as SciPy and cURL:</p>
</blockquote>
<pre><code>conda install scipy curl</code></pre>
<blockquote>
<p>Note: It is best to install all packages at once, so that all of the
dependencies are installed at the same time.</p>
</blockquote>
</div>
<div id="update" class="section level3">
<h3>Update</h3>
<p>Documentation conda.io <a
href="https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html#updating-packages">updating
packages</a></p>
<blockquote>
<p>Use the terminal or an Anaconda Prompt for the following steps.</p>
</blockquote>
<blockquote>
<p>To update a specific package:</p>
</blockquote>
<pre><code>conda update biopython</code></pre>
<blockquote>
<p>To update Python:</p>
</blockquote>
<pre><code>conda update python</code></pre>
<blockquote>
<p>To update conda itself:</p>
</blockquote>
<pre><code>conda update conda</code></pre>
</div>
<div id="environment-file" class="section level3">
<h3>Environment file</h3>
<p>Creating an environment file manually</p>
<p>You can create an environment file (environment.yml) manually to
share with others.</p>
<p>EXAMPLE: A simple environment file:</p>
<p>name: stats dependencies: - numpy - pandas</p>
<p>EXAMPLE: A more complex environment file:</p>
<p>name: stats2 channels: - javascript dependencies: - python=3.6 # or
2.7 - bokeh=0.9.2 - numpy=1.9.<em> - nodejs=0.10.</em> - flask - pip: -
Flask-Testing</p>
<p>Note</p>
<p>Note the use of the wildcard * when defining the patch version
number. Defining the version number by fixing the major and minor
version numbers while allowing the patch version number to vary allows
us to use our environment file to update our environment to get any bug
fixes whilst still maintaining consistency of software environment.</p>
</div>
</div>
<div id="create-a-package" class="section level2">
<h2>Create a package</h2>
<div id="upload-a-package-to-pypi" class="section level3">
<h3>Upload a package to pypi</h3>
<p>To upload a package to pypi, you need a pypi account. The <a
href="https://packaging.python.org/tutorials/packaging-projects/#uploading-the-distribution-archives">instructions
on uploading distribution archives explain how to upload the package to
pypi</a>:</p>
<pre><code>  python3 -m twine upload --repository testpypi dist/*</code></pre>
</div>
<div id="authorship" class="section level3">
<h3>Authorship</h3>
<p>It’s only possible to specify one author field in setup.py. The
recommendation is to use a mailing list when there are multiple authors
and to set separate files for attribution.</p>
<p><a
href="https://stackoverflow.com/questions/9999829/how-to-specify-multiple-authors-emails-in-setup-py">How
to specify multiple authords in setup.py?</a></p>
</div>
<div id="add-non-code-files" class="section level3">
<h3>Add non code files</h3>
<p>The Python packaging documentation on <a
href="https://python-packaging.readthedocs.io/en/latest/non-code-files.html">adding
non code files</a></p>
<blockquote>
<p>“The mechanism that provides this is the MANIFEST.in file. This is
relatively quite simple: MANIFEST.in is really just a list of relative
file paths specifying files or globs to include.:</p>
</blockquote>
<pre><code>include README.rst
include docs/*.txt
include funniest/data.json</code></pre>
<blockquote>
<p>“In order for these files to be copied at install time to the
package’s folder inside site-packages, you’ll need to supply
include_package_data=True to the setup() function.”</p>
</blockquote>
<blockquote>
<p>“Files which are to be used by your installed library (e.g. data
files to support a particular computation method) should usually be
placed inside of the Python module directory itself. E.g. in our case, a
data file might be at <code>funniest/funniest/data.json</code>. That
way, code which loads those files can easily specify a relative path
from the consuming module’s <code>__file__</code> variable.”</p>
</blockquote>
<p>The Python packaging <a
href="https://packaging.python.org/en/latest/guides/using-manifest-in/">documentation
on the Manifest commands</a> The syntax of recursive-include graft
commands.</p>
<blockquote>
<p>Add all files under directories matching dir-pattern that match any
of the listed patterns</p>
</blockquote>
<pre><code>recursive-include dir-pattern pat1 pat2</code></pre>
<blockquote>
<p>Add all files under directories matching dir-pattern</p>
</blockquote>
<pre><code>graft dir-pattern</code></pre>
<p>The Python packaging documentation on <a
href="https://docs.python.org/3/distutils/sourcedist.html">source
dist</a> gives an example of the patterns</p>
<pre><code>include *.txt
recursive-include examples *.txt *.py
prune examples/sample?/build</code></pre>
<blockquote>
<p>” The meanings should be fairly clear: include all files in the
distribution root matching <code>*.txt</code>, all files anywhere under
the examples directory matching <code>*.txt</code> or <code>*.py</code>,
and exclude all directories matching examples/sample?/build.</p>
</blockquote>
</div>
<div id="version" class="section level3">
<h3>Version</h3>
<p><a
href="https://stackoverflow.com/questions/17583443/what-is-the-correct-way-to-share-package-version-with-setup-py-and-the-package">SO
What is the correct way to share package version with setup.py and the
package?</a></p>
<p>The version of a package has to be set both in <code>setup.py</code>
and <code>__init__py</code> it’s crazy the number of options that people
have thought about. <a
href="https://stackoverflow.com/a/61960231/2641825">This answers</a>
summarizes the state of the art in 7 options, including a link to the <a
href="https://packaging.python.org/en/latest/guides/single-sourcing-package-version/">python
packaging user guide</a></p>
<div id="bump-version" class="section level4">
<h4>Bump version</h4>
<p>Install bumpversion</p>
<pre><code>pip install bumpversion</code></pre>
<p>Increment the version number both in setup.py and
<strong>init</strong>.py with the command line tool bumpversion. First
create a configuration file <code>.bumpversion.cfg</code> where the
<code>current_version</code> matches the versions in
<code>setup.py</code> and <code>packagename/__init__.py</code></p>
<pre><code>[bumpversion]
current_version = 0.0.5
commit = True
tag = True

[bumpversion:file:setup.py]
[bumpversion:file:biotrade/__init__.py]</code></pre>
<p>Increment the version number in all files and the git tag with:</p>
<pre><code>bumpversion patch
# Or to increment minor or major versions
bumpversion minor
bumpversion major</code></pre>
<p>Push the corresponding tags to the remote repository</p>
<pre><code>git push origin --tags</code></pre>
<p>Check the updated version in setup.py</p>
<pre><code>python setup.py --version </code></pre>
<p>Start an ipython prompt to test the package version</p>
<pre><code>ipython
import packagename
packagename.__version__</code></pre>
</div>
</div>
</div>
<div id="location-of-the-python" class="section level2">
<h2>Location of the python</h2>
<p><a
href="https://stackoverflow.com/questions/749711/how-to-get-the-python-exe-location-programmatically">Get
the location of the python executable</a> with</p>
<pre><code>&gt;&gt;&gt; import sys
&gt;&gt;&gt; print(sys.executable)</code></pre>
<p>In virtual env, it can return the symlink to another folder. In that
case, the path can be deduced from</p>
<pre><code>&gt;&gt;&gt; import os
&gt;&gt;&gt; os.__file__</code></pre>
</div>
<div id="virtual-environments" class="section level2">
<h2>Virtual environments</h2>
<p><a href="https://pipenv.pypa.io/en/latest/">Pipenv</a> makes pip and
virtual env work together.</p>
</div>
</div>
<div id="compilers" class="section level1">
<h1>Compilers</h1>
<div id="numba-just-in-time-compiler" class="section level2">
<h2>Numba just-in-time compiler</h2>
<p><a
href="https://numba.readthedocs.io/en/stable/user/5minguide.html">Numba
User Manual</a></p>
<blockquote>
<p>“When a call is made to a Numba-decorated function it is compiled to
machine code “just-in-time” for execution and all or part of your code
can subsequently run at native machine code speed!”</p>
</blockquote>
</div>
<div id="pythran-ahead-of-time-compiler" class="section level2">
<h2>Pythran Ahead of time compiler</h2>
<p><a href="https://github.com/serge-sans-paille/pythran"
class="uri">https://github.com/serge-sans-paille/pythran</a></p>
<blockquote>
<p>“Pythran is an ahead of time compiler for a subset of the Python
language, with a focus on scientific computing. It takes a Python module
annotated with a few interface descriptions and turns it into a native
Python module with the same interface, but (hopefully) faster.”</p>
</blockquote>
</div>
</div>
<div id="control-flow" class="section level1">
<h1>Control flow</h1>
<p>dotnetperls: <a href="https://www.dotnetperls.com/not-python">not
python</a></p>
<p>Sample code with a function and if conditions:</p>
<pre><code>def function(condition):
    if condition:
        print(&quot;Hi&quot;)
    if not condition:
        print(&quot;Bye&quot;)
function(True)
function(False)
function(&#39;&#39;)
function(&#39;lalala&#39;)</code></pre>
</div>
<div id="command-line" class="section level1">
<h1>Command line</h1>
<div id="parsing-arguments-with-argparse" class="section level2">
<h2>Parsing arguments with argparse</h2>
<p><a href="https://docs.python.org/3/howto/argparse.html#">Argparse
Tutorial</a> explain how to create a python program that processes
command line arguments. Save the following in <code>prog.py</code></p>
<pre><code>import argparse
parser = argparse.ArgumentParser()
parser.add_argument(&quot;square&quot;, type=int,
                    help=&quot;display a square of a given number&quot;)
parser.add_argument(&quot;-v&quot;, &quot;--verbosity&quot;, type=int,
                    help=&quot;increase output verbosity&quot;)
args = parser.parse_args()
answer = args.square**2
if args.verbosity == 2:
    print(f&quot;the square of {args.square} equals {answer}&quot;)
elif args.verbosity == 1:
    print(f&quot;{args.square}^2 == {answer}&quot;)
else:
    print(answer)</code></pre>
<p>Usage</p>
<pre><code>$ python3 prog.py 4
16
$ python3 prog.py 4 -v
usage: prog.py [-h] [-v VERBOSITY] square
prog.py: error: argument -v/--verbosity: expected one argument
$ python3 prog.py 4 -v 1
4^2 == 16
$ python3 prog.py 4 -v 2
the square of 4 equals 16
$ python3 prog.py 4 -v 3
16</code></pre>
<p><a href="https://stackoverflow.com/a/42829692/2641825">SO answer</a>
explains that when using <strong>ipython</strong>, you need to separate
ipython arguments from your script arguments using <code>--</code>.</p>
</div>
</div>
<div id="databases" class="section level1">
<h1>Databases</h1>
<div id="sql-alchemy" class="section level2">
<h2>SQL Alchemy</h2>
<p>SQL Alchemy is a database abstraction layer. Interaction with the
database is built upon <a
href="https://docs.sqlalchemy.org/en/14/core/schema.html">metadata
objects</a>:</p>
<blockquote>
<p>The core of SQLAlchemy’s query and object mapping operations are
supported by <strong>database metadata</strong>, which is comprised of
Python objects that describe tables and other schema-level objects.
These objects are at the core of three major types of operations -
issuing CREATE and DROP statements (known as DDL), constructing SQL
queries, and expressing information about structures that already exist
within the database. Database metadata can be expressed by explicitly
naming the various components and their properties, using constructs
such as Table, Column, ForeignKey and Sequence, all of which are
imported from the sqlalchemy.schema package. It can also be generated by
SQLAlchemy using a process called reflection, which means you start with
a single object such as Table, assign it a name, and then instruct
SQLAlchemy to load all the additional information related to that name
from a particular engine source.</p>
</blockquote>
<p><a
href="https://docs.sqlalchemy.org/en/14/core/reflection.html">Reflecting
database objects</a></p>
<pre><code>from sqlalchemy import MetaData
from sqlalchemy import Table
meta = MetaData(schema = &quot;raw_comtrade&quot;)
meta.bind = comtrade.database.engine
yearly_hs2 = Table(&#39;yearly_hs2&#39;, meta, autoload_with=comtrade.database.engine)</code></pre>
<p>SQL Alchemy has an <a
href="https://docs.sqlalchemy.org/en/14/orm/extensions/automap.html">automap</a>
feature which generates mapped classes and relationships from a database
schema.</p>
<p>I used <a
href="https://pypi.org/project/sqlacodegen/">sqlacodegen</a> to
automatically generate python code from an existing PostGreSQl database
table as follows</p>
<pre><code>sqlacodegen --schema raw_comtrade --tables yearly_hs2 postgresql://rdb@localhost/biotrade</code></pre>
<div id="check-for-table-existence" class="section level3">
<h3>Check for table existence</h3>
<p>Paul’s <a href="https://stackoverflow.com/a/69224576/2641825">SO
Answer</a>. SQL Alchemy’s recommended way to check for the presence of a
table is to create an inspector object and use its
<code>has_table()</code> method. The following example was copied from
<a
href="https://docs.sqlalchemy.org/en/14/core/reflection.html#sqlalchemy.engine.reflection.Inspector.has_table">sqlalchemy.engine.reflection.Inspector.has_table</a>,
with the addition of an SQLite engine to make it reproducible:</p>
<pre><code>from sqlalchemy import create_engine, inspect
from sqlalchemy import MetaData, Table, Column, Text
engine = create_engine(&#39;sqlite://&#39;)
meta = MetaData()
meta.bind = engine
user_table = Table(&#39;user&#39;, meta, 
                   Column(&quot;name&quot;, Text),
                   Column(&quot;full_name&quot;, Text))
user_table.create()
inspector = inspect(engine)
inspector.has_table(&#39;user&#39;)</code></pre>
<p>You can also use the <code>user_table</code> metadata element
<code>name</code> to check if it exists as such:</p>
<pre><code>inspector.has_table(user_table.name)</code></pre>
</div>
<div id="orm-querying-guide" class="section level3">
<h3>ORM querying guide</h3>
<div id="select-where" class="section level4">
<h4>Select where</h4>
<p>SQL Alchemy <a
href="https://docs.sqlalchemy.org/en/14/orm/queryguide.html">Object
Relational Model Querying Guide</a></p>
<pre><code>from sqlalchemy import select
stmt = select(user_table).where(user_table.c.name == &#39;spongebob&#39;)
print(stmt)</code></pre>
<p>Since version 1.4 <code>.where()</code> is a synonym of
<code>.filter()</code> as explained in <a
href="https://docs.sqlalchemy.org/en/14/orm/query.html#sqlalchemy.orm.Query.where">sqlalchemy.orm.Query.where</a>.</p>
<p>To select only one column you can use <a
href="https://docs.sqlalchemy.org/en/14/core/selectable.html#sqlalchemy.sql.expression.Select.with_only_columns">Select.with_only_columns</a>:</p>
<pre><code>from sqlalchemy import MetaData, Table, Column, Text
meta = MetaData()
table = Table(&#39;user&#39;, meta, 
              Column(&quot;name&quot;, Text),
              Column(&quot;full_name&quot;, Text))
stmt = (table.select()
        .with_only_columns([table.c.name])
       )
print(stmt)</code></pre>
<p>Entering columns in the <code>select</code> method returns an error.
Although it should be valid according to the documentation.</p>
<pre><code>print(table.select([table.c.name]))
# ArgumentError: SQL expression for WHERE/HAVING role expected, 
# got [Column(&#39;name&#39;, Text(), table=&lt;user&gt;)].</code></pre>
</div>
<div id="insert" class="section level4">
<h4>Insert</h4>
<p><a
href="https://docs.sqlalchemy.org/en/14/core/dml.html#sqlalchemy.sql.expression.insert">Insert</a>
some data into the <code>user</code> table</p>
<pre><code>from sqlalchemy import insert
from sqlalchemy.orm import Session
stmt = (
    insert(user_table).
    values(name=&#39;Bob&#39;, full_name=&#39;Sponge Bob&#39;)
)
with Session(engine) as session:
    result = session.execute(stmt)
    session.commit()</code></pre>
</div>
</div>
<div id="orm-query-to-pandas" class="section level3">
<h3>ORM query to pandas</h3>
<p>The <a
href="https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-sql-method">pandas.to_sql</a>
method uses sqlalchemy to write pandas data frame to a PostgreSQL
database.</p>
<blockquote>
<p>“The pandas.io.sql module provides a collection of query wrappers to
both facilitate data retrieval and to reduce dependency on DB-specific
API. Database abstraction is provided by SQLAlchemy if installed. In
addition you will need a driver library for your database. Examples of
such drivers are psycopg2 for PostgreSQL or pymysql for MySQL. For
SQLite this is included in Python’s standard library by default.”</p>
</blockquote>
<div id="table.select-select-or-a-session" class="section level4">
<h4>table.select(), select() or a session</h4>
<p>Repeat the example table defined above, read the result of a <a
href="https://docs.sqlalchemy.org/en/14/tutorial/data_select.html#the-select-sql-expression-construct">select</a>
statement into a pandas data frame:</p>
<pre><code>import pandas
from sqlalchemy import create_engine
from sqlalchemy import MetaData, Table, Column, Text
from sqlalchemy.orm import Session
# Define metadata and create the table
engine = create_engine(&#39;sqlite://&#39;)
meta = MetaData()
meta.bind = engine
user_table = Table(&#39;user&#39;, meta,
                   Column(&quot;name&quot;, Text),
                   Column(&quot;full_name&quot;, Text))
user_table.create()
# Insert data into the user table
stmt = user_table.insert().values(name=&#39;Bob&#39;, full_name=&#39;Sponge Bob&#39;)
with Session(engine) as session:
    result = session.execute(stmt)
    session.commit()
# Select data into a pandas data frame
stmt = user_table.select().where(user_table.c.name == &#39;Bob&#39;)
df = pandas.read_sql_query(stmt, engine)</code></pre>
<p>Another way importing the select statement:</p>
<pre><code>from sqlalchemy import select
stmt = select(user_table).where(user_table.c.name == &#39;Bob&#39;)
df = pandas.read_sql_query(stmt, engine)</code></pre>
<p>Another way using a session</p>
<pre><code>with Session(engine) as session:
    df2 = pandas.read_sql(session.query(user_table).filter(user_table.name==&quot;Bob&quot;).statement, session.bind)</code></pre>
<p>Read the whole table into pandas</p>
<pre><code>df3 = pandas.read_sql_table(&quot;user&quot;, engine)</code></pre>
<p><a href="https://stackoverflow.com/a/69812326/2641825">Stack Overflow
Answer</a></p>
</div>
<div id="define-and-insert-the-iris-dataset" class="section level4">
<h4>Define and insert the iris dataset</h4>
<p>Define an ORM structure for the iris dataset, then use pandas to
insert the data into an SQLite database. Pandas inserts with
<code>if_exists="append"</code> argument so that it keeps the structure
defined in SQL Alchemy.</p>
<pre><code>import seaborn
import pandas
from sqlalchemy import create_engine
from sqlalchemy import MetaData, Table, Column, Text, Float
from sqlalchemy.orm import Session</code></pre>
<p>Define metadata and create the table</p>
<pre><code>engine = create_engine(&#39;sqlite://&#39;)
meta = MetaData()
meta.bind = engine
iris_table = Table(&#39;iris&#39;,
                   meta,
                   Column(&quot;sepal_length&quot;, Float),
                   Column(&quot;sepal_width&quot;, Float),
                   Column(&quot;petal_length&quot;, Float),
                   Column(&quot;petal_width&quot;, Float),
                   Column(&quot;species&quot;, Text))
iris_table.create()</code></pre>
<p>Load data into the table</p>
<pre><code>iris = seaborn.load_dataset(&quot;iris&quot;)
iris.to_sql(name=&quot;iris&quot;,
            con=engine,
            if_exists=&quot;append&quot;,
            index=False,
            chunksize=10 ** 6,
            )</code></pre>
</div>
<div id="unique-values" class="section level4">
<h4>Unique values</h4>
<p>The SQL ALchemy <code>iris_table</code> from above can be used to
build a select statement that extracts unique values:</p>
<pre><code>from sqlalchemy import distinct, select
stmt = select(distinct(iris_table.c.species))
df = pandas.read_sql_query(stmt, engine)</code></pre>
</div>
</div>
</div>
<div id="postgresql" class="section level2">
<h2>PostgreSQL</h2>
<p>Create a database engin with SQLalchemy</p>
<pre><code>from sqlalchemy import create_engine
engine = create_engine(&#39;postgresql://myusername:mypassword@myhost:5432/mydatabase&#39;)</code></pre>
<p>Blogs and Stackoverflow</p>
<ul>
<li><p><a
href="https://hakibenita.com/fast-load-data-python-postgresql">Load data
into postgreSQL using python</a> (without pandas)</p></li>
<li><p><a
href="https://medium.com/@apoor/quickly-load-csvs-into-postgresql-using-python-and-pandas-9101c274a92f">Load
CSVs into PostgreSQL using python and pandas</a></p></li>
<li><p><a
href="https://stackoverflow.com/questions/413228/pygresql-vs-psycopg2">SO
question pygresql-vs-psycopg2</a></p></li>
<li><p><a
href="https://medium.com/poka-techblog/5-different-ways-to-backup-your-postgresql-database-using-python-3f06cea4f51">5
ways to backup your postgreSQl database using python</a> Mentions the <a
href="https://pypi.org/project/sh/">sh package</a>, a subprocess
replacement.</p></li>
</ul>
</div>
<div id="sqlite" class="section level2">
<h2>SQLite</h2>
<p>Create an SQLITE in memory database and add a table to it.</p>
<pre><code>In [17]: from sqlalchemy import create_engine, inspect
    ...: from sqlalchemy import MetaData, Table, Column, Text
    ...: engine = create_engine(&#39;sqlite://&#39;)
    ...: meta = MetaData()
    ...: meta.bind = engine
    ...: user_table = Table(&#39;user&#39;, meta, Column(&quot;name&quot;, Text))
    ...: user_table.create()
    ...: inspector = inspect(engine)
    ...: inspector.has_table(&#39;user&#39;)
Out[17]: True</code></pre>
<p>Create a file based database at a specific path:</p>
<pre><code># absolute path
e = create_engine(&#39;sqlite:////path/to/database.db&#39;)</code></pre>
</div>
</div>
<div id="editors" class="section level1">
<h1>Editors</h1>
<div id="spyder" class="section level2">
<h2>Spyder</h2>
<p>I have set the following shortcuts to be similar to RStudio:</p>
<ul>
<li>Ctrl+H find and replace dialog</li>
<li>Ctrl+R run selection or current line</li>
<li>Ctrl+Shift+C comment/uncomment code block</li>
<li>F1 inspect current object (i.e. display function and classes
documentation)</li>
<li>F2 go to function definition</li>
</ul>
</div>
<div id="vim" class="section level2">
<h2>Vim</h2>
<p>See my page on <a href="vim.html">vim.html</a>.</p>
</div>
</div>
<div id="neural-networks" class="section level1">
<h1>Neural Networks</h1>
<div id="pytorch" class="section level2">
<h2>Pytorch</h2>
<p>Print the size of the output layer</p>
<pre><code>import torch
import torch.nn as nn
x = torch.randn(28,28).view(-1,1,28,28)
model = nn.Sequential(
      nn.Conv2d(1, 32, (3, 3)),
      nn.ReLU(),
      nn.MaxPool2d((2, 2)),
      nn.Conv2d(32, 64, (3, 3)),
)
print(model(x).shape)</code></pre>
</div>
</div>
<div id="objects" class="section level1">
<h1>Objects</h1>
<div id="object-types" class="section level2">
<h2>Object types</h2>
<p><code>type()</code> displays the type of an object.</p>
<pre><code>i = 1
print(type(i))
# &lt;type &#39;int&#39;&gt;
x = 1.2
print(type(x))
# &lt;type &#39;float&#39;&gt;
t = (1,2)
print(type(t))
# &lt;type &#39;tuple&#39;&gt;
l = [1,2]
print(type(l))
# &lt;type &#39;list&#39;&gt;</code></pre>
<div id="check-object-types" class="section level3">
<h3>Check object types</h3>
<p>Check if a variable is a string, int or float</p>
<pre><code>isinstance(&quot;a&quot;, str)
isinstance(1,  int)
isinstance(1.2, float)</code></pre>
</div>
<div id="convert-between-object-types" class="section level3">
<h3>Convert between object types</h3>
<p>Character to numeric</p>
<pre><code>int(&quot;3&quot;)
float(&quot;3.33&quot;)
int(&quot;3.33&quot;)</code></pre>
<p>Numeric to character</p>
<pre><code>str(2)</code></pre>
<p>Convert a list to a comma separated string</p>
<pre><code>&quot;,&quot;.join([&quot;a&quot;,&quot;b&quot;,&quot;c&quot;])</code></pre>
<p>Another example with the list of the last 5 years</p>
<pre><code>import datetime
year = datetime.datetime.today().year
# Create a numeric list of years
YEARS = [year - i for i in range(1,6)]
# Convert each element of the list to a string
YEARS = [str(x) for x in YEARS]
&quot;,&quot;.join(YEARS)</code></pre>
</div>
<div id="dictionary" class="section level3">
<h3>Dictionary</h3>
<p>Create a dictionary with curly braces</p>
<pre><code>ceci = {&#39;x&#39;:1, &#39;y&#39;:2, &#39;z&#39;:3}</code></pre>
<p>Converts 2 lists into a dictionary with the <code>dict</code> built
in function</p>
<pre><code>dict(zip([&#39;x&#39;, &#39;y&#39;, &#39;z&#39;], [1, 2, 3]))</code></pre>
<p>Dictionary comprehension</p>
<pre><code>d = {n: True for n in range(5)}</code></pre>
<p>Loop over the key and values of a dictionary</p>
<pre><code>for key, value in ceci.items():
    print(key, &quot;has the value&quot;, value)</code></pre>
</div>
<div id="iterator" class="section level3">
<h3>Iterator</h3>
<p>The <code>map</code> function makes an iterator object of type
<code>map</code></p>
<pre><code>iter = map(lambda x:x+1,range(3))
type(iter)
[i for i in iter]</code></pre>
</div>
<div id="list" class="section level3">
<h3>List</h3>
<p><a href="https://stackoverflow.com/a/31077838/2641825">Remove an
element from a list of strings</a></p>
<pre><code>myList = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]
myList.remove(&#39;c&#39;)
myList
[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;]</code></pre>
<p>Create a list of strings using split (seen in <a
href="https://stackoverflow.com/a/52110266/2641825">this answer</a>)</p>
<pre><code>&quot;slope, intercept, r_value, p_value, std_err&quot;.split(&quot;, &quot;)</code></pre>
<div id="list-of-tuples" class="section level4">
<h4>List of tuples</h4>
<p><a
href="https://stackoverflow.com/questions/10632839/transform-list-of-tuples-into-a-flat-list-or-a-matrix">How
to flatten a list of tuples</a></p>
<pre><code>nested_list = [(1, 2, 4), (0, 9)]</code></pre>
<p>Using <code>reduce</code>:</p>
<pre><code>reduce(lambda x,y:x+y, map(list, nested_list))                                                                                                                              
[1, 2, 4, 0, 9]</code></pre>
<p>Using itertools.chain:</p>
<pre><code>import itertools
list(itertools.chain.from_iterable(nested_list))</code></pre>
<p>Using <code>extend</code>:</p>
<pre><code>flat_list = []
for a_tuple in nested_list:
    flat_list.extend(list(a_tuple))                                                                                                                                     
flat_list
[1, 2, 4, 0, 9]</code></pre>
</div>
</div>
<div id="set" class="section level3">
<h3>Set</h3>
<p>Instances of <a
href="https://docs.python.org/3/library/stdtypes.html#set">set</a>
provide the following operations:</p>
<pre><code>issubset(other)
set &lt;= other

    Test whether every element in the set is in other.</code></pre>
<p>For example <a href="https://stackoverflow.com/a/3931655/2641825">SO
answer using issubset</a></p>
<pre><code>l = [1,2,3]
m = [1,2]
set(m).issubset(l)
# True

set &lt; other

    Test whether the set is a proper subset of other, that is, set &lt;= other and set != other.

issuperset(other)
set &gt;= other

    Test whether every element in other is in the set.

set &gt; other

    Test whether the set is a proper superset of other, that is, set &gt;= other and set != other.

union(*others)
set | other | ...

    Return a new set with elements from the set and all others.</code></pre>
<p>Note the following perform a union:</p>
<pre><code>set(range(3,10)).union(set(range(5)))
set(range(3,10)) | set(range(5))</code></pre>
<p>But this is not a union:</p>
<pre><code>set(range(3,10)) or set(range(5))

intersection(*others)
set &amp; other &amp; ...

    Return a new set with elements common to the set and all others.

difference(*others)
set - other - ...

    Return a new set with elements in the set that are not in the others.

symmetric_difference(other)
set ^ other

    Return a new set with elements in either the set or other but not both.</code></pre>
</div>
</div>
<div id="programming-objects" class="section level2">
<h2>Programming objects</h2>
<div id="inheritance-and-composition" class="section level3">
<h3>Inheritance and composition</h3>
<p>Below is an example of object inheritance where a Car and a Boat
classes inherit from a Vehicle class.</p>
<pre><code>class Vehicle(object):

    def __init__(self, color, speed_max, garage=None):
        self.color = color
        self.speed_max = speed_max
        self.garage = garage

    def paint(self, new_color):
        self.color = new_color

    def go_back_home(self, new_color):
        self.position = self.go_to(self.parent.location)

class Car(Vehicle):

    def open_door(self):
        pass

class Boat(Vehicle):

    def open_balast(self):
        pass

honda = Car(&#39;bleu&#39;, 60)
gorgeoote = Boat(&#39;rouge&#39;, 30)
honda.paint(&#39;purple&#39;)</code></pre>
<p>Note that the object should be able to access it’s parent properties
through the super() method.</p>
<p>Below an example of object composition where the Garage class is
parent to many Vehicle objects.</p>
<pre><code>class Garage(object):

    def __init__(self, all_vehicles):
        self.all_vehicles = all_vehicles

    def mass_paint(self, new_color):
        for v in self.all_vehicles: v.paint(new_color)

    def build_car(self, color):
        new_car = Car(color, 90, self)
        self.all_vehicles.append(new_car)
        return new_car

    @property
    def location(self):
        return &#39;10, 18&#39;


mike = Garage([honda, gorgeoote])

mike.mass_paint()

sport_car = mike.build_car(&#39;rouge&#39;)</code></pre>
</div>
<div id="why-do-python-classes-inherit-object" class="section level3">
<h3>Why do Python classes inherit object?</h3>
<p><a
href="https://stackoverflow.com/questions/4015417/why-do-python-classes-inherit-object">Why
do Python classes inherit object?</a></p>
<blockquote>
<p>So, what should you do?</p>
</blockquote>
<blockquote>
<p>In Python 2: always inherit from object explicitly. Get the
perks.</p>
</blockquote>
<blockquote>
<p>In Python 3: inherit from object if you are writing code that tries
to be Python agnostic, that is, it needs to work both in Python 2 and in
Python 3. Otherwise don’t, it really makes no difference since Python
inserts it for you behind the scenes.</p>
</blockquote>
</div>
</div>
</div>
<div id="http" class="section level1">
<h1>HTTP</h1>
<div id="file-download" class="section level2">
<h2>File download</h2>
<div id="zipped-csv-files" class="section level3">
<h3>Zipped csv files</h3>
<p>The following example uses urllib.request.urlopen to download a zip
file containing Oceania’s crop production data from the FAO statistical
database. In that example, it is necessary to define a minimal header,
otherwise FAOSTAT throws an <code>Error 403: Forbidden</code>. It was
posted as a <a
href="https://stackoverflow.com/a/68804963/2641825">StackOverflow
Answer</a>.</p>
<pre><code>import shutil
import urllib.request
import tempfile

# Create a request object with URL and headers    
url = &quot;http://fenixservices.fao.org/faostat/static/bulkdownloads/Production_Crops_Livestock_E_Oceania.zip&quot;
header = {&#39;User-Agent&#39;: &#39;Mozilla/5.0 (X11; Linux x86_64) &#39;}
req = urllib.request.Request(url=url, headers=header)

# Define the destination file
dest_file = tempfile.gettempdir() + &#39;/&#39; + &#39;crop.zip&#39;
print(f&quot;File located at:{dest_file}&quot;)

# Create an http response object
with urllib.request.urlopen(req) as response:
    # Create a file object
    with open(dest_file, &quot;wb&quot;) as f:
        # Copy the binary content of the response to the file
        shutil.copyfileobj(response, f)</code></pre>
<p>Based on <a href="https://stackoverflow.com/a/48691447/2641825"
class="uri">https://stackoverflow.com/a/48691447/2641825</a> and <a
href="https://stackoverflow.com/a/66591873/2641825"
class="uri">https://stackoverflow.com/a/66591873/2641825</a>, see also
the documentation at <a
href="https://docs.python.org/3/howto/urllib2.html"
class="uri">https://docs.python.org/3/howto/urllib2.html</a></p>
</div>
<div id="json-files" class="section level3">
<h3>JSON files</h3>
<p>The following loads a JSON file into a pandas data frame from the
Comtrade API.</p>
<pre><code>import urllib.request
import json
import pandas

url_reporter = &quot;https://comtrade.un.org/Data/cache/reporterAreas.json&quot;
url_partner = &quot;https://comtrade.un.org/Data/cache/partnerAreas.json&quot;

# attempt with pandas.io, with an issue related to nested json
pandas.io.json.read_json(url_reporter, encoding=&#39;utf-8-sig&#39;)
pandas.io.json.read_json(url_partner)
# `results` is a character column containing {&#39;id&#39;: &#39;4&#39;, &#39;text&#39;: &#39;Afghanistan&#39;}.
# Is there a way to tell read_json to load the id and text columns directly instead?</code></pre>
<p><a href="https://stackoverflow.com/a/68988284/2641825">SO
answer</a></p>
<blockquote>
<p>“Since the whole processing is done in the pd.io.json.read_json
method, we cannot select the keys to direct to the actual data that we
are after. So you need to run this additional code to get your desired
results:”</p>
</blockquote>
<pre><code>df = pandas.io.json.read_json(url_reporter, encoding=&#39;utf-8-sig&#39;)
df2 = pandas.json_normalize(df.results.to_list())</code></pre>
<p>Other attempt using lower level packages</p>
<pre><code>req = urllib.request.Request(url=url_reporter)
with urllib.request.urlopen(req) as response:
    json_content = json.load(response)
    df = pandas.json_normalize(json_content[&#39;results&#39;])

In [17]: df
Out[17]:
      id                    text
0    all                     All
1      4             Afghanistan
2      8                 Albania
3     12                 Algeria
4     20                 Andorra
..   ...                     ...
252  876  Wallis and Futuna Isds
253  887                   Yemen
254  894                  Zambia
255  716                Zimbabwe
256  975                   ASEAN</code></pre>
<ul>
<li><p>Related question I asked on SO.: <a
href="https://stackoverflow.com/questions/68985729/how-to-load-a-nested-data-frame-with-pandas-io-json-read-json">How
to load a nested data frame with pandas.io.json.read_json?</a></p></li>
<li><p>Enconding issue <a
href="https://stackoverflow.com/questions/57152985/what-is-the-difference-between-utf-8-and-utf-8-sig">What
is the difference between utf-8 and utf-8-sig?</a></p></li>
<li><p><a
href="https://stackoverflow.com/questions/2223882/whats-the-difference-between-utf-8-and-utf-8-without-bom">What’s
the difference between UTF-8 and UTF-8 without BOM?</a></p></li>
</ul>
</div>
</div>
</div>
<div id="ipython" class="section level1">
<h1>ipython</h1>
<p>Add these options at the ipyhton command line to reload objects
automatically while you are coding</p>
<pre><code>%load_ext autoreload   
%autoreload 2         </code></pre>
<div id="debugging-in-ipython" class="section level2">
<h2>Debugging in ipython</h2>
<p>Once an error occurs at the ipython command line. Press
<code>debug</code> then you can move up the stack trace with:</p>
<pre><code>`u`</code></pre>
<p>Move down the stack trace with:</p>
<pre><code>`d` </code></pre>
<p>Show code context of the error:</p>
<pre><code>`l` </code></pre>
<p>Show available variable in the current context:</p>
<pre><code>`a` </code></pre>
</div>
<div id="breakpoint" class="section level2">
<h2>Breakpoint</h2>
<p>To break at every step in a loop, use the <code>breakpoint()</code>
function in any part of the code as explained in <a
href="https://stackoverflow.com/questions/16867347/step-by-step-debugging-with-ipython">setp
by step debuging with ipython</a>.</p>
<pre><code>continue</code></pre>
</div>
<div id="running-from-ipython" class="section level2">
<h2>Running from ipython</h2>
<p>Run a file from the ipython console</p>
<pre><code>%run -i test.py.</code></pre>
<p><a href="https://github.com/ipython/ipython/issues/1001"
class="uri">https://github.com/ipython/ipython/issues/1001</a></p>
</div>
</div>
<div id="jupyter-notebooks-and-lab" class="section level1">
<h1>Jupyter notebooks and lab</h1>
<div id="call-bash-from-a-notebook" class="section level2">
<h2>Call bash from a notebook</h2>
<p>Prefix the bash call with an exclamation mark, for example:</p>
<pre><code>!df -h</code></pre>
<p>In fact the question mark also works from an ipython shell. See also
<a
href="https://stackoverflow.com/questions/45784499/difference-between-and-in-jupyter-notebooks">Difference
between ! and % in Jupyter Notebooks</a></p>
</div>
<div id="convert-and-execute-notebooks-programmatically"
class="section level2">
<h2>Convert and execute notebooks programmatically</h2>
<div id="at-the-shell" class="section level3">
<h3>At the shell</h3>
<p>To work from the ipython command line it’s useful to load execute the
whole notebook inside the ipython shell with</p>
<pre><code>ipython -c &quot;%run notebook.ipynb&quot;</code></pre>
<p>It’s also possible to convert the long notebooks to a python script
with:</p>
<pre><code>jupyter nbconvert --to script notebook.ipynb</code></pre>
<p>Then run the whole notebook and start an interactive shell with:</p>
<pre><code>ipython -i notebook.py</code></pre>
<p>Otherwise I also sometimes open the synchronized markdown version of
the notebook and execute a few cells using Vim slime to sent them to a
tmux pane where ipython is running.</p>
</div>
<div id="convert-notebooks-to-html" class="section level3">
<h3>Convert notebooks to html</h3>
<p>Notebooks can be converted from the File / Save and Export Notebook
As / HTML menu. Or <a
href="https://nbconvert.readthedocs.io/en/latest/usage.html#convert-html">at
the command line with nbconvert</a></p>
<pre><code>jupyter nbconvert --to html notebook.ipynb</code></pre>
</div>
<div id="from-python" class="section level3">
<h3>From python</h3>
<p>Run an ipython notebook from python using <a
href="https://nbconvert.readthedocs.io/en/latest/execute_api.html#example">nbconver</a>’s
execute API:</p>
<pre><code>import nbformat
from nbconvert.preprocessors import ExecutePreprocessor
import jupytext

####################
# Run one notebook #
####################
filename = &#39;notebook.ipynb&#39;
with open(filename) as ff:
    nb_in = nbformat.read(ff, nbformat.NO_CONVERT)

# Read a notebook from the markdown file synchronized by jupytext
nb_md = jupytext.read(&#39;notebook.md&#39;)

# Run the notebook
ep = ExecutePreprocessor(timeout=600, kernel_name=&#39;python3&#39;)
nb_out = ep.preprocess(nb_in)

# Save the output notebook
with open(filename, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f:
    nbformat.write(nb_out, f)</code></pre>
<p>Saving fails in my case.</p>
</div>
</div>
<div id="dashboards-and-widgets" class="section level2">
<h2>Dashboards and widgets</h2>
<ul>
<li><p><a href="https://github.com/voila-dashboards/voila">Voila
dashboard</a></p>
<ul>
<li>Examples dasboards and applications in the <a
href="https://voila-gallery.org/">Voilà gallery</a></li>
</ul></li>
<li><p><a
href="https://github.com/jupyter-widgets/ipywidgets">ipywidgets</a></p>
<blockquote>
<p>“interactive HTML widgets for Jupyter notebooks and the IPython
kernel.”</p>
</blockquote></li>
</ul>
<div id="interactive-widgets" class="section level3">
<h3>Interactive widgets</h3>
<p><a
href="https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html">Documentation
of interactive widgets</a></p>
<p>Create a text box</p>
<pre><code>def print_name(name):
    return(&quot;Name: &quot; + name)
interact(print_name, name=&quot;Paul&quot;)</code></pre>
<p>Create a drop down list for an interactive plot</p>
<pre><code>import matplotlib.pyplot as plt
import seaborn
from ipywidgets import interact
iris = seaborn.load_dataset(&quot;iris&quot;).set_index(&quot;species&quot;)

def plot_iris(species):
    &quot;&quot;&quot;Plot the given species&quot;&quot;&quot;
    df = iris.loc[species]
    ax = df.plot.scatter(x=&#39;petal_length&#39;, y=&#39;petal_width&#39;, title=species)
    ax.set_xlim(0,8)
    ax.set_ylim(0,4)

interact(plot_iris, species=list(iris.index.unique()))</code></pre>
<p>Use the <code>@interact</code> decorator</p>
<pre><code>@interact(species=list(iris.index.unique()))
def plot_iris(species):
    &quot;&quot;&quot;Plot the given species&quot;&quot;&quot;
    df = iris.loc[species]
    ax = df.plot.scatter(x=&#39;petal_length&#39;, y=&#39;petal_width&#39;, title=species)
    ax.set_xlim(0,8)
    ax.set_ylim(0,4)</code></pre>
</div>
</div>
<div id="display-all-rows-and-columns-of-a-data-frame"
class="section level2">
<h2>Display all rows and columns of a data frame</h2>
<p>Display all columns</p>
<pre><code>pandas.options.display.max_columns = None</code></pre>
<p>Display max rows</p>
<pre><code>pandas.set_option(&#39;display.max_rows&#39;, 500)</code></pre>
<p>With a context manager <a
href="https://stackoverflow.com/a/47113685/2641825">as in this
answer</a></p>
<pre><code>with pd.option_context(&#39;display.max_rows&#39;, 100, &#39;display.max_columns&#39;, 10):
some pandas stuff</code></pre>
</div>
<div id="docker-stacks" class="section level2">
<h2>Docker stacks</h2>
<p><a
href="https://jupyter-docker-stacks.readthedocs.io/en/latest/">Docker
stacks for Jupyter notebooks</a></p>
<p><a
href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#core-stacks">Selecting
an image</a></p>
</div>
<div id="download-data-from-a-jupyter-notebook" class="section level2">
<h2>Download data from a jupyter notebook</h2>
<p>I wrote this csv download function in an <a
href="https://stackoverflow.com/a/57613621/2641825">SO answer</a></p>
<pre><code>def csv_download_link(df, csv_file_name, delete_prompt=True):
    &quot;&quot;&quot;Display a download link to load a data frame as csv from within a Jupyter notebook&quot;&quot;&quot;
    df.to_csv(csv_file_name, index=False)
    from IPython.display import FileLink
    display(FileLink(csv_file_name))
    if delete_prompt:
        a = input(&#39;Press enter to delete the file after you have downloaded it.&#39;)
        import os
        os.remove(csv_file_name)</code></pre>
<p>To get a link to a csv file, enter the above function and the code
below in a jupyter notebook cell :</p>
<pre><code>csv_download_link(df, &#39;df.csv&#39;)</code></pre>
</div>
<div id="documentation-with-jupyter" class="section level2">
<h2>Documentation with Jupyter</h2>
<p><a
href="https://hub.packtpub.com/using-jupyter-write-documentation/">Using
jupyter to write documentation</a></p>
</div>
<div id="help-in-a-jupyter-notebook" class="section level2">
<h2>Help in a jupyter notebook</h2>
<p>To get help on a function, enter <code>function_name?</code> in a
cell. Quick hep can also be obtained by pressing SHIFT + TAB.</p>
</div>
<div id="install-jupyter" class="section level2">
<h2>Install Jupyter</h2>
<p>To <a href="https://jupyter.org/install">install Jupyter</a>
notebooks on python3:</p>
<pre><code>pip3 install jupyter notebook</code></pre>
<p>Then start the notebook server as such:</p>
<pre><code>jupyter notebook</code></pre>
</div>
<div id="plots-in-notebooks" class="section level2">
<h2>Plots in notebooks</h2>
<p>It is <a
href="https://stackoverflow.com/a/24884342/2641825">sometimes necessary
to add the following</a> at the beginning of a jupyter notebook so that
plots are displayed inline</p>
<pre><code>%matplotlib inline</code></pre>
<p>Change the size of a plot displayed in a notebook</p>
<pre><code>import seaborn
p = seaborn.lineplot(x=&quot;year&quot;, y=&quot;value&quot;, hue=&quot;source&quot;, data=df1)
p.figure.set_figwidth(15)</code></pre>
</div>
<div id="security-and-authentication-on-a-public-server"
class="section level2">
<h2>Security and authentication on a public server</h2>
<p><a
href="https://stackoverflow.com/questions/37808410/ipython-jupyter-notebook-with-authentication">Jupyter
notebook with authentication</a></p>
</div>
<div id="toc-table-of-content-in-your-notebooks" class="section level2">
<h2>TOC Table of content in your notebooks</h2>
<p>Install <a
href="https://github.com/ipython-contrib/jupyter_contrib_nbextensions">jupyter_contrib_nbextensions</a></p>
<pre><code>python3 -m pip install --user jupyter_contrib_nbextensions
python3 -m jupyter contrib nbextension install --user</code></pre>
<p>Activate the table of content extension:</p>
<pre><code>python3 -m jupyter nbextension enable toc2/main</code></pre>
<p>There are many other extensions available in this package.
<strong>Optionally</strong> you can install the jupyter notebook
extension configurator (not needed)</p>
<pre><code>python3 -m pip install --user jupyter_nbextensions_configurator
jupyter nbextensions_configurator enable --user</code></pre>
<p>This will make a configuration interface available at:</p>
<pre><code>http://localhost:8888/nbextensions</code></pre>
<p>Using the old Table of Content extension <a
href="https://github.com/minrk/ipython_extensions#table-of-contents">jupyter
table of content extension</a></p>
<pre><code>jupyter nbconvert --to markdown mynotebook.ipynb
jupyter nbconvert --to html mynotebook.ipynb</code></pre>
<p>For a colleague using Anaconda <a
href="https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html">Installing
jupyter_contrib_nbextensions</a> specifies that</p>
<blockquote>
<p>“There are conda packages for the notebook extensions and the
jupyter_nbextensions_configurator available from conda-forge. You can
install both using”</p>
</blockquote>
<pre><code>conda install -c conda-forge jupyter_contrib_nbextensions</code></pre>
</div>
<div id="jupyter-and-git-version-control" class="section level2">
<h2>Jupyter and git version control</h2>
<div id="jupytext-with-markdown-and-git" class="section level3">
<h3>Jupytext with markdown and git</h3>
<p>Convert notebooks to markdown so they are easier to track in git.</p>
<p>Install <a href="https://github.com/mwouts/jupytext"
class="uri">https://github.com/mwouts/jupytext</a></p>
<pre><code>python3 -m pip install --user jupytext</code></pre>
<p>More commands:</p>
<pre><code>python3 -m jupyter notebook --generate-config
vim ~/.jupyter/jupyter_notebook_config.py</code></pre>
<p>Add this line:</p>
<pre><code>c.NotebookApp.contents_manager_class = &quot;jupytext.TextFileContentsManager&quot;</code></pre>
<p>And also this line if you always want to pair notebooks with their
markdown counterparts:</p>
<pre><code>c.ContentsManager.default_jupytext_formats = &quot;ipynb,md&quot;</code></pre>
<p>More commands:</p>
<pre><code>python3 -m jupyter nbextension install jupytext --py --user
python3 -m jupyter nbextension enable  jupytext --py --user</code></pre>
<p>Add syncing to a given notebook:</p>
<pre><code># Markdown sync
jupytext --set-formats ipynb,md --sync ~/repos/example_repos/notebooks/test.ipynb
# Python sync
jupytext --set-formats ipynb,py --sync ~/repos/example_repos/notebooks/test.ipynb</code></pre>
</div>
<div id="remove-jupyter-notebook-output-when-using-git"
class="section level3">
<h3>Remove jupyter notebook output when using git</h3>
<p>Alternative to the above, this post explains <a
href="https://janakiev.com/blog/jupyter-git-remove-output/">how to
remove Jupyter notebook output from terminal and when using git</a>.</p>
</div>
</div>
</div>
<div id="errors-exceptions-and-logging" class="section level1">
<h1>Errors, exceptions and logging</h1>
<div id="handling-exceptions-with-try-and-except-statements"
class="section level2">
<h2>Handling Exceptions with try and except statements</h2>
<p>Python documentation on <a
href="https://docs.python.org/3/tutorial/errors.html#handling-exceptions">Handling
Exceptions</a>.</p>
<pre><code>while True:
    try:
        x = int(input(&quot;Please enter a number: &quot;))
        break
    except ValueError:
        print(&quot;Oops!  That was no valid number.  Try again...&quot;)</code></pre>
<p><a href="https://stackoverflow.com/a/4690655/2641825">Exception
message capturing</a></p>
<pre><code>for i in [1,0]:
    try:
        print(1/i)
    except Exception as e:
        print(&quot;Failed to compute:&quot;, str(e))</code></pre>
<p>Handle empty data in pandas</p>
<pre><code>from pandas.errors import EmptyDataError
try:
    df = gfpmx_data[s]
    columns = df.columns
except EmptyDataError:
    print(f&quot;no data in file {s}&quot;)
    columns = []</code></pre>
</div>
<div id="raising-exceptions" class="section level2">
<h2>Raising Exceptions</h2>
<p>Python documentation on <a
href="https://docs.python.org/3/tutorial/errors.html#raising-exceptions">Raising
Exceptions</a></p>
<pre><code>raise Exception(&#39;spam&#39;)
raise ValueError(&#39;Not an acceptable value&#39;)
raise NameError(&quot;Wrong name: %s&quot; % &quot;quack quack quack&quot;)</code></pre>
<p>Display variables in the error message:</p>
<pre><code>raise ValueError(&quot;This is wrong: %s&quot; % &quot;wrong_value&quot;)
msg = &quot;Value %s and value %s have problems.&quot;
raise ValueError(msg % (1, 2))</code></pre>
</div>
<div id="warnings" class="section level2">
<h2>Warnings</h2>
<p>Send a warning to the user</p>
<pre><code>import warnings
warnings.warn(&quot;there is no data&quot;)</code></pre>
</div>
<div id="logging" class="section level2">
<h2>Logging</h2>
<p>docs.python.org <a
href="https://docs.python.org/3/howto/logging-cookbook.html">logging
cookbook</a></p>
<p>Pylint error: Use lazy % formatting in logging functions</p>
<p><a href="https://stackoverflow.com/a/52012660/2641825">Answer to Lazy
evaluation of strings in python logging: comparing <code>%</code> with
<code>.format</code></a></p>
<p>The documentation <a
href="https://docs.python.org/2/library/logging.html"
class="uri">https://docs.python.org/2/library/logging.html</a> suggest
the following for lazy evaluation of string interpolation:</p>
<pre><code>logging.getLogger().debug(&#39;test: %i&#39;, 42)</code></pre>
</div>
</div>
<div id="functions" class="section level1">
<h1>Functions</h1>
<p>Functions in python can be defined with</p>
<pre><code>def add_one(x):
    return x + 1
add_one(1)

# 2</code></pre>
<div id="annotations" class="section level2">
<h2>Annotations</h2>
<p><a href="https://peps.python.org/pep-3107/">PEP 3107</a></p>
<blockquote>
<p>Annotations for parameters take the form of optional expressions that
follow the parameter name:</p>
</blockquote>
<pre><code>def foo(a: expression, b: expression = 5):
    ...</code></pre>
<blockquote>
<p>to annotate the type of a function’s return value. This is done like
so:</p>
</blockquote>
<pre><code>def sum() -&gt; expression:
    ...</code></pre>
<p><a href="https://stackoverflow.com/a/15073109/2641825">SO
example</a></p>
<pre><code>def kinetic_energy(m:&#39;in KG&#39;, v:&#39;in M/S&#39;)-&gt;&#39;Joules&#39;:
return 1/2_m_v**2

kinetic_energy.__annotations__
{&#39;m&#39;: &#39;in KG&#39;, &#39;v&#39;: &#39;in M/S&#39;, &#39;return&#39;: &#39;Joules&#39;}</code></pre>
<p>The pandas code base doesn’t use it everywhere, there are functions
that use the standard sphinx type of documentation <a
href="https://github.com/pandas-dev/pandas/blob/a2029ce7bdd640931cb2c19e8a2c2c5a258fa5f9/pandas/core/arrays/timedeltas.py#L1094">timedeltas.py#L1094</a>.
I have the impression that the annotation are used for the package
internal functions, while the sphinx documentation is used for the
functions that are exposed to the outside users. And in the same script,
they use both sphinx documentation and type annotations <a
href="https://github.com/pandas-dev/pandas/blob/a2029ce7bdd640931cb2c19e8a2c2c5a258fa5f9/pandas/core/arrays/timedeltas.py#L952">timedeltas.py#L952</a>.</p>
<p><a
href="https://www.blog.pythonlibrary.org/2020/04/15/type-checking-in-python/">Type
checking in python</a></p>
<blockquote>
<p>There are several things to know about up front when it comes to type
hinting in Python. Let’s look at the pros of type hinting first:</p>
<ul>
<li>Type hints are nice way to document your code in addition to
docstrings</li>
<li>Type hints can make IDEs and linters give better feedback and better
autocomplete</li>
<li>Adding type hints forces you to think about types, which may help
you make good decisions during the design of your applications.</li>
</ul>
<p>Adding type hinting isn’t all rainbows and roses though. There are
some downsides:</p>
<ul>
<li>The code is more verbose and arguably harder to write</li>
<li>Type hinting adds development time</li>
<li>Type hints only work in Python 3.5+. Before that, you had to use
type comments</li>
<li>Type hinting can have a minor start up time penalty in code that
uses it, especially if you import the typing module.</li>
</ul>
</blockquote>
</div>
<div id="call-by-reference-or-call-by-value" class="section level2">
<h2>Call by reference or call by value</h2>
<p>When using numpy arrays, python displays a behaviour of call by
reference</p>
<pre><code>a = np.array([1,2])

def changeinput(x, scalar):
    x[0] = scalar

changeinput(a,3)

a
# array([3, 2])</code></pre>
<p>This is really weird coming from R, which has a copy-on-modify
principle.</p>
<p>The R Language Definition says this (in section 4.3.3 Argument
Evaluation)</p>
<blockquote>
<p>“The semantics of invoking a function in R argument are
call-by-value. In general, supplied arguments behave as if they are
local variables initialized with the value supplied and the name of the
corresponding formal argument. Changing the value of a supplied argument
within a function will not affect the value of the variable in the
calling frame. [Emphasis added]”</p>
</blockquote>
</div>
<div id="decorators" class="section level2">
<h2>Decorators</h2>
<p>Decorators are a way to wrap a function around another function. It
is useful to repeat a pattern of behaviour around a function.</p>
<ul>
<li>Data camp <a
href="https://www.datacamp.com/community/tutorials/decorators-python">course
on decorators</a></li>
<li>Examples <a
href="https://www.oreilly.com/ideas/5-reasons-you-need-to-learn-to-write-python-decorators">5
use cases for decorators</a></li>
</ul>
<p>I have used decorators to cache the function output along a data
processing pipeline.</p>
<div id="property-and-cached-property" class="section level3">
<h3>Property and cached property</h3>
<p>Since python 3.8 there is also a <code>@cached_property</code>
decorator <a
href="https://docs.python.org/dev/library/functools.html#functools.cached_property">functools.cached_property</a></p>
<blockquote>
<p>“Transform a method of a class into a property whose value is
computed once and then cached as a normal attribute for the life of the
instance. Similar to property(), with the addition of caching. Useful
for expensive computed properties of instances that are otherwise
effectively immutable.”</p>
</blockquote>
<p>There is also a <code>@cache</code> decorator <a
href="https://docs.python.org/dev/library/functools.html#functools.cache">functools.cache</a>
that creates:</p>
<blockquote>
<p>“a thin wrapper around a dictionary lookup for the function
arguments. Because it never needs to evict old values, this is smaller
and faster than lru_cache() with a size limit.</p>
</blockquote>
</div>
</div>
<div id="deprecate-arguments" class="section level2">
<h2>Deprecate arguments</h2>
<p>Deprecate the old name of a function argument</p>
<pre><code>def agg_trade_eu_row(df, grouping_side=&quot;partner&quot;, index_side=None):
    if index_side is not None:
        warnings.warn(&quot;index_side is deprecated; use grouping_side&quot;, DeprecationWarning, 2)
        grouping_side = index_side</code></pre>
<p>This <a href="https://stackoverflow.com/q/49802412/2641825">SO
Questions</a> asks how to create an argument alias, without changing the
number of arguments to the function.</p>
</div>
<div id="docstring-documentation" class="section level2">
<h2>Docstring Documentation</h2>
<p>Document python functions with the sphinx convention <a
href="https://stackoverflow.com/a/40596167">SO Answer</a></p>
<pre><code>def send_message(sender, recipient, message_body, priority=1) -&gt; int:
   &quot;&quot;&quot;
   Send a message to a recipient

   :param str sender: The person sending the message
   :param str recipient: The recipient of the message
   :param str message_body: The body of the message
   :param priority: The priority of the message, can be a number 1-5
   :type priority: integer or None
   :return: the message id
   :rtype: int
   :raises ValueError: if the message_body exceeds 160 characters
   :raises TypeError: if the message_body is not a basestring
   &quot;&quot;&quot;</code></pre>
</div>
</div>
<div id="math" class="section level1">
<h1>Math</h1>
<p><a
href="https://www.digitalocean.com/community/tutorials/how-to-do-math-in-python-3-with-operators">How
to do maths in python 3 with operators</a></p>
<p>2 to the power of 3</p>
<pre><code>2**3
# 8</code></pre>
<div id="floor-division" class="section level2">
<h2>Floor division</h2>
<p>Floor division</p>
<pre><code>5//3
# 1
# Use it to extract the year of a Comtrade period
202105 // 100</code></pre>
</div>
<div id="modulo" class="section level2">
<h2>Modulo</h2>
<pre><code>5%3
# 2
12
# Use it to extract the last 2 digits of an integer
202105 % 100</code></pre>
</div>
<div id="sympy" class="section level2">
<h2>Sympy</h2>
<p><a href="https://www.sympy.org/en/index.html"
class="uri">https://www.sympy.org/en/index.html</a></p>
<blockquote>
<p>“SymPy is a Python library for symbolic mathematics. It aims to
become a full-featured computer algebra system (CAS) while keeping the
code as simple as possible in order to be comprehensible and easily
extensible. SymPy is written entirely in Python.”</p>
</blockquote>
</div>
</div>
<div id="modelling" class="section level1">
<h1>Modelling</h1>
<div id="pyomo" class="section level2">
<h2>Pyomo</h2>
<p><a
href="https://jckantor.github.io/ND-Pyomo-Cookbook/01.00-Getting-Started-with-Pyomo.html">Pyomo
Cookbook</a></p>
<blockquote>
<p>“Pyomo is well suited to modeling simple and complex systems that can
be described by linear or nonlinear algebraic, differential, and partial
differential equations and constraints.”</p>
</blockquote>
</div>
</div>
<div id="numpy-vectors-and-matrices-arrays" class="section level1">
<h1>Numpy vectors and matrices (arrays)</h1>
<p>All examples below are based on the numpy package being imported as
np :</p>
<pre><code>import numpy as np</code></pre>
<div id="logical-operators-and-binary-operations"
class="section level2">
<h2>Logical operators and binary operations</h2>
<p>I mostly use <a
href="%3Chttps://numpy.org/doc/stable/reference/routines.bitwise.html">binary
operators</a> on boolean arrays for index selections in pandas data
frames.</p>
<p>Bitwise and</p>
<pre><code>np.array([True, True]) &amp; np.array([False, True])</code></pre>
<p>Bitwise not</p>
<pre><code>~np.array([True, False])</code></pre>
<p>They are equivalent to logical operators <a
href="https://numpy.org/doc/stable/reference/generated/numpy.logical_and.html">numpy.logical_and</a>,
<a
href="https://numpy.org/doc/stable/reference/generated/numpy.logical_not.html">numpy.logical_not</a>
for logical arrays.</p>
<p>A <a href="https://stackoverflow.com/a/54435820/2641825">SO
answer</a> quotes <a
href="https://www.numpy.org/devdocs/user/numpy-for-matlab-users.html#numpy-for-matlab-users-notes">the
NumPy v1.15 Manual</a></p>
<pre><code>&gt; If you know you have boolean arguments, you can get away with using
&gt; NumPy’s bitwise operators, but be careful with parentheses, like this:
&gt; `z = (x &gt; 1) &amp; (x &lt; 2)`. The absence of NumPy operator forms of
&gt; `logical_and` and `logical_or` is an unfortunate consequence of Python’s
&gt; design.</code></pre>
<blockquote>
<p>So one can also use <code>~</code> for <code>logical_not</code> and
<code>|</code> for <code>logical_or</code>.</p>
</blockquote>
<p><a
href="https://numpy.org/doc/stable/reference/generated/numpy.bitwise_and.html">Bitwise
and</a></p>
<blockquote>
<p>“The number 13 is represented by 00001101. Likewise, 17 is
represented by 00010001. The bit-wise AND of 13 and 17 is therefore
000000001, or 1”</p>
</blockquote>
<pre><code>np.bitwise_and(13, 17)
# 1</code></pre>
<p>The <code>&amp;</code> operator can be used as a shorthand for
np.bitwise_and on ndarrays.</p>
<pre><code>x1 = np.array([2, 5, 255])
x2 = np.array([3, 14, 16])
x1 &amp; x2</code></pre>
</div>
<div id="indexing-multi-dimensional-arrays-and-masks"
class="section level2">
<h2>Indexing Multi-dimensional arrays and masks</h2>
<p>Numpy <a
href="https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html">array
indexing</a></p>
<blockquote>
<p>“Basic slicing extends Python’s basic concept of slicing to N
dimensions. Basic slicing occurs when obj is a slice object (constructed
by start:stop:step notation inside of brackets), an integer, or a tuple
of slice objects and integers.” […] The basic slice syntax is i:j:k
where i is the starting index, j is the stopping index, and k is the
step (<span class="math inline">\(k\neq0\)</span>). “[…]”Advanced
indexing always returns a copy of the data (contrast with basic slicing
that returns a view).” “Integer array indexing allows selection of
arbitrary items in the array based on their N-dimensional index. Each
integer array represents a number of indexes into that dimension.”</p>
</blockquote>
<pre><code>x[0:3,0:2]
# array([[0.64174957, 0.18540429],
#        [0.97558697, 0.69314058],
#        [0.51646795, 0.71055115]])</code></pre>
<p>In this case because every row is selected, it is the same as:</p>
<pre><code>x[:,0:2]</code></pre>
<p>Examples modified from <a
href="https://docs.scipy.org/doc/numpy/user/basics.indexing.html"
class="uri">https://docs.scipy.org/doc/numpy/user/basics.indexing.html</a></p>
<pre><code>y = np.arange(35).reshape(5,7)
print(y[np.array([0,2,4]), np.array([0,1,2])])

print(&#39;With slice 1:3&#39;)
print(y[np.array([0,2,4]),1:3])
print(&#39;is equivalent to&#39;)
print(y[np.array([[0],[2],[4]]),np.array([[1,2]])])
# This one is the same but transposed, which is weird
print(y[np.array([[0,2,4]]),np.array([[1],[2]])])
# Notice the difference with the following
print(y[np.array([0,2,4]),np.array([1,2,3])])</code></pre>
<p>Masks <a
href="https://docs.scipy.org/doc/numpy/reference/maskedarray.generic.html">masked
array</a> We wish to mark the fourth entry as invalid. The easiest is to
create a masked array:</p>
<pre><code>x = np.array([1, 2, 3, -1, 5])
mx = np.ma.masked_array(x, mask=[0, 0, 0, 1, 0])
print(x.sum(), mx.sum())
# 10 11</code></pre>
</div>
<div id="matrix-creation-and-shapes" class="section level2">
<h2>Matrix creation and shapes</h2>
<p>Create a vector</p>
<pre><code>a = np.array([1,2,3])</code></pre>
<p>Create a matrix</p>
<pre><code>b = np.array([[1,2,3],[5,6,6]])</code></pre>
<p>Shape</p>
<pre><code>a.shape
# (3,)
b.shape
# (2, 3)</code></pre>
<p>Matrix of zeroes</p>
<pre><code>np.zeros([2,2])
#array([[0., 0.],
#       [0., 0.]])</code></pre>
<p>Create a matrix with an additional dimension</p>
<pre><code>np.zeros(b.shape + (2,))
array([[[0., 0.],
        [0., 0.],
        [0., 0.]],

       [[0., 0.],
        [0., 0.],
        [0., 0.]]])</code></pre>
<p>Transpose</p>
<pre><code>b.transpose()
# array([[1, 5],
#        [2, 6],
#        [3, 6]])
c = b.transpose()</code></pre>
<p>Math functions in numpy:</p>
<pre><code>np.cos()
np.sin()
np.tan()
np.exp()</code></pre>
<p>min and max</p>
<pre><code>x = np.array([1,2,3,4,5,-7,10,-8])
x.max()
# 10
x.min()
# -8</code></pre>
</div>
<div id="matrix-multiplication" class="section level2">
<h2>Matrix multiplication</h2>
<p>Matrix multiplication <a
href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html">matmul</a></p>
<pre><code>np.matmul(a,c)
# array([14, 35])

# Can also be written as
a @ c
# array([14, 35])</code></pre>
<p>Otherwise the multiplication symbol implements an element wise
multiplication, also called the</p>
<p><a
href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)">Hadamard
product</a>. It only works on 2 matrices of same dimensions.
Element-wise multiplication is used for example in convolution
kernels.</p>
<pre><code>b * b
# array([[ 1,  4,  9],
#        [25, 36, 36]])</code></pre>
<p>So here is again an example showing the difference between</p>
<pre><code>m = np.array([[0,1],[2,3]])</code></pre>
<p>Element wise multiplication :</p>
<pre><code>m * m 
# array([[0, 1],
#        [4, 9]])</code></pre>
<p>Matrix multiplication :</p>
<pre><code>m @ m
# array([[ 2,  3],
#        [ 6, 11]])</code></pre>
</div>
<div id="norm-of-a-matrix" class="section level2">
<h2>Norm of a matrix</h2>
<p>Linear algebra functionalities are provided by numpy.linalg For
example the norm of a matrix or vector:</p>
<pre><code>np.linalg.norm(x)
# 16.3707055437449
np.linalg.norm(np.array([3,4]))
# 5.0
np.linalg.norm(a)
# 3.7416573867739413</code></pre>
<p>Norm of the matrix for the regularization parameter in a machine
learning model</p>
<pre><code>bli = np.array([[1, 1, 0.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 0.0, 0.0],
                [0.0, 1, 0.0, 0.0, 0.0]])
sum(np.linalg.norm(bli, axis=0)**2) 3.0000000000000004
sum(np.linalg.norm(bli, axis=1)**2) 3.0000000000000004
np.linalg.norm(bli)**2 2.9999999999999996</code></pre>
<p>Append vs concatenate</p>
<pre><code>x = np.array([1,2])
print(np.append(x,x))
# [1 2 1 2]
print(np.concatenate((x,x),axis=None))
a = np.array([[1, 2], [3, 4]])
b = np.array([[5, 6]])
print(np.concatenate((a, b), axis=0))
print(np.concatenate((a, b.T), axis=1))
print(np.concatenate((a, b), axis=None))</code></pre>
</div>
<div id="power" class="section level2">
<h2>Power</h2>
<p>Power of an array</p>
<pre><code>import numpy as np
a = np.arange(4).reshape(2, 2)
print(a)
print(a**2)
print(a*a)
np.power(a, 2)</code></pre>
<p>Broadcast the power operator</p>
<pre><code>np.power(a, a)</code></pre>
</div>
<div id="random-vector-or-matrices" class="section level2">
<h2>Random vector or matrices</h2>
<pre><code>x = np.random.random([3,4])
x
# array([[0.64174957, 0.18540429, 0.7045183 , 0.44623567],
#        [0.97558697, 0.69314058, 0.32469324, 0.82612627],
#        [0.51646795, 0.71055115, 0.74864751, 0.2142459 ]])</code></pre>
<p>Random choice, with a given probability Choose zero with probability
0.1 and one with probability 0.9.</p>
<pre><code>for i in range(10):
    print(np.random.choice(2, p=[0.1, 0.9]))
    
print(np.random.choice(2, 10, p=[0.1, 0.9]))
print(np.random.choice(2, (10,10), p=[0.1, 0.9]))

[[1 1 1 1 1 1 1 1 1 0]
 [1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 0]
 [1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 0 1 1]
 [1 1 1 0 1 1 1 1 1 1]
 [1 1 0 1 1 1 1 1 0 1]
 [1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 0 1 1 0]
 [1 1 1 1 1 1 1 1 1 1]]</code></pre>
<p>Error if probabilities do not sum up to one</p>
<pre><code>print(np.random.choice(2, p=[0.1, 0.8]))

# ---------------------------------------------------------------------------
# ValueError                                Traceback (most recent call last)
# &lt;ipython-input-31-8a8665287968&gt; in &lt;module&gt;
# ----&gt; 1 print(np.random.choice(2, p=[0.1, 0.8]))

# mtrand.pyx in numpy.random.mtrand.RandomState.choice()

# ValueError: probabilities do not sum to 1</code></pre>
</div>
</div>
<div id="pandas-data-frames" class="section level1">
<h1>Pandas data frames</h1>
<p>All code below assumes you have imported pandas</p>
<pre><code>import pandas </code></pre>
<div id="assign-values" class="section level2">
<h2>Assign values</h2>
<div id="create-a-data-frame" class="section level3">
<h3>Create a data frame</h3>
<p>You can create a data frame by passing a <strong>dictionary of
lists</strong> with column names as keys</p>
<pre><code>df = pandas.DataFrame({&#39;x&#39;:range(0,3), 
                  &#39;y&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})

#      a  b
#   0  0  3
#   1  1  4
#   2  2  5</code></pre>
<p>Or by passing a list of tuples and defining the <code>columns</code>
argument</p>
<pre><code>pandas.DataFrame(
    list(zip(range(0,3), [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;])), 
    columns=[&quot;x&quot;, &quot;y&quot;]
)</code></pre>
<p>Random numbers</p>
<pre><code>import numpy as np
df = pandas.DataFrame({&#39;x&#39;:np.random.random(100)})</code></pre>
</div>
<div id="use-the-assign-method" class="section level3">
<h3>Use the assign method</h3>
<p>Create a new column based on another one</p>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:range(0,3), 
                       &#39;b&#39;:[&#39;p&#39;,&#39;q&#39;,&#39;r&#39;], 
                       &#39;c&#39;:[&#39;m&#39;,&#39;n&#39;,&#39;o&#39;]})
df[&quot;d&quot;] = df[&quot;a&quot;] * 2</code></pre>
<p>Use the <code>assign</code> method</p>
<pre><code>df.assign(e = lambda x: x[&quot;a&quot;] * 3)</code></pre>
<div id="sum-columns-together-and-compute-a-share"
class="section level4">
<h4>Sum columns together and compute a share</h4>
<p>Sum all columns in an assign and use it to compute a share</p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;).set_index(&quot;species&quot;)
iris.assign(sp_sum = lambda x: x.sum(axis=1),
            sl_share = lambda x: x.sepal_length / x.sp_sum)</code></pre>
</div>
</div>
<div id="recursive-computation-xt-depends-on-xt-1"
class="section level3">
<h3>Recursive computation x(t) depends on x(t-1)</h3>
<p>A recursive function is difficult to vectorize because each input at
time t depends on the previous input at time t-1. When possible use a
year index for shorter selection with <code>.loc()</code>.</p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;year&#39;:range(2020,2024),&#39;a&#39;:range(3,7)})
df1 = df.copy()
# Set the initial value
t0 = min(df1.year)
df1.loc[df1.year==t0, &quot;x&quot;] = 0

# Doesn&#39;t work when the right side of the equation is a pandas.core.series.Series
for t in range (min(df1.year)+1, max(df1.year)+1):
    df1.loc[df1.year==t, &quot;x&quot;] = df1.loc[df1.year==t-1,&quot;x&quot;] + df1.loc[df1.year==t-1,&quot;a&quot;]
print(df1)
#    year  a    x
# 0  2020  3  0.0
# 1  2021  4  NaN
# 2  2022  5  NaN
# 3  2023  6  NaN
print(type(df1.loc[df1.year==t-1,&quot;x&quot;] + df1.loc[df1.year==t-1,&quot;a&quot;]))
# &lt;class &#39;pandas.core.series.Series&#39;&gt;

# Works when the right side of the equation is a numpy array
for t in range (min(df1.year)+1, max(df1.year)+1):
    df1.loc[df1.year==t, &quot;x&quot;] = (df1.loc[df1.year==t-1,&quot;x&quot;] + df1.loc[df1.year==t-1,&quot;a&quot;]).unique()
    #break
print(df1)
#    year  a     x
# 0  2020  3   0.0
# 1  2021  4   3.0
# 2  2022  5   7.0
# 3  2023  6  12.0
print(type((df1.loc[df1.year==t-1,&quot;x&quot;] + df1.loc[df1.year==t-1,&quot;a&quot;]).unique()))
# &lt;class &#39;numpy.ndarray&#39;&gt;

# Assignement works directly when the .loc() selection is using a year index
df2 = df.set_index(&quot;year&quot;).copy()
# Set the initial value
df2.loc[df2.index.min(), &quot;x&quot;] = 0
for t in range (df2.index.min()+1, df2.index.max()+1):
    df2.loc[t, &quot;x&quot;] = df2.loc[t-1, &quot;x&quot;] + df2.loc[t-1,&quot;a&quot;]
    #break
print(df2)
#       a     x
# year
# 2020  3   0.0
# 2021  4   3.0
# 2022  5   7.0
# 2023  6  12.0
print(type(df2.loc[t-1, &quot;x&quot;] + df2.loc[t-1,&quot;a&quot;]))
# &lt;class &#39;numpy.float64&#39;&gt;

#SO answer using cumsum</code></pre>
<p>Our real problem is more complicated since there is a multiplicative
and an additive component</p>
<pre><code>import pandas
df3 = pandas.DataFrame({&#39;year&#39;:range(2020,2024),&#39;a&#39;:range(3,7), &#39;b&#39;:range(8,12)})
df3 = df3.set_index(&quot;year&quot;).copy()
# Set the initial value
initial_value = 1
df3.loc[df3.index.min(), &quot;x&quot;] = initial_value
# Use a loop
for t in range (df3.index.min()+1, df3.index.max()+1):
    df3.loc[t, &quot;x&quot;] = df3.loc[t-1, &quot;x&quot;] * df3.loc[t-1, &quot;a&quot;] + df3.loc[t-1, &quot;b&quot;]
# Use cumsum and cumprod
df3[&quot;cumprod_a&quot;] = df3.a.cumprod().shift(1).fillna(1)
df3[&quot;cumsum_cumprod_a_b&quot;] = df3.cumprod_a.cumsum().shift(1).fillna(0) * df3.b
df3[&quot;x2&quot;] = df3.cumprod_a * initial_value + df3.cumsum_cumprod_a_b
print(df3)</code></pre>
<ul>
<li><p><code>type(df1.loc[df1.year==t-1,"x"] + df1.loc[df1.year==t-1,"a"])</code>
is a pandas series while
<code>type(df2.loc[t-1, "x"] + df2.loc[t-1,"a"])</code> is a numpy
float. Why are types different?</p></li>
<li><p>Is there a better way to write a recursive <code>.loc()</code>
assignment than to use <code>.unique()</code>?</p></li>
</ul>
<p>See also:</p>
<ul>
<li>related Question and Answer on <a
href="https://stackoverflow.com/a/38008937/2641825">recursive
assignment</a></li>
<li>related documentation on <a
href="https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#mutating-with-user-defined-function-udf-methods">Mutating
User Defined Function methods</a></li>
</ul>
<blockquote>
<p>“It is a general rule in programming that one should not mutate a
container while it is being iterated over. Mutation will invalidate the
iterator, causing unexpected behavior.” […] “To resolve this issue, one
can make a copy so that the mutation does not apply to the container
being iterated over.”</p>
</blockquote>
</div>
<div id="set-values-with-.loc" class="section level3">
<h3>Set values with .loc</h3>
<p>Create an example data frame</p>
<pre><code>import pandas
df = pandas.DataFrame([[1, 2], [4, 5], [7, 8]],
                      index=[&#39;cobra&#39;, &#39;viper&#39;, &#39;sidewinder&#39;],
                      columns=[&#39;max_speed&#39;, &#39;shield&#39;])</code></pre>
<p>Set value for all items matching the list of labels</p>
<pre><code>df.loc[[&#39;viper&#39;, &#39;sidewinder&#39;], [&#39;shield&#39;]] = 50

#             max_speed  shield
# cobra               1       2
# viper               4      50
# sidewinder          7      50</code></pre>
</div>
<div id="map-values-with-a-dictionary" class="section level3">
<h3>Map values with a dictionary</h3>
<pre><code>df = pandas.DataFrame({&#39;lettre&#39;:[&#39;p&#39;,&#39;q&#39;,&#39;r&#39;,&#39;r&#39;,&#39;s&#39;,&#39;v&#39;,&#39;p&#39;]})
mapping = {&#39;p&#39;:&#39;pour&#39;,&#39;q&#39;:&#39;quoi&#39;,&#39;r&#39;:&#39;roi&#39;}
df[&quot;mot&quot;] = df[&quot;lettre&quot;].map(mapping)</code></pre>
</div>
</div>
<div id="convert-data-frames" class="section level2">
<h2>Convert data frames</h2>
<p>Convert 2 columns to a dictionary</p>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:range(0,3), 
                       &#39;b&#39;:[&#39;p&#39;,&#39;q&#39;,&#39;r&#39;], 
                       &#39;c&#39;:[&#39;m&#39;,&#39;n&#39;,&#39;o&#39;]})
df.set_index(&#39;b&#39;).to_dict()[&#39;c&#39;]</code></pre>
</div>
<div id="compare-data-frames" class="section level2">
<h2>Compare data frames</h2>
<p>Pure equality example from <a
href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.equals.html">pandas.DataFrame.equals</a></p>
<pre><code>import pandas
df = pandas.DataFrame({1: [10], 2: [20]})
exactly_equal = pandas.DataFrame({1: [10], 2: [20]})
df.equals(exactly_equal)
different_column_type = pandas.DataFrame({1.0: [10], 2.0: [20]})
df.equals(different_column_type)
different_data_type = pandas.DataFrame({1: [10.0], 2: [20.0]})
df.equals(different_data_type)</code></pre>
<p>Testing closeness (for example with floating point results computed
in another software)</p>
<pre><code>import numpy as np
df.equals(df+1e-6)
np.testing.assert_allclose(df,df+1e-7)
np.testing.assert_allclose(df,df+1e-3)</code></pre>
</div>
<div id="concatenate-and-merge" class="section level2">
<h2>Concatenate and merge</h2>
<div id="concatenate-2-data-frames" class="section level3">
<h3>Concatenate 2 data frames</h3>
</div>
<div id="concatenate-2-series" class="section level3">
<h3>Concatenate 2 series</h3>
<p>Concatenate two series <a
href="https://stackoverflow.com/questions/18062135/combining-two-series-into-a-dataframe-in-pandas">SO</a>
Notice the difference between the default <code>axis=0</code>
concatenate on the index, and <code>axis=1</code> concatenate on the
columns.</p>
<pre><code>import pandas
s1 = pandas.Series([1, 2, 3], index=[&#39;A&#39;, &#39;B&#39;, &#39;c&#39;], name=&#39;s1&#39;)
s2 = pandas.Series([4, 5, 6], index=[&#39;A&#39;, &#39;B&#39;, &#39;D&#39;], name=&#39;s2&#39;)
pandas.concat([s1, s2], axis=0)
pandas.concat([s1, s2], axis=1)</code></pre>
</div>
<div id="merge-or-join" class="section level3">
<h3>Merge or join</h3>
<p>Stackoverflow <a
href="https://stackoverflow.com/questions/53645882/pandas-merging-101/53645883#53645883">Pandas
merging</a></p>
</div>
</div>
<div id="columns" class="section level2">
<h2>Columns</h2>
<div id="list-columns" class="section level3">
<h3>List Columns</h3>
<p>List columns as an index object</p>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:range(0,3),&#39;b&#39;:range(3,6)})
df.columns</code></pre>
<p>List columns as a list</p>
<pre><code>df.columns.tolist()</code></pre>
<p>Select only certain columns in a list</p>
<pre><code>df[&#39;bla&#39;] = 0
cols = df.columns.tolist()
[name for name in cols if &#39;a&#39; in name]</code></pre>
</div>
<div id="remove-empty-columns" class="section level3">
<h3>Remove empty columns</h3>
<p>Remove empty columns</p>
<pre><code>import pandas
import numpy as np
df = pandas.DataFrame({&#39;A&#39; : [&#39;bli&#39;, &#39;bla&#39;, &#39;bla&#39;, &#39;bla&#39;, &#39;bla&#39;],
                       &#39;B&#39; : [np.nan, &#39;2&#39;,&#39;2&#39;, &#39;4&#39;, &#39;1&#39;],
                       &#39;C&#39; : np.nan})
columns_to_keep = [x for x in df.columns if not all(df[x].isna())]
df = df[columns_to_keep].copy()</code></pre>
</div>
<div id="rename-columns" class="section level3">
<h3>Rename columns</h3>
<p>Rename the ‘a’ column to ‘new’</p>
<pre><code>df.rename(columns={&#39;a&#39;:&#39;new&#39;})</code></pre>
<p>Rename columns to snake case using a regular expression</p>
<pre><code>import re
df.rename(columns=lambda x: re.sub(r&quot; &quot;, &quot;_&quot;, str(x)).lower(), inplace=True)
# Another regexp that replaces all non alphanumeric characters by an
# underscore
df.rename(columns=lambda x: re.sub(r&quot;\W+&quot;, &quot;_&quot;, str(x)).lower(), inplace=True)</code></pre>
<p>Remove parenthesis and dots in column names</p>
<pre><code>df.rename(columns=lambda x: re.sub(r&quot;[()\.]&quot;, &quot;&quot;, x), inplace=True)</code></pre>
</div>
<div id="reorder-columns" class="section level3">
<h3>Reorder columns</h3>
<p>Place the last column first</p>
<pre><code>  cols = df.columns.to_list()
  cols = [cols[-1] + cols[:-1]
  df = df[cols]</code></pre>
<p>This <a href="https://stackoverflow.com/a/58776941/2641825">SO
Answer</a> provide 6 different ways to reorder columns.</p>
</div>
<div id="replace-the-content-of-columns" class="section level3">
<h3>Replace the content of columns</h3>
<p>Replace Comtrade product code by the FAOSTAT product codes</p>
<pre><code># Create a dictionary from 2 columns of a data frame
product_dict = product_mapping.set_index(&#39;comtrade_code&#39;).to_dict()[&#39;faostat_code&#39;]
df_comtrade[&quot;product_code&quot;] = df_comtrade[&quot;product_code&quot;].replace(product_dict)</code></pre>
</div>
<div id="variable-type" class="section level3">
<h3>Variable Type</h3>
<p>To change the type of a column use astype:</p>
<pre><code>s = pandas.Series(range(3))
s.to_list()
s.astype(str).to_list()
s.astype(float).to_list()</code></pre>
<p>Note using NA values is not possible with the base integer type, it
requires a special type Int64 as explained in this <a
href="https://stackoverflow.com/a/67270477/2641825">SO answer</a></p>
</div>
<div id="memory-usage" class="section level3">
<h3>Memory usage</h3>
<p>To display the memory usage of <a
href="https://stackoverflow.com/questions/18089667/how-to-estimate-how-much-memory-a-pandas-dataframe-will-need">each
column in a pandas data frame</a></p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;x&#39;:range(0,3), &#39;y&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})
print(df.memory_usage(deep=True))
print(df.memory_usage(deep=True).sum())
df.info()</code></pre>
<p>Using <code>sys.getsizeof</code>:</p>
<pre><code>import sys
print(sys.getsizeof(df))</code></pre>
<p>Changing a repeated data series to a categorical can help reduce
memory usage</p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
print(iris[&quot;species&quot;].memory_usage(deep=True))
print(iris[&quot;species&quot;].astype(&#39;category&#39;).memory_usage(deep=True))
iris2 = iris.copy()
iris2[&quot;species&quot;] = iris[&quot;species&quot;].astype(&#39;category&#39;)
print(sys.getsizeof(iris2))
print(sys.getsizeof(iris))</code></pre>
</div>
</div>
<div id="datetime-operations" class="section level2">
<h2>Datetime operations</h2>
<p>Create date time columns from a character column</p>
<pre><code>import pandas
pandas.to_datetime(&#39;2020-01-01&#39;, format=&#39;%Y-%m-%d&#39;)
pandas.to_datetime(&#39;2020-01-02&#39;)
pandas.to_datetime(&#39;20200103&#39;)</code></pre>
<p>Extract the year</p>
<pre><code>s = pandas.Series(pandas.date_range(&quot;2000-01-01&quot;, periods=3, freq=&quot;Y&quot;))
print(s)
print(s.dt.year)</code></pre>
</div>
<div id="group-by-operations" class="section level2">
<h2>Group by operations</h2>
<p>Compute the sum of sepal length grouped by species</p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
# Aggregate one value
iris.groupby(&#39;species&#39;)[&quot;sepal_length&quot;].agg(sum).reset_index()
# Aggregate multiple values
iris.groupby(&#39;species&#39;)[[&quot;sepal_length&quot;, &quot;petal_length&quot;]].agg(sum).reset_index()
# Aggregate multiple values and give new names
iris.groupby(&#39;species&#39;).agg(sepal_length_sum = (&#39;sepal_length&#39;, sum),
                            petal_length_sum = (&#39;petal_length&#39;, sum))</code></pre>
<p>Compute the sum but repeated for every original row</p>
<pre><code>iris[&#39;sepal_sum&#39;] = iris.groupby(&#39;species&#39;)[&#39;sepal_length&#39;].transform(&#39;sum&#39;)
iris</code></pre>
<p>This is useful to compute the <a
href="https://stackoverflow.com/questions/23377108/pandas-percentage-of-total-with-groupby">share
of total in each group</a> for example.</p>
<p>Compute the cumulative sum of the sepal length</p>
<pre><code>iris[&#39;cumsum&#39;] = iris.groupby(&#39;species&#39;).sepal_length.cumsum()
ris[&#39;cumsum&#39;].plot()
from matplotlib import pyplot
pyplot.show()</code></pre>
<p>Compute a lag</p>
<pre><code>iris[&#39;cumsum_lag&#39;] = iris.groupby(&#39;species&#39;)[&#39;cumsum&#39;].transform(&#39;shift&#39;, fill_value=0)
iris[[&#39;cumsum&#39;, &#39;cumsum_lag&#39;]].plot()
pyplot.show()</code></pre>
<div id="compute-with-a-lambda-function" class="section level3">
<h3>Compute with a lambda function</h3>
<p>Beyond standard function such as <code>sum</code> and
<code>mean</code>, it’s possible to use a self defined lambda function
as follows</p>
<pre><code>import numpy as np
(iris
 .groupby([&quot;species&quot;])
 .agg(pw_sum = (&quot;petal_width&quot;, sum),
      pw_sum_div_by_10 = (&quot;petal_width&quot;, lambda x: x.sum()/0),
      n = (&quot;petal_width&quot;, len),
      mean1 = (&quot;petal_width&quot;, np.mean))
 .assign(mean2 = lambda x: x.pw_sum / x.n)
)</code></pre>
</div>
<div id="lag-or-shift-a-grouped-variable" class="section level3">
<h3>Lag or shift a grouped variable</h3>
<p>Load the flights dataset and for each month, display the passenger
value in the same month of the previous year. Compare the
<code>passengers</code> and <code>pass_year_minus_one</code> columns by
displaying the tables for January and December.</p>
<pre><code>import seaborn
flights = seaborn.load_dataset(&quot;flights&quot;)
flights[&#39;pass_year_minus_one&#39;] = flights.groupby([&#39;month&#39;]).passengers.shift()
flights.query(&quot;month==&#39;January&#39;&quot;)
flights.query(&quot;month==&#39;December&#39;&quot;)</code></pre>
</div>
<div id="min-or-max-in-group" class="section level3">
<h3>Min or max in group</h3>
<p>Min or max in each group</p>
<pre><code>df.loc[df.groupby(&#39;A&#39;)[&#39;B val&#39;].idxmin()]</code></pre>
</div>
<div id="slice-get-the-first-elements-of-each-group"
class="section level3">
<h3>Slice, get the first elements of each group</h3>
<ul>
<li><p><a
href="https://stackoverflow.com/questions/30486417/pandas-how-do-i-select-first-row-in-each-group-by-group">How
do I select the first row in each group in groupby</a></p>
<p>import pandas import numpy as np df = pandas.DataFrame({‘A’ : [‘foo’,
‘foo’, ‘bar’, ‘bar’, ‘bar’], ‘B’ : [‘1’, ‘2’,‘2’, ‘4’, ‘1’], ‘C’ :
[np.nan, ‘X’, ‘Y’, ‘Y’, ‘Y’]}) df.sort_values(‘B’).groupby(‘A’).nth(0)
df.sort_values(‘B’).groupby(‘A’).nth(list(range(2)))
df.sort_values(‘B’).groupby(‘A’).head(2)</p></li>
</ul>
</div>
<div id="transform-and-apply" class="section level3">
<h3>Transform and apply</h3>
<p><a href="https://stackoverflow.com/a/47143056/2641825">SO answer
explaining the difference between transform and apply</a></p>
</div>
</div>
<div id="index" class="section level2">
<h2>Index</h2>
<p>Index can be converted back to a data frame See also index selection
in the “.loc” section.</p>
<div id="recursive-computation-on-a-index-in-a-loop"
class="section level3">
<h3>Recursive computation on a index in a loop</h3>
<div id="simple-index-case" class="section level4">
<h4>Simple index case</h4>
<p>Compute in a loop based on the value of the previous year t-1. If
there is a single value by year, scalar computation</p>
<pre><code>df = pandas.DataFrame({&#39;x&#39;:range(0,10)})
df.loc[0, &quot;y&quot;] = 2
for t in range(1, len(df)):
    df.loc[t, &quot;y&quot;] = pow(df.loc[t-1, &quot;y&quot;], df.loc[t, &quot;x&quot;]/2)
df</code></pre>
<p>If there are multiple values for each single year vector
computation.</p>
<pre><code>import itertools
import pandas
countries = [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;]
years = range(1990, 2020)
expand_grid = list(itertools.product(countries, years))
df = pandas.DataFrame(expand_grid, columns=(&#39;country&#39;, &#39;year&#39;))
df[&quot;x&quot;] = 1
df[&quot;x&quot;] = df[&quot;x&quot;].cumsum()
df.set_index([&quot;year&quot;], inplace=True)
df.loc[min(years), &quot;y&quot;] = 2
for t in range(min(years)+1, max(years)+1):
    df.loc[t, &quot;y&quot;] = pow(df.loc[t-1, &quot;y&quot;], df.loc[t, &quot;x&quot;]/2)
df</code></pre>
<p>Multi index case I would like to compute the consumption equation of
a partial equilibrium model.</p>
<pre><code>pandas.DataFrame({&#39;x&#39;:range(0,3), 
                  &#39;y&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})

for t in range(gfpmx_data.base_year + 1, years.max()+1):
    # TODO: replace this loop by vectorized operations using only the index on years
    for c in countries:
        # Consumption
        swd.loc[(t,c), &quot;cons2&quot;] = (swd.loc[(t, c), &quot;constant&quot;]
                                   * pow(swd.loc[(t-1, c), &quot;price&quot;],
                                         swd.loc[(t, c), &quot;price_elasticity&quot;])
                                   * pow(swd.loc[(t, c), &quot;gdp&quot;],
                                         swd.loc[(t, c), &quot;gdp_elasticity&quot;])
                                  )
swd[&#39;comp_prop&#39;] = swd.cons2 / swd.cons -1
print(swd[&quot;comp_prop&quot;].abs().max())
swd.query(&quot;year &gt;= 2019&quot;)</code></pre>
</div>
</div>
<div id="unique-values-of-a-multi-index" class="section level3">
<h3>Unique values of a multi index</h3>
<p>Display the unique values of the two columns with a count of
occurrences</p>
<pre><code>import seaborn
penguins = seaborn.load_dataset(&quot;penguins&quot;)
penguins.value_counts([&quot;species&quot;, &quot;island&quot;])
penguins[[&quot;species&quot;, &quot;island&quot;]].value_counts()</code></pre>
<p>Lower level method using <code>unique()</code> on a multi index and
returning a data frame</p>
<pre><code>penguins.set_index([&quot;species&quot;, &quot;island&quot;]).index.unique().to_frame(False)</code></pre>
</div>
</div>
<div id="pyarrow" class="section level2">
<h2>PyArrow</h2>
<ul>
<li><a href="https://arrow.apache.org/overview/">Apache Arrow
overview</a> explains the advantage of using a in memory columnar format
to store data:</li>
</ul>
<blockquote>
<p>“The Apache Arrow format allows computational routines and execution
engines to maximize their efficiency when scanning and iterating large
chunks of data. In particular, the contiguous columnar layout enables
vectorization using the latest SIMD (Single Instruction, Multiple Data)
operations included in modern processors.” “[…] a standardized memory
format facilitates reuse of libraries of algorithms, even across
languages.” “Arrow libraries for C (Glib), MATLAB, Python, R, and Ruby
are built on top of the C++ library.”</p>
</blockquote>
<ul>
<li><p><a
href="https://arrow.apache.org/docs/python/pandas.html">PyArrow
interface with pandas</a></p></li>
<li><p><a href="https://arrow.apache.org/docs/python/csv.html">Read and
write csv files</a></p></li>
</ul>
<div id="dask-data-frame" class="section level3">
<h3>Dask data frame</h3>
<p><a href="https://docs.dask.org/en/latest/dataframe.html"
class="uri">https://docs.dask.org/en/latest/dataframe.html</a></p>
</div>
<div id="vaex" class="section level3">
<h3>Vaex</h3>
<p><a href="https://github.com/vaexio/vaex"
class="uri">https://github.com/vaexio/vaex</a></p>
</div>
</div>
<div id="io-input-output" class="section level2">
<h2>IO Input Output</h2>
<div id="csv" class="section level3">
<h3>CSV</h3>
<p>Read and write csv</p>
<div id="compressed-csv" class="section level4">
<h4>Compressed csv</h4>
<p>Write a compressed csv file as a gzip archive</p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;x&#39;:range(0,3), &#39;y&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})
df.to_csv(&quot;/tmp/df.csv.gz&quot;, index=False, compression=&quot;gzip&quot;)</code></pre>
<p>Write a compressed csv file as a zip archive, using a dict with the
option “archive_name” (works only for the zip format)</p>
<pre><code>compression_opts = dict(method=&#39;zip&#39;, archive_name=&#39;out.csv&#39;)
df.to_csv(&#39;/tmp/df.csv.zip&#39;, index=False, compression=compression_opts)</code></pre>
<p>Read compressed csv files</p>
<pre><code>df1 = pandas.read_csv(&quot;/tmp/df.csv.gz&quot;)
df.equals(df1)
df2 = pandas.read_csv(&quot;/tmp/df.csv.zip&quot;)
df.equals(df2)</code></pre>
</div>
<div id="from-an-api" class="section level4">
<h4>From an API</h4>
<p>Pandas data frames can be used to read CSV files from the <a
href="https://comtrade.un.org/Data/">Comtrade data API</a>. For example,
using the default API URL for all countries:</p>
<pre><code>import pandas
df1 = pandas.read_csv(&#39;http://comtrade.un.org/api/get?max=500&amp;type=C&amp;freq=A&amp;px=HS&amp;ps=2020&amp;r=all&amp;p=0&amp;rg=all&amp;cc=TOTAL&amp;fmt=csv&#39;)

df2 = pandas.read_csv(&#39;http://comtrade.un.org/api/get?max=500&amp;type=C&amp;freq=A&amp;px=HS&amp;ps=2020&amp;r=all&amp;p=0&amp;rg=all&amp;cc=01&amp;fmt=csv&#39;,
                       # Force the id column to remain a character column,
                       # otherwise str &quot;01&quot; becomes an int 1.
                       dtype={&#39;Commodity Code&#39;: str, &#39;bli&#39;: str})</code></pre>
<p>Then use df.to_csv to write the data frame to a csv file</p>
<pre><code> df1.to_csv(&quot;/tmp/comtrade.csv&quot;)</code></pre>
</div>
</div>
<div id="feather" class="section level3">
<h3>Feather</h3>
<p>Load a sample data frame and save it to a feather file</p>
<pre><code>import pandas
import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
iris.to_feather(&quot;/tmp/iris.feather&quot;)</code></pre>
<p>Load the data from the feather file</p>
<pre><code>iris2 = pandas.read_feather(&quot;/tmp/iris.feather&quot;)
iris2.equals(iris)</code></pre>
</div>
<div id="parquet" class="section level3">
<h3>Parquet</h3>
<p>Write to one file defaults to [snappy compression](<a
href="https://en.wikipedia.org/wiki/Snappy_(compression)"
class="uri">https://en.wikipedia.org/wiki/Snappy_(compression)</a></p>
<pre><code>import pandas
import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
iris.to_parquet(&quot;/tmp/iris.parquet&quot;)</code></pre>
<p>Read back the file</p>
<pre><code>iris3 = pandas.read_parquet(&quot;/tmp/iris.parquet&quot;)
iris3.equals(iris)</code></pre>
<p>You can also use gzip compression for a smaller file size (but slower
read and write times)</p>
<pre><code>iris.to_parquet(&quot;/tmp/iris.parquet.gzip&quot;, compression=&#39;gzip&#39;) </code></pre>
<div id="partition-column" class="section level4">
<h4>Partition column</h4>
<p>Write to multiple files along a column used as partition variable</p>
<pre><code>iris.to_parquet(&quot;/tmp/iris&quot;,partition_cols=&quot;species&quot;) </code></pre>
<p>The partitioned dataset is saved under a sub directory for each
unique value of the partition variable. For example there is a sub
directory for each species in the <code>/tmp/iris</code> directory</p>
<pre><code>iris
├── species=setosa
│   └── 1609afe5535d4e2b94e65f1892210269.parquet
├── species=versicolor
│   └── 18dd7ae6d0794fd48dad37bf8950d813.parquet
└── species=virginica
    └── e0a9786251f54eed9f16380c8f5c3db3.parquet</code></pre>
<p>On can read a single file in memory</p>
<pre><code>virginica = pandas.read_parquet(&quot;/tmp/iris/species=virginica&quot;)</code></pre>
<p>Note it has lost the species column</p>
<p>Read all files in memory</p>
<pre><code>iris4 = pandas.read_parquet(&quot;/tmp/iris&quot;)</code></pre>
<p>Note the data frame is slightly different. Values are the same but
the species columns has become a categorical variable.</p>
<pre><code>iris4.equals(iris)
# False
iris4.species
# ...
# Name: species, Length: 150, dtype: category
# Categories (3, object): [&#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39;]</code></pre>
<p>Changing it back to a strings makes the 2 data frames equals
again.</p>
<pre><code>iris4[&quot;species&quot;] = iris4[&quot;species&quot;].astype(&quot;str&quot;)
iris4.equals(iris)
# True</code></pre>
<p>Read files with a filter. See
<code>help(pyarrow.parquet.read_pandas)</code> for arguments concerning
the pyarrow engine.</p>
<pre><code>selection = [(&quot;species&quot;, &quot;in&quot;, [&quot;versicolor&quot;,&quot;virginica&quot;])]
iris5 = pandas.read_parquet(&quot;/tmp/iris&quot;, filters=selection)</code></pre>
<p>In fact, the filter variable doesn’t have to be a partition
variable.</p>
<pre><code>selection = [(&quot;species&quot;, &quot;in&quot;, [&quot;versicolor&quot;,&quot;virginica&quot;]), 
             (&quot;petal_width&quot;, &quot;&gt;&quot;, 2.4)]
iris6 = pandas.read_parquet(&quot;/tmp/iris&quot;, filters=selection)</code></pre>
<p>This works as well on the single file version</p>
<pre><code>iris7 = pandas.read_parquet(&quot;/tmp/iris.parquet&quot;, filters=selection)
# Change column type for the comparison
iris6[&quot;species&quot;] = iris6[&quot;species&quot;].astype(&quot;str&quot;)
iris7.equals(iris6)</code></pre>
<p>But if the query is only on the partition variable, read time can be
increased by a lot.</p>
</div>
<div
id="experiment-with-the-parquet-format-using-filters-and-partition-columns."
class="section level4">
<h4>Experiment with the parquet format using filters and partition
columns.</h4>
<p>Note the detaset to perform these comparisons is not made available
here. I keep these for information purposes.</p>
<p>Compare a read of 2 countries with the read of the whole dataset</p>
<pre><code># start_time = timeit.default_timer()
# selection = [(&quot;reporter&quot;, &quot;in&quot;, [&quot;France&quot;,&quot;Germany&quot;])]
# ft_frde = pandas.read_parquet(la_fo_data_dir / &quot;comtrade_forest_footprint.parquet&quot;,
#                                             filters=selection)
# print(&quot;Reading 2 countries took:&quot;,timeit.default_timer() - start_time)
#
# start_time = timeit.default_timer()
# ft2 = pandas.read_parquet(la_fo_data_dir / &quot;comtrade_forest_footprint.parquet&quot;)
# print(&quot;Reading the whole dataset took:&quot;,timeit.default_timer() - start_time)
#</code></pre>
<p>Time comparison when the reporter is used as a partition column It’s
about 10 times faster!</p>
<pre><code># ft.to_parquet(&quot;/tmp/ft&quot;, partition_cols=&quot;reporter&quot;)
# start_time = timeit.default_timer()
# selection = [(&quot;reporter&quot;, &quot;in&quot;, [&quot;France&quot;,&quot;Germany&quot;])]
# ft_frde2 = pandas.read_parquet(&quot;/tmp/ft&quot;, filters=selection)
# print(&quot;Reading 2 countries took:&quot;,timeit.default_timer() - start_time)
#
# # Save to a compressed csv file in biotrade_data
# # file_path = la_fo_data_dir / &quot;comtrade_forest_footprint.csv.gz&quot;
# # ft.to_csv(file_path, index=False, compression=&quot;gzip&quot;)</code></pre>
<p>Also try the feather format.</p>
<pre><code># # Save to a feather file
# ft.to_feather(la_fo_data_dir / &quot;comtrade_forest_footprint.feather&quot;)
#
# # Read time of a feather file
# start_time = timeit.default_timer()
# ft_frde2 = pandas.read_feather(la_fo_data_dir / &quot;comtrade_forest_footprint.feather&quot;)
# print(&quot;Reading a feather file took:&quot;,timeit.default_timer() - start_time)</code></pre>
</div>
<div id="what-is-the-difference-between-apache-arrow-and-apache-parquet"
class="section level4">
<h4>What is the difference between Apache Arrow and Apache Parquet?</h4>
<p><a
href="https://arrow.apache.org/faq/#what-about-the-feather-file-format">Apache
Arrow FAQ</a></p>
<blockquote>
<p>Parquet is a storage format designed for maximum space efficiency,
using advanced compression and encoding techniques. It is ideal when
wanting to minimize disk usage while storing gigabytes of data, or
perhaps more. This efficiency comes at the cost of relatively expensive
reading into memory, as Parquet data cannot be directly operated on but
must be decoded in large chunks.</p>
</blockquote>
<blockquote>
<p>Conversely, Arrow is an in-memory format meant for direct and
efficient use for computational purposes. Arrow data is not compressed
(or only lightly so, when using dictionary encoding) but laid out in
natural format for the CPU, so that data can be accessed at arbitrary
places at full speed.</p>
</blockquote>
<blockquote>
<p>Therefore, Arrow and Parquet complement each other and are commonly
used together in applications. Storing your data on disk using Parquet
and reading it into memory in the Arrow format will allow you to make
the most of your computing hardware.”</p>
</blockquote>
<blockquote>
<p>What about “Arrow files” then?</p>
</blockquote>
<blockquote>
<p>Apache Arrow defines an inter-process communication (IPC) mechanism
to transfer a collection of Arrow columnar arrays (called a “record
batch”). It can be used synchronously between processes using the Arrow
“stream format”, or asynchronously by first persisting data on storage
using the Arrow “file format”.</p>
</blockquote>
<blockquote>
<p>The Arrow IPC mechanism is based on the Arrow in-memory format, such
that there is no translation necessary between the on-disk
representation and the in-memory representation. Therefore, performing
analytics on an Arrow IPC file can use memory-mapping, avoiding any
deserialization cost and extra copies.</p>
</blockquote>
<blockquote>
<p>Some things to keep in mind when comparing the Arrow IPC file format
and the Parquet format:</p>
</blockquote>
<blockquote>
<pre><code>Parquet is designed for long-term storage and archival purposes, meaning
if you write a file today, you can expect that any system that says they
can “read Parquet” will be able to read the file in 5 years or 10 years.
While the Arrow on-disk format is stable and will be readable by future
versions of the libraries, it does not prioritize the requirements of
long-term archival storage.</code></pre>
</blockquote>
<blockquote>
<pre><code>Reading Parquet files generally requires efficient yet relatively complex
decoding, while reading Arrow IPC files does not involve any decoding
because the on-disk representation is the same as the in-memory
representation.</code></pre>
</blockquote>
<blockquote>
<pre><code>Parquet files are often much smaller than Arrow IPC files because of the
columnar data compression strategies that Parquet uses. If your disk
storage or network is slow, Parquet may be a better choice even for
short-term storage or caching.</code></pre>
</blockquote>
</div>
<div id="one-large-parquet-file-or-many-smaller-files"
class="section level4">
<h4>One large parquet file or many smaller files?</h4>
<p><a href="https://stackoverflow.com/a/59535659/2641825">Is it better
to have one large parquet file or lots of smaller parquet files?</a></p>
<blockquote>
<p>“Notice that Parquet files are internally split into row groups <a
href="https://parquet.apache.org/documentation/latest/"
class="uri">https://parquet.apache.org/documentation/latest/</a> So by
making parquet files larger, row groups can still be the same if your
baseline parquet files were not small/tiny. There is no huge direct
penalty on processing, but opposite, there are more opportunities for
readers to take advantage of perhaps larger/ more optimal row groups if
your parquet files were smaller/tiny for example as row groups can’t
span multiple parquet files.”</p>
</blockquote>
<blockquote>
<p>“Also larger parquet files don’t limit parallelism of readers, as
each parquet file can be broken up logically into multiple splits
(consisting of one or more row groups).”</p>
</blockquote>
<blockquote>
<p>“The only downside of larger parquet files is it takes more memory to
create them. So you can watch out if you need to bump up Spark
executors’ memory.”</p>
</blockquote>
</div>
<div id="see-also" class="section level4">
<h4>See also</h4>
<ul>
<li><p>It’s not possible to <a
href="https://stackoverflow.com/questions/50456673/storing-multiple-dataframes-of-different-widths-with-parquet">store
multiple data frames of different widths with parquet</a></p></li>
<li><p><a
href="https://stackoverflow.com/questions/59972588/control-row-groups-with-pandas-dataframe-to-parquet">Control
row groups size with pandas df.to_parquet</a></p></li>
<li><p><a
href="https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d">Benchmark
of feather, hdf, msgpack, parquet and pickle</a></p></li>
</ul>
</div>
</div>
</div>
<div id="reshape" class="section level2">
<h2>Reshape</h2>
<div id="from-wide-to-long" class="section level3">
<h3>From wide to long</h3>
<p><a
href="https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#reshaping-by-melt">The
Pandas user guide on reshaping</a> gives several example using
<code>melt</code> (easier to rename the “variable” and “value” columns)
or <code>stack</code> (designed to work together with MultiIndex
objects).</p>
<p>Reshape using <code>melt</code></p>
<pre><code>cheese = pandas.DataFrame(
      {
          &quot;first&quot;: [&quot;John&quot;, &quot;Mary&quot;],
          &quot;last&quot;: [&quot;Doe&quot;, &quot;Bo&quot;],
          &quot;height&quot;: [5.5, 6.0],
          &quot;weight&quot;: [130, 150],
      }
)
cheese
cheese.melt(id_vars=[&quot;first&quot;, &quot;last&quot;], var_name=&quot;quantity&quot;)</code></pre>
<p>Reshape using the <code>wide_to_long</code> convenience function</p>
<pre><code>import numpy as np
dft = pandas.DataFrame(
    {
        &quot;A1970&quot;: {0: &quot;a&quot;, 1: &quot;b&quot;, 2: &quot;c&quot;},
        &quot;A1980&quot;: {0: &quot;d&quot;, 1: &quot;e&quot;, 2: &quot;f&quot;},
        &quot;B1970&quot;: {0: 2.5, 1: 1.2, 2: 0.7},
        &quot;B1980&quot;: {0: 3.2, 1: 1.3, 2: 0.1},
        &quot;X&quot;: dict(zip(range(3), np.random.randn(3))),
        &quot;id&quot;:  {0: 0, 1: 1, 2: 2},
    }
)
dft
pandas.wide_to_long(dft, stubnames=[&quot;A&quot;, &quot;B&quot;], i=&quot;id&quot;, j=&quot;year&quot;)</code></pre>
</div>
<div id="from-long-to-wide" class="section level3">
<h3>From long to wide</h3>
<p>Pivot from long to wide format using <code>pivot</code>:</p>
<pre><code>df = pandas.DataFrame({
    &quot;lev1&quot;: [1, 1, 1, 2, 2, 2],
    &quot;lev2&quot;: [1, 1, 2, 1, 1, 2],
    &quot;lev3&quot;: [1, 2, 1, 2, 1, 2],
    &quot;lev4&quot;: [1, 2, 3, 4, 5, 6],
    &quot;values&quot;: [0, 1, 2, 3, 4, 5]})
df_wide = df.pivot(index=&quot;lev1&quot;, columns=[&quot;lev2&quot;, &quot;lev3&quot;], values=&quot;values&quot;)
df_wide

# lev2    1         2
# lev3    1    2    1    2
# lev1
# 1     0.0  1.0  2.0  NaN
# 2     4.0  3.0  NaN  5.0</code></pre>
<p>Rename the (sometimes confusing) axis names</p>
<pre><code>df_wide.rename_axis(columns=[None, None])

#         1         2
#         1    2    1    2
# lev1
# 1     0.0  1.0  2.0  NaN
# 2     4.0  3.0  NaN  5.0</code></pre>
</div>
</div>
<div id="replace" class="section level2">
<h2>Replace</h2>
<p><a
href="https://stackoverflow.com/questions/12152716/python-pandas-equivalent-for-replace">Python
pandas equivalent for replace</a></p>
<pre><code>import pandas
s = pandas.Series([&quot;ape&quot;, &quot;monkey&quot;, &quot;seagull&quot;])
s.replace([&quot;ape&quot;, &quot;monkey&quot;], [&quot;lion&quot;, &quot;panda&quot;])
s.replace(&quot;a&quot;, &quot;x&quot;, regex=True)
`s.replace({&quot;ape&quot;: &quot;lion&quot;, &quot;monkey&quot;: &quot;panda&quot;})`
pandas.Series([&quot;bla&quot;, &quot;bla&quot;]).replace(&quot;a&quot;,&quot;i&quot;,regex=True)</code></pre>
<div id="replace-values-where-a-condition-is-false"
class="section level3">
<h3>Replace values where a condition is false</h3>
<p>Replace values where the condition is false see
<code>help(df.where)</code></p>
<blockquote>
<p>“Where <code>cond</code> is True, keep the original value. Where
False, replace with corresponding value from <code>other</code>.”</p>
</blockquote>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:range(0,3), 
                       &#39;b&#39;:[&#39;p&#39;,&#39;q&#39;,&#39;r&#39;], 
                       &#39;c&#39;:[&#39;m&#39;,&#39;n&#39;,&#39;o&#39;]})
df[&quot;b&quot;].where(df[&quot;c&quot;].isin([&quot;n&quot;,&quot;o&quot;]),&quot;no&quot;)
df.where(df[&quot;c&quot;].isin([&quot;n&quot;,&quot;o&quot;]),&quot;no&quot;)</code></pre>
</div>
<div id="fill-na-values" class="section level3">
<h3>Fill Na values</h3>
<p>Replace NA values by another value</p>
<pre><code>import pandas
import numpy as np
df = pandas.DataFrame([[np.nan, 2, np.nan, 0],
                  [3, 4, np.nan, 1],
                  [np.nan, np.nan, np.nan, 5],
                  [np.nan, 3, np.nan, 4]],
                 columns=list(&quot;ABCD&quot;))
# Replace all NaN elements with 0s.
df.fillna(0)
# Replace by 0 and column 2 and by 1 in column B
df.fillna({&quot;A&quot;:0, &quot;B&quot;:1}, inplace=True)
df</code></pre>
</div>
</div>
<div id="select-with-loc-iloc-query-isin-and-xs" class="section level2">
<h2>Select with loc, iloc, query, isin and xs</h2>
<ul>
<li>blog <a
href="https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/">Select
pandas data frame rows and columns using iloc and loc</a></li>
</ul>
<div id="loc" class="section level3">
<h3>loc</h3>
<p><code>.loc</code> is primarily label based, but may also be used with
a boolean array.</p>
<p>I copied the examples below from the pandas <strong>loc</strong>
documentation at: <a
href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html">pandas.DataFrame.loc</a></p>
<p>Create an example data frame</p>
<pre><code>import pandas
df = pandas.DataFrame([[1, 2], [4, 5], [7, 8]],
                      index=[&#39;cobra&#39;, &#39;viper&#39;, &#39;sidewinder&#39;],
                      columns=[&#39;max_speed&#39;, &#39;shield&#39;])</code></pre>
<p>List of index labels</p>
<pre><code>In :  df.loc[[&#39;viper&#39;, &#39;sidewinder&#39;]]
Out:
                    max_speed  shield
        viper               4       5
        sidewinder          7       8</code></pre>
<p>Selecting a cell with 2 lists returns a data frame</p>
<pre><code>df.loc[[&quot;viper&quot;], [&quot;shield&quot;]]</code></pre>
<p>Selecting cell with tuples (for multi indexes) or strings returns its
value</p>
<pre><code>df.loc[(&quot;viper&quot;), (&quot;shield&quot;)]
df.loc[&quot;viper&quot;, &quot;shield&quot;]</code></pre>
<p>Note: in the case of a multi index, use tuples for index selection,
see section below on multi index selection with loc.</p>
<p>Conditional that returns a boolean Series</p>
<pre><code>In :  df.loc[df[&#39;shield&#39;] &gt; 6]
Out:
                     max_speed  shield
         sidewinder          7       8</code></pre>
<p>Slice with labels for row and labels for columns.</p>
<pre><code>In :  df.loc[&#39;cobra&#39;:&#39;viper&#39;, &#39;max_speed&#39;:&#39;shield&#39;]
Out:
               max_speed  shield
        cobra          1       2
        viper          4       5</code></pre>
<p>Set value for all items matching the list of labels</p>
<pre><code>In : df.loc[[&#39;viper&#39;, &#39;sidewinder&#39;], [&#39;shield&#39;]] = 50

In : df
Out:
                    max_speed  shield
        cobra               1       2
        viper               4      50
        sidewinder          7      50</code></pre>
<p>Another example using integers for the index</p>
<pre><code>df2 = pandas.DataFrame([[1, 2], [4, 5], [7, 8]],
                      index=[7, 8, 9],
                      columns=[&#39;max_speed&#39;, &#39;shield&#39;])</code></pre>
<p>Slice with integer labels for rows. Note that <strong>both the start
and stop of the slice</strong> are included. Python slices behave
differently.</p>
<pre><code>In :  df2.loc[8:9]
Out:
      max_speed  shield
   8          4       5
   9          7       8</code></pre>
<div id="index.isin" class="section level4">
<h4>index.isin()</h4>
<p>Using the same example as above, select rows that are not in
[‘cobra’,‘viper’]. Based on a <a
href="https://stackoverflow.com/a/29140194/2641825">SO answer use isin
on the index</a>:</p>
<pre><code>In : df.index.isin([&#39;cobra&#39;,&#39;viper&#39;])
Out: array([ True,  True, False])

In : df.loc[~df.index.isin([&#39;cobra&#39;,&#39;viper&#39;])]
Out: 
            max_speed  shield
sidewinder          7       8</code></pre>
<p>Or assign the selector to reuse it:</p>
<pre><code>selector = df.index.isin([&#39;cobra&#39;,&#39;viper&#39;])
df.loc[selector]
df.loc[~selector]</code></pre>
</div>
<div id="multiple-conditions" class="section level4">
<h4>Multiple conditions</h4>
<pre><code>import pandas
df = pandas.DataFrame([[1, 2], [4, 5], [7, 8]],
                      index=[&#39;cobra&#39;, &#39;viper&#39;, &#39;sidewinder&#39;],
                      columns=[&#39;max_speed&#39;, &#39;shield&#39;])
df.loc[(df[&quot;max_speed&quot;] &gt; 1) &amp; (df[&quot;shield&quot;] &lt; 7)]
df.query(&quot;max_speed &gt; 1 &amp; shield &lt; 7&quot;)</code></pre>
</div>
<div id="multi-index-selection-with-loc" class="section level4">
<h4>Multi-index selection with loc</h4>
<p>Create a panel data set with a multi index in years and countries</p>
<pre><code>import pandas
import numpy as np
df = pandas.DataFrame(
    {&quot;country&quot;: [&#39;Algeria&#39;, &#39;Angola&#39;, &#39;Benin&#39;, &#39;Botswana&#39;, &#39;Burkina Faso&#39;] * 2,
     &quot;year&quot;: np.repeat(np.array([2020,2021]), 5),
     &quot;value&quot;:  np.random.randint(0,1e3,10)
     })
df = df.set_index([&quot;year&quot;, &quot;country&quot;])
      </code></pre>
<p>See also the course material <a
href="https://python.quantecon.org/pandas_panel.html">Pandas for panel
data</a>.</p>
<p>Sample data copied from <code>help(df.loc)</code>:</p>
<pre><code>tuples = [
   (&#39;cobra&#39;, &#39;mark i&#39;), (&#39;cobra&#39;, &#39;mark ii&#39;),
   (&#39;sidewinder&#39;, &#39;mark i&#39;), (&#39;sidewinder&#39;, &#39;mark ii&#39;),
   (&#39;viper&#39;, &#39;mark ii&#39;), (&#39;viper&#39;, &#39;mark iii&#39;)
]
index = pandas.MultiIndex.from_tuples(tuples)
values = [[12, 2], [0, 4], [10, 20],
        [1, 4], [7, 1], [16, 36]]
df = pandas.DataFrame(values, columns=[&#39;max_speed&#39;, &#39;shield&#39;], index=index)</code></pre>
<p>Single label. Note this returns a DataFrame with a single index.</p>
<pre><code>df.loc[&#39;cobra&#39;]</code></pre>
<p>Single index tuple. Note this returns a Series.</p>
<pre><code>df.loc[(&#39;cobra&#39;, &#39;mark ii&#39;)]
df.loc[(:,&#39;mark ii&#39;)]</code></pre>
<p>Single tuple. Note using <code>[[]]</code> returns a DataFrame.</p>
<pre><code>df.loc[[(&#39;cobra&#39;, &#39;mark ii&#39;)]]</code></pre>
<p>Single label for row and column. Similar to passing in a tuple, this
returns a Series.</p>
<pre><code>df.loc[&#39;cobra&#39;, &#39;mark i&#39;]</code></pre>
<p>Slice from index tuple to single label</p>
<pre><code>df.loc[(&#39;cobra&#39;, &#39;mark i&#39;):&#39;viper&#39;]</code></pre>
<p>Slice from index tuple to index tuple</p>
<pre><code>df.loc[(&#39;cobra&#39;, &#39;mark i&#39;):(&#39;viper&#39;, &#39;mark ii&#39;)]</code></pre>
<p>Invert a selection on the second index</p>
<pre><code>df.loc[~df.index.isin([&quot;mark i&quot;], level=1)]</code></pre>
</div>
<div id="multi-index-slicers" class="section level4">
<h4>Multi-index slicers</h4>
<p><a href="https://stackoverflow.com/a/50414126/2641825">Using loc on
just the second index in multi index</a> Using the same data frame as
above.</p>
<pre><code>idx = pandas.IndexSlice
df.loc[idx[:, &quot;mark i&quot;],:]
df.xs(&quot;mark i&quot;, level=1)</code></pre>
</div>
</div>
<div id="iloc" class="section level3">
<h3>iloc</h3>
<p><a
href="https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-integer">.iloc</a>
is primarily integer position based (from 0 to length -1 of the axis),
but may also be used with a boolean array.</p>
<p>Create a sample data frame:</p>
<pre><code>In : example = [{&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3, &#39;d&#39;: 4},
                {&#39;a&#39;: 100, &#39;b&#39;: 200, &#39;c&#39;: 300, &#39;d&#39;: 400},
                {&#39;a&#39;: 1000, &#39;b&#39;: 2000, &#39;c&#39;: 3000, &#39;d&#39;: 4000 }]
      df = pandas.DataFrame(example)

In : df
Out: 
            a     b     c     d
      0     1     2     3     4
      1   100   200   300   400
      2  1000  2000  3000  4000</code></pre>
<p>Index with a slice object. Note that it doesn’t include the upper
bound.</p>
<pre><code>In :  df.iloc[0:2]
Out: 
          a    b    c    d
     0    1    2    3    4
     1  100  200  300  400</code></pre>
<p>With lists of integers.</p>
<pre><code>In : df.iloc[[0, 2], [1, 3]]
Out: 
            b     d
      0     2     4
      2  2000  4000</code></pre>
<p>With slice objects.</p>
<pre><code>In : df.iloc[1:3, 0:3]
Out: 
            a     b     c
      1   100   200   300
      2  1000  2000  3000</code></pre>
<p>With a boolean array whose length matches the columns.</p>
<pre><code>In : df.iloc[:, [True, False, True, False]]
Out: 
            a     c
      0     1     3
      1   100   300
      2  1000  3000</code></pre>
</div>
<div id="query" class="section level3">
<h3>Query</h3>
<p>Query the columns of a Data Frame with a boolean expression.</p>
<pre><code>df = pandas.DataFrame({&#39;A&#39;: range(1, 6),
                       &#39;B&#39;: range(10, 0, -2),
                       &#39;C&#39;: range(10, 5, -1)})
df.query(&quot;A &gt; B&quot;)

A  B  C
5  2  6</code></pre>
<p>Two queries</p>
<pre><code>df.query(&quot;A &lt; B and B &lt; C&quot;)
df.query(&quot;A &lt; B or B &lt; C&quot;)</code></pre>
<p>Query using a variable</p>
<pre><code>limit = 3
df.query(&quot;A &gt; @limit&quot;)

A  B  C
4  4  7
5  2  6</code></pre>
<p>Query for a variable in a list</p>
<pre><code>df.query(&quot;A in [3,6]&quot;)</code></pre>
<div id="str.contains-and-str.startswith" class="section level4">
<h4>str.contains and str.startswith</h4>
<p>str.contains and str.startswith do not work with the default numexpre
engine, you need to set <code>engine="python"</code> as explained in <a
href="https://stackoverflow.com/a/51375487/2641825">this answer</a>.</p>
<p>Example use on a table of product codes, query products description
that contain “oak” but not “cloak” and query sawnwood products starting
with “4407”:</p>
<pre><code>comtrade.products.hs.query(&quot;product_description.str.contains(&#39;oak&#39;) and not product_description.str.contains(&#39;cloak&#39;)&quot;, engine=&quot;python&quot;)
comtrade.products.hs.query(&quot;product_code.str.startswith(&#39;4407&#39;)&quot;, engine=&quot;python&quot;)</code></pre>
</div>
</div>
<div id="isin" class="section level3">
<h3>isin</h3>
<p><a
href="https://stackoverflow.com/questions/12096252/use-a-list-of-values-to-select-rows-from-a-pandas-dataframe">Use
alist of values to select rows</a></p>
<pre><code>df = pandas.DataFrame({&#39;A&#39;: [5,6,3,4], &#39;B&#39;: [1,2,3,5]})
df[df[&#39;A&#39;].isin([3, 6])]
df.loc[df[&#39;A&#39;].isin([3, 6])]
df.query(&quot;A in [3,6]&quot;)</code></pre>
</div>
<div id="xs-cross-sections" class="section level3">
<h3>xs cross sections</h3>
<p>The <code>key</code> and <code>level</code> arguments specify which
part of the multilevel index should be used. Create a sample data frame,
copied from <code>help(df.xs)</code>:</p>
<pre><code>d = {&#39;num_legs&#39;: [4, 4, 2, 2],
     &#39;num_wings&#39;: [0, 0, 2, 2],
     &#39;class&#39;: [&#39;mammal&#39;, &#39;mammal&#39;, &#39;mammal&#39;, &#39;bird&#39;],
     &#39;animal&#39;: [&#39;cat&#39;, &#39;dog&#39;, &#39;bat&#39;, &#39;penguin&#39;],
     &#39;locomotion&#39;: [&#39;walks&#39;, &#39;walks&#39;, &#39;flies&#39;, &#39;walks&#39;]}
df = pandas.DataFrame(data=d)
df = df.set_index([&#39;class&#39;, &#39;animal&#39;, &#39;locomotion&#39;])
print(df)</code></pre>
<p>Select with a key following the order in which levels appear in the
index:</p>
<pre><code>df.xs(&#39;mammal&#39;)
df.xs((&#39;mammal&#39;, &#39;dog&#39;))</code></pre>
<p>Select with a key and specify the levels:</p>
<pre><code>df.xs(key=&#39;cat&#39;, level=1)
df.xs(key=(&#39;bird&#39;, &#39;walks&#39;),
      level=[0, &#39;locomotion&#39;])</code></pre>
<p>Pandas <a
href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html">DataFrame.xs</a>
“cannot be used to set values.”</p>
</div>
<div id="determine-whether-a-column-contains-a-particular-value"
class="section level3">
<h3>Determine whether a column contains a particular value</h3>
<p><a
href="https://stackoverflow.com/questions/21319929/how-to-determine-whether-a-pandas-column-contains-a-particular-value">How
to determine whether a pandas column contains a particular
varlue</a></p>
<blockquote>
<p>In of a Series checks whether the value is in the index:</p>
</blockquote>
<pre><code>In : s = pd.Series(list(&#39;abc&#39;))
In : 1 in s
Out: True
In : &#39;a&#39; in s
Out: False</code></pre>
<blockquote>
<p>One option is to see if it’s in unique values:</p>
</blockquote>
<pre><code>In : &#39;a&#39; in s.unique()
Out: True</code></pre>
</div>
</div>
<div id="sort-or-arrange-values" class="section level2">
<h2>Sort or arrange values</h2>
<p>Sort iris by descending order of species and ascending order of petal
width</p>
<pre><code>iris.sort_values(by=[&quot;species&quot;, &quot;petal_width&quot;], ascending=[False,True])</code></pre>
</div>
<div id="string-operations-in-pandas" class="section level2">
<h2>String operations in pandas</h2>
<p>See also string operations in python in another section.</p>
<p>String operations in pandas use vectorized string methods of the
class StringMethods(pandas.core.base.NoNewAttributesMixin).</p>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})
help(df.a.str)</code></pre>
<p>Concatenate all values in a character vector:</p>
<pre><code>df[&#39;a&#39;].str.cat()</code></pre>
<p>Replace elements in a character vector:</p>
<pre><code>df[&#39;a&#39;].replace(&#39;a&#39;,&#39;b&#39;,regex=True)</code></pre>
<p>Extract the first 2 or last 2 characters</p>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:[&#39;bla&#39;,&#39;bli&#39;,&#39;quoi?&#39;]})
df[&quot;a&quot;].str[:2]
df[&quot;a&quot;].str[-2:]</code></pre>
<div id="separate-a-columns-in-two-based-on-a-split-pattern"
class="section level3">
<h3>Separate a columns in two based on a split pattern</h3>
<p>The “too many values to unpack” error can also be returned by the
<code>str.split</code> method of pandas data frames.</p>
<p>For example splitting a character vector on the “<code>,</code>”
pattern:</p>
<pre><code>import pandas
df = pandas.DataFrame({&quot;x&quot;: [&quot;a&quot;, &quot;a, b&quot;, &quot;a,b,c&quot;]})
df.x.str.split(&quot;,&quot;)

# 0          [a]
# 1      [a,  b]
# 2    [a, b, c]

df.x.str.split(&quot;,&quot;, n=1)

# 0         [a]
# 1     [a,  b]
# 2    [a, b,c]

df.x.str.split(&quot;,&quot;, expand=True)

#    0     1     2
# 0  a  None  None
# 1  a     b  None
# 2  a     b     c

df.x.str.split(&quot;,&quot;, n=1, expand=True)

#    0     1
# 0  a  None
# 1  a     b
# 2  a   b,c</code></pre>
<p>The following version works only if each row has exactly 2 splits. It
<strong>fails</strong> with the <strong>error</strong> “too many values
to unpack (expected 2)” in this example:</p>
<pre><code>df[&quot;y&quot;], df[&quot;z&quot;] = df.x.str.split(&quot;,&quot;, n=1)</code></pre>
<p>The last version with both <code>n=1</code> and
<code>expand=True</code> is the one to use for multiple vector
assignment. It is equivalent to <a
href="https://tidyr.tidyverse.org/reference/separate.html">tidyr::separate</a>
in R.</p>
<pre><code>df[[&quot;y&quot;, &quot;z&quot;]] = df.x.str.split(&quot;,&quot;, n=1, expand=True)
df

#        x  y     z
# 0      a  a  None
# 1   a, b  a     b
# 2  a,b,c  a   b,c</code></pre>
<p>According to the <a
href="https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html">documentation
of pandas.Series.str.split</a> If n &gt; 0 and</p>
<blockquote>
<p>“If for a certain row the number of found splits &lt; n, append None
for padding up to n if expand=True.”</p>
</blockquote>
</div>
<div id="extract-columns-based-on-a-pattern" class="section level3">
<h3>Extract columns based on a pattern</h3>
<p>Place product patterns in a capture group for extraction</p>
<pre><code>df = pandas.DataFrame({&quot;x&quot;: [&quot;am&quot;, &quot;an&quot;, &quot;o&quot;, &quot;bm&quot;, &quot;bn&quot;, &quot;cm&quot;]})
product_pattern = &quot;a|b|c&quot;
df[[&quot;product&quot;, &quot;element&quot;]] = df.x.str.extract(f&quot;({product_pattern})?(.*)&quot;)
df</code></pre>
</div>
</div>
<div id="difference-between-2-data-frames" class="section level2">
<h2>Difference between 2 data frames</h2>
<ul>
<li><a
href="https://stackoverflow.com/questions/48647534/python-pandas-find-difference-between-two-data-frames">Find
difference between two data frames</a></li>
<li><a
href="https://stackoverflow.com/questions/36891977/pandas-diff-of-two-dataframes/36893773">Diff
of 2 data frames</a></li>
</ul>
<p>Two methods Using <code>merge</code>:</p>
<pre><code>merged = df1.merge(df2, indicator=True, how=&#39;outer&#39;)
merged[merged[&#39;_merge&#39;] == &#39;right_only&#39;]</code></pre>
<p>Using <code>drop_duplicates</code></p>
<pre><code>newdf=pd.concat[df1,df2].drop_duplicates(keep=False)</code></pre>
</div>
<div id="duplicated-values" class="section level2">
<h2>Duplicated values</h2>
<p>Warn in case the variable x is duplicated</p>
<pre><code>import pandas
df = pandas.DataFrame({&quot;x&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;], &quot;y&quot;: range(4)})
dup_x = df[&quot;x&quot;].duplicated(keep=False)
if any(dup_x):
    msg = &quot;x values are not unique. &quot;
    msg += &quot;The following duplicates are present:\n&quot;
    msg += f&quot;{df.loc[dup_x]}&quot;
    raise ValueError(msg)</code></pre>
<p>Drop duplicates</p>
<pre><code>df[&quot;x&quot;].drop_duplicates()
df[&quot;x&quot;].drop_duplicates(keep=False)
df[&quot;x&quot;].drop_duplicates(keep=&quot;last&quot;)</code></pre>
</div>
<div id="where-and-mask" class="section level2">
<h2>Where and mask</h2>
<p><code>where</code> replaces values that do not fit the condition and
<code>mask</code> replaces values that fit the condition.</p>
<pre><code>s = pandas.Series(range(5))
s.where(s &gt; 1, 10)
s.mask(s &gt; 1, 10)</code></pre>
<p>On a data frame</p>
<pre><code>import pandas
import numpy as np
df1 = pandas.DataFrame({&#39;x&#39;:[0,np.nan, np.nan], 
                        &#39;y&#39;:[&#39;a&#39;,np.nan,&#39;c&#39;]})
df2 = pandas.DataFrame({&#39;x&#39;:[10, 11, 12], 
                        &#39;y&#39;:[&#39;x&#39;,&#39;y&#39;, np.nan]})
df1.mask(df1.isna(), df2)
df1.where(df1.isna(), df2)</code></pre>
</div>
<div id="xarray" class="section level2">
<h2>Xarray</h2>
<ul>
<li><a
href="https://stackoverflow.com/questions/35422862/speeding-up-reading-of-very-large-netcdf-file-in-python">How
to read netcdf files in chunks with Xarray and Dask</a></li>
</ul>
</div>
</div>
<div id="paths" class="section level1">
<h1>Paths</h1>
<div id="pathlib" class="section level2">
<h2>Pathlib</h2>
<p>Pathlib is an object oriented path API for python as explained in <a
href="https://www.python.org/dev/peps/pep-0428/#why-an-object-oriented-api">PEP
428</a></p>
<p>Instead of</p>
<pre><code>import os
os.path.join(&#39;~&#39;,&#39;downloads&#39;)</code></pre>
<p>You can use:</p>
<pre><code>from pathlib import Path
Path(&#39;~&#39;) / &#39;downloads&#39;</code></pre>
<p>Data located in the home folder</p>
<pre><code> data_dir = Path.home() / &quot;repos/data/&quot;</code></pre>
<div id="dir-name-or-parent-directory" class="section level3">
<h3>Dir name or parent directory</h3>
<p><a href="https://stackoverflow.com/a/35490226/2641825">SO
question</a> that illustrate different levels of parents</p>
<pre><code>import os
import pathlib
p = pathlib.Path(&#39;/path/to/my/file&#39;)
p.parents[0]
p.parents[1]
p.parent</code></pre>
<blockquote>
<p>“Note that os.path.dirname and pathlib treat paths with a trailing
slash differently. The pathlib parent of some/path/ is some: While
os.path.dirname on some/path/ returns some/path”:</p>
</blockquote>
<pre><code>pathlib.Path(&#39;some/path/&#39;).parent
os.path.dirname(&#39;some/path/&#39;)</code></pre>
</div>
<div id="list-all-files-in-a-directory" class="section level3">
<h3>List all files in a directory</h3>
<p>If <code>p</code> is a pathlib object you can list file names as
such:</p>
<pre><code>[x.name for x in p.glob(&#39;**/*.csv&#39;)]</code></pre>
</div>
<div id="check-if-a-directory-is-empty" class="section level3">
<h3>Check if a directory is empty</h3>
<p>Check if a directory is empty using pathlib</p>
<pre><code>import pathlib
p1 = pathlib.Path(&quot;/tmp/&quot;)
p2 = pathlib.Path(&quot;/tmp/thisisempty/&quot;)
p2.mkdir()
any(p1.iterdir()) # returns True
any(p2.iterdir()) # returns False</code></pre>
</div>
</div>
<div id="temporary-directories-and-files" class="section level2">
<h2>Temporary directories and files</h2>
<p>Docs.python.org <a
href="https://docs.python.org/3/library/tempfile.html#examples">tempfile
examples</a> using a context manager</p>
<pre><code>import tempfile
# create a temporary directory using the context manager
with tempfile.TemporaryDirectory() as tmpdirname:
    print(&#39;created temporary directory&#39;, tmpdirname)
# directory and contents have been removed</code></pre>
<p>Using <code>pathlib</code> to facilitate path manipulation on top of
<code>tempfile</code> makes it possible to create new paths using the
<code>/</code> path operator of pathlib:</p>
<pre><code>import tempfile
from pathlib import Path
with tempfile.TemporaryDirectory() as tmpdirname:
    temp_dir = Path(tmpdirname)
    print(temp_dir, temp_dir.exists())
    file_name = temp_dir / &quot;test.txt&quot;
    file_name.write_text(&quot;bla bla bla&quot;)
    print(file_name, &quot;contains&quot;, file_name.open().read())</code></pre>
<p>Outside the context manager, files have been destroyed</p>
<pre><code>print(temp_dir, temp_dir.exists())
# /tmp/tmp81iox6s2 False
print(file_name, file_name.exists())
# /tmp/tmp81iox6s2/test.txt False</code></pre>
</div>
</div>
<div id="plot" class="section level1">
<h1>Plot</h1>
<p><a href="https://pythonplot.com/">Python plotting for exploratory
analysis</a> is a great gallery of plot examples, each example is
written in 5 different plotting libraries: pandas, plotnine, plotly,
altair and R ggplot2. There is also one seaborn example.</p>
<div id="matplotlib" class="section level2">
<h2>Matplotlib</h2>
<p>All matplotlib examples require the following imports:</p>
<pre><code>from matplotlib import pyplot as plt
plt.style.use(&#39;seaborn-whitegrid&#39;)
import numpy as np</code></pre>
<p>Simple line plot changing the figure size and the axes limit with
pyplot</p>
<pre><code>plt.rcParams[&#39;figure.figsize&#39;] = [10, 10]
fig = plt.figure()
ax = plt.axes()
x = np.linspace(-1.5, 1.5, 1000)
ax.plot(x, 1-3*x)
ax.set_xlim(-6, 6)
ax.set_ylim(-6, 6)</code></pre>
<p>Scatter plot, using a colour variable and the ‘jet’ colour map.</p>
<pre><code>Y = np.array([1,-1,-1, 1])
X = np.array([
        [-1, -1],
        [ 1, -1],
        [-1,  1],
        [ 1,  1]])
fig = plt.figure()
ax = plt.axes()
ax.scatter(X[:,0], X[:,1],c=Y, cmap=&#39;jet&#39;)</code></pre>
<p>Use another <a
href="https://matplotlib.org/examples/color/colormaps_reference.html">colour
map</a></p>
<pre><code>ax.scatter(X[:,0], X[:,1],c=Y, cmap=&#39;Spectral&#39;)</code></pre>
<p>Plot the probability density function of the <a
href="https://en.wikipedia.org/wiki/Normal_distribution">normal
distribution</a>.</p>
<p><span class="math display">\[f(x)=\frac{1}{\sigma{\sqrt {2\pi
}}}e^{-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma
}}\right)^{2}}\]</span></p>
<p>With various sigma and mu values displayed in the legend.</p>
<pre><code>fig = plt.figure()
ax = plt.axes()
x = np.linspace(-5, 5, 1000)
def pdensitynormal(x,sigma_squared,mu):
    sigma = np.sqrt(sigma_squared)
    return 1/(sigma*np.sqrt(2*np.math.pi))*np.exp(-1/2*((x-mu)/sigma)**2)
ax.plot(x, pdensitynormal(x,0.2,0), label=&quot;$\sigma^2=0.2, \mu=0$&quot;)
ax.plot(x, pdensitynormal(x,1,0), label=&quot;$\sigma^2=1, \mu=0$&quot;)
ax.plot(x, pdensitynormal(x,5,0), label=&quot;$\sigma^2=5, \mu=0$&quot;)
ax.plot(x, pdensitynormal(x,0.5,-2), label=&quot;$\sigma^2=0.5, \mu=-2$&quot;)
ax.legend(loc=&quot;upper right&quot;)
plt.show()</code></pre>
<p>3D line, contour plot and scatter plot</p>
<pre><code>from mpl_toolkits import mplot3d # Required for 3d plots
fig = plt.figure()
ax = plt.axes(projection=&#39;3d&#39;)
# Data for a three-dimensional line
xline = np.linspace(-10, 10, 1000)
yline = np.linspace(-10, 10, 1000)
# Just a line
zline = xline**2 + yline**2
ax.plot3D(xline, yline, zline, &#39;gray&#39;)
# A mesh grid
X, Y = np.meshgrid(xline, yline)
Z = X**2 + Y**2
ax.contour3D(X, Y, Z, 50, cmap=&#39;binary&#39;)
# Scatter points
ax.scatter(1,2,3)</code></pre>
<p>See how the <code>np.meshgridi</code> objects interact with each
other. Note this nested loop is not the optimal way to compute. Better
to use X<strong>2 + Y</strong>2 directly as above.</p>
<pre><code>for i in range(Z.shape[0]):
    for j in range(Z.shape[1]):
        vector = np.array([X[i,j],Y[i,j]])
            Z[i,j] = np.linalg.norm(vector)**2
fig = plt.figure()
ax = plt.axes(projection=&#39;3d&#39;)
ax.contour3D(X, Y, Z, 50, cmap=&#39;binary&#39;)</code></pre>
<div id="pandas-plots-are-matplotlib-axessubplot-objects"
class="section level3">
<h3>Pandas plots are matplotlib AxesSubplot objects</h3>
<div id="show-pandas-plots-in-ipython" class="section level4">
<h4>Show pandas plots in ipython</h4>
<p>Create some data and change the xticks labels</p>
<pre><code>import pandas
import matplotlib.pyplot as plt
df = pandas.DataFrame({&#39;x&#39;:range(0,30), &#39;y&#39;:range(10,40)})
df.set_index(&#39;x&#39;, inplace=True)
plot = df.plot(title=&#39;Two ranges&#39;)
type(plot)
#help(plot)
plot.set_xticks(range(0,31,10), minor=False)
plt.show()</code></pre>
<p>Save the figure to a pdf file:</p>
<pre><code>plot.get_figure().savefig(&#39;/tmp/output.pdf&#39;, format=&#39;pdf&#39;)</code></pre>
</div>
<div id="pandas-plots-side-by-side" class="section level4">
<h4>Pandas plots side by side</h4>
<p>Using the same df as above show 2 plost side by side based on this <a
href="https://stackoverflow.com/a/68008119/2641825">SO answer</a></p>
<pre><code>fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,6))
df.plot(title=&#39;Two ranges&#39;, ax=ax1)
df.plot(title=&#39;Two ranges&#39;, ax=ax2)
plt.show()</code></pre>
</div>
</div>
</div>
<div id="plotly" class="section level2">
<h2>Plotly</h2>
<p>The advantage of plotly is that it provides dynamic visualisation
inside web pages, such as the possibility to zoom in a graph. It’s the
open source component of a commercial project called Dash
entreprise.</p>
<p>For example <a
href="https://colab.research.google.com/github/bytehub-ai/blog-examples/blob/master/temperature_forecast_example.ipynb#scrollTo=7yJZA1CZSSx4">this
notebook</a> on machine learning used to enhance the localisation of
weather forecasts. Seen on this blog post <a
href="https://medium.com/bytehub-ai/what-does-machine-learning-have-to-do-with-weather-94f3ac625ad3">What
does machine learning have to do with weather</a>.</p>
</div>
<div id="plotnine" class="section level2">
<h2>Plotnine</h2>
<p>Grammar of graphics for python <a
href="https://github.com/has2k1/plotnine"
class="uri">https://github.com/has2k1/plotnine</a></p>
<div id="figure-size" class="section level3">
<h3>Figure size</h3>
<p>Change the <a
href="https://plotnine.readthedocs.io/en/stable/generated/plotnine.options.figure_size.html">plotnine
figure size</a></p>
<pre><code>import plotnine
plotnine.options.figure_size = (12, 8)</code></pre>
</div>
<div id="facet-grid" class="section level3">
<h3>Facet grid</h3>
<p>Create a facet grid plot</p>
<pre><code>from plotnine import ggplot, aes, geom_line, facet_grid, labs</code></pre>
</div>
</div>
<div id="seaborn" class="section level2">
<h2>Seaborn</h2>
<p>All Seaborn examples below require the following imports and
datasets:</p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
tips = seaborn.load_dataset(&quot;tips&quot;) 
from matplotlib import pyplot as plt</code></pre>
<div id="scatter-plot" class="section level3">
<h3>Scatter plot</h3>
<p>Create a scatter plot with a title and axis labels</p>
<pre><code>p = seaborn.scatterplot(&#39;petal_length&#39;,&#39;petal_width&#39;,&#39;species&#39;,data=iris)
p.set(xlabel = &quot;Petal Length&quot;, ylabel = &quot;Petal Width&quot;, title = &quot;Flower sizes&quot;)
plt.show()</code></pre>
</div>
<div id="line-plot" class="section level3">
<h3>Line plot</h3>
<p>Create a line plot with a title and axis labels.</p>
<pre><code>import numpy as np
df = pandas.DataFrame({&#39;value&#39;:np.random.random(100), 
                       &#39;year&#39;:range(1901,2001)})
p = seaborn.lineplot(x=&quot;year&quot;, y=&quot;value&quot;, data=df)
p.set(ylabel = &quot;Random variation&quot;, title = &quot;Title here&quot;)
plt.show()</code></pre>
</div>
<div id="axes-limit" class="section level3">
<h3>Axes limit</h3>
<p>Set limits on the one axis in a Seaborn plot:</p>
<pre><code>p = seaborn.scatterplot(&#39;petal_length&#39;,&#39;petal_width&#39;,&#39;species&#39;,data=iris)
p.set(ylim=(-2,None))</code></pre>
<p>In Seaborn facet grid. <a
href="https://stackoverflow.com/a/25213614/2641825">How to set xlim and
ylim in seaborn facet grid</a></p>
<pre><code>g = seaborn.FacetGrid(tips, col=&quot;time&quot;, row=&quot;smoker&quot;)
g = g.map(plt.hist, &quot;total_bill&quot;)
g.set(ylim=(0, None)) </code></pre>
</div>
<div id="grid-plot" class="section level3">
<h3>Grid plot</h3>
<div id="grid-scatter-plot" class="section level4">
<h4>Grid scatter plot</h4>
<p>Draw a scatter plot for each iris species</p>
<pre><code>g = seaborn.FacetGrid(iris, col=&quot;species&quot;, height=6, width=2)
iris[&#39;species&#39;] = iris[&#39;species&#39;].astype(&#39;category&#39;)
g.map(seaborn.scatterplot,&#39;petal_length&#39;,&#39;petal_width&#39;,&#39;species&#39;)
plt.show()</code></pre>
<p>Notice that if you don’t change the color to a categorical variable,
it will not vary across the species. I reported <a
href="https://github.com/mwaskom/seaborn/issues/2028">this
issue</a>.</p>
</div>
<div id="grid-bar-plot" class="section level4">
<h4>Grid Bar plot</h4>
<p>Draw a facet bar plot <a
href="https://stackoverflow.com/a/62225095/2641825">from SO</a> for each
combination of size and smoker/non smoker</p>
<pre><code>import seaborn as sns
import matplotlib.pyplot as plt
sns.set()
tips=sns.load_dataset(&quot;tips&quot;)
g = sns.FacetGrid(tips, col = &#39;size&#39;,  row = &#39;smoker&#39;, hue = &#39;day&#39;)
g = (g.map(sns.barplot, &#39;time&#39;, &#39;total_bill&#39;, ci = None).add_legend())
plt.show()</code></pre>
</div>
<div id="grid-line-plot" class="section level4">
<h4>Grid line plot</h4>
<blockquote>
<p>This function provides access to several different axes-level
functions that show the relationship between two variables with semantic
mappings of subsets. The <code>kind</code> parameter selects the
underlying axes-level function to use:</p>
</blockquote>
<blockquote>
<ul>
<li>:func:<code>scatterplot</code> (with <code>kind="scatter"</code>;
the default)</li>
<li>:func:<code>lineplot</code> (with <code>kind="line"</code>)</li>
</ul>
</blockquote>
<p><a href="https://seaborn.pydata.org/examples/faceted_lineplot.html"
class="uri">https://seaborn.pydata.org/examples/faceted_lineplot.html</a></p>
<pre><code>import seaborn as sns
sns.set_theme(style=&quot;ticks&quot;)

dots = sns.load_dataset(&quot;dots&quot;)

# Define the palette as a list to specify exact values
palette = sns.color_palette(&quot;rocket_r&quot;)

# Plot the lines on two facets
g = sns.relplot(
    data=dots,
    x=&quot;time&quot;, y=&quot;firing_rate&quot;,
    hue=&quot;coherence&quot;, size=&quot;choice&quot;, col=&quot;align&quot;,
    kind=&quot;line&quot;, size_order=[&quot;T1&quot;, &quot;T2&quot;], palette=palette,
    height=5, aspect=.75, facet_kws=dict(sharex=False),
)
g.fig.suptitle(&quot;Dots example&quot;)
# Add a title and adjust the position so the title doesn&#39;t overwrite facets
g.set_ylabels(&quot;Y label&quot;)
plt.subplots_adjust(top=0.9)</code></pre>
</div>
</div>
<div id="title" class="section level3">
<h3>Title</h3>
<p>Use <code>set_title</code> to add a title:</p>
<pre><code>(seaborn
 .scatterplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips)
 .set_title(&#39;Progression of tips along the bill amount&#39;)
)</code></pre>
<p>Set a common title for grid plots</p>
<pre><code>g = seaborn.FacetGrid(tips, col=&quot;time&quot;, row=&quot;smoker&quot;)
g = g.map(plt.hist, &quot;total_bill&quot;)
g.fig.suptitle(&#39;I don&#39;t smoke and I don&#39;t tip.&#39;)</code></pre>
<p>In case the title is overwritten on the subplots, you might need to
use <a
href="https://stackoverflow.com/a/28650623/2641825">fig.subplot_adjust()</a>
as such:</p>
<pre><code>g.fig.subplots_adjust(top=.95)</code></pre>
</div>
<div id="figure-size-1" class="section level3">
<h3>Figure size</h3>
<p>Resize a scatter plot</p>
<pre><code>p = seaborn.scatterplot(&#39;petal_length&#39;,&#39;petal_width&#39;,&#39;species&#39;,data=iris)
p.figure.set_figwidth(15)</code></pre>
<div id="larger-grid-plots" class="section level4">
<h4>Larger grid plots</h4>
<p><code>set_figwidth</code> and <code>set_figheight</code> work well to
resize a grid object in its entirety.</p>
<pre><code>g = seaborn.FacetGrid(tips, col=&quot;time&quot;, row=&quot;smoker&quot;)
g = g.map(plt.hist, &quot;total_bill&quot;)
g.fig.set_figwidth(10)
g.fig.set_figheight(10) </code></pre>
<p>Mentioned as a comment under <a
href="https://stackoverflow.com/a/56970556/2641825">this answer</a></p>
<p>To change the height and aspect ration of individual grid cells, you
can use the <code>height</code> and <code>aspect</code> arguments of the
FacetGrid call as such:</p>
<pre><code>import seaborn 
from matplotlib import pyplot
seaborn.set()
iris = seaborn.load_dataset(&quot;iris&quot;)
# Change height and aspect ratio
g = seaborn.FacetGrid(iris, col=&quot;species&quot;, height=8, aspect=0.3)
iris[&#39;species&#39;] = iris[&#39;species&#39;].astype(&#39;category&#39;)
g.map(seaborn.scatterplot,&#39;petal_length&#39;,&#39;petal_width&#39;,&#39;species&#39;)
pyplot.show()</code></pre>
<p><code>help(seaborn.FacetGrid)</code></p>
<blockquote>
<p><code>aspect * height</code> gives the width of each facet in
inches.</p>
</blockquote>
</div>
</div>
<div id="scatter-plot-1" class="section level3">
<h3>Scatter Plot</h3>
<p>Create a scatter plot</p>
<pre><code>import seaborn
import matplotlib.pyplot as plt
tips = seaborn.load_dataset(&quot;tips&quot;)
seaborn.scatterplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips)
plt.show()</code></pre>
<p>Group by another variable and show the groups with different
colors:</p>
<pre><code>seaborn(x=&quot;total_bill&quot;, y=&quot;tip&quot;, hue=&quot;time&quot;, data=tips)</code></pre>
</div>
<div id="sample-data" class="section level3">
<h3>Sample data</h3>
<p>Show all Seaborn sample datasets</p>
<pre><code>for dataset in seaborn.get_dataset_names():
    print(dataset)
    print(seaborn.load_dataset(dataset).head())</code></pre>
</div>
</div>
<div id="squarify-treemaps" class="section level2">
<h2>Squarify treemaps</h2>
<p>Plot a <a href="https://www.python-graph-gallery.com/treemap/">tree
map from the python graph gallery</a></p>
<pre><code>import matplotlib.pyplot as plt
import squarify    # pip install squarify (algorithm for treemap)
import pandas
df = pandas.DataFrame({&#39;nb_people&#39;:[8,3,4,2], &#39;group&#39;:[&quot;group A&quot;, &quot;group B&quot;, &quot;group C&quot;, &quot;group D&quot;] })
squarify.plot(sizes=df[&#39;nb_people&#39;], label=df[&#39;group&#39;], alpha=.8 )
plt.axis(&#39;off&#39;)
plt.show()</code></pre>
</div>
<div id="vega" class="section level2">
<h2>Vega</h2>
<p>The tool tip feature is nice in an interactive notebook.</p>
<ul>
<li>Ipython vega for Jupyter notebooks <a
href="https://github.com/vega/ipyvega"
class="uri">https://github.com/vega/ipyvega</a></li>
<li>Vega gallery <a href="https://vega.github.io/vega/examples/"
class="uri">https://vega.github.io/vega/examples/</a></li>
</ul>
<p>Vega Lite</p>
<ul>
<li><p>Vega lite gallery <a
href="https://vega.github.io/vega-lite-v1/examples/"
class="uri">https://vega.github.io/vega-lite-v1/examples/</a></p></li>
<li><p>Vega lite documentation on <a
href="https://vega.github.io/vega-lite/docs/tooltip.html">tooltips</a></p>
<p>from vega import VegaLite import pandas df =
pandas.read_json(‘cars.json’) VegaLite({ “data”: {“url”:
“data/cars.json”}, “mark”: {“type”: “point”, “tooltip”: true},
“encoding”: { “x”: {“field”: “Horsepower”,“type”: “quantitative”}, “y”:
{“field”: “Miles_per_Gallon”,“type”: “quantitative”} } }, df)</p></li>
</ul>
</div>
</div>
<div id="print" class="section level1">
<h1>Print</h1>
<p><a href="https://stackoverflow.com/a/21786287/2641825">How to print
coloured text at the terminal?</a></p>
<blockquote>
<p>“Print a string that starts a color/style, then the string, and then
end the color/style change with ‘1b[0m’.”</p>
</blockquote>
<p>For example</p>
<pre><code>print(1000 * (&quot;\x1b[1;32;44m&quot; + &quot;Winter&quot; + &quot;\x1b[0m&quot; + &quot;, &quot; +
              &quot;\x1b[1;32;42m&quot; + &quot;Spring&quot; + &quot;\x1b[0m&quot; + &quot;, &quot; +
              &quot;\x1b[1;35;41m&quot; + &quot;Summer&quot; + &quot;\x1b[0m&quot; + &quot;, &quot; +
              &quot;\x1b[1;35;45m&quot; + &quot;Autumn&quot; + &quot;\x1b[0m&quot; + &quot;, &quot;))</code></pre>
</div>
<div id="profiling-and-measuring-time" class="section level1">
<h1>Profiling and measuring time</h1>
<p><a
href="https://stackoverflow.com/questions/2866380/how-can-i-time-a-code-segment-for-testing-performance-with-pythons-timeit">How
can I time a code segment for testing performance with Pythons
timeit?</a></p>
<p>Time a function:</p>
<pre><code>import timeit
import time
def wait():
    time.sleep(1)
timeit.timeit(wait, number=3)</code></pre>
<blockquote>
<p>“If you are profiling your code and can use IPython, it has the magic
function <code>%timeit</code>. <code>%%timeit</code> operates on
cells.”</p>
</blockquote>
<pre><code>%timeit wait()</code></pre>
<p><a href="https://stackoverflow.com/a/15707125/2641825">Time a code
block</a>:</p>
<pre><code>import timeit
start_time = timeit.default_timer()
# code you want to evaluate
elapsed = timeit.default_timer() - start_time</code></pre>
</div>
<div id="r-and-python" class="section level1">
<h1>R and python</h1>
<p>See also the <a href="R.html">R page</a> for more details on R.</p>
<p>Reddit <a
href="https://old.reddit.com/r/datascience/comments/67p72w/python_vs_r/">python
vs R</a></p>
<blockquote>
<p>“R is for analysis. Python is for production. If you want to do
analysis only, use R. If you want to do production only, use Python. If
you want to do analysis then production, use Python for both. If you
aren’t planning to do production then it’s not worth doing, (unless
you’re an academic). Conclusion: Use python.”</p>
</blockquote>
<div id="history" class="section level2">
<h2>History</h2>
<p>The central objects in R are vectors, matrices and data frames, that
is why I mostly compare R to the python packages numpy and pandas. R was
created almost 20 years before numpy and more than 40 years before
pandas.</p>
<p><a
href="https://en.wikipedia.org/wiki/R_(programming_language)">R_(programming_language)</a></p>
<blockquote>
<p>“R is an implementation of the S programming language combined with
lexical scoping semantics, inspired by Scheme. S was created by John
Chambers in 1976 while at Bell Labs. A commercial version of S was
offered as S-PLUS starting in 1988.”</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/NumPy#History">NumPy
history</a></p>
<blockquote>
<p>“In 1995 the special interest group (SIG) matrix-sig was founded with
the aim of defining an array computing package; among its members was
Python designer and maintainer Guido van Rossum, who extended Python’s
syntax (in particular the indexing syntax) to make array computing
easier. […] An implementation of a matrix package was completed by Jim
Fulton, then generalized by Jim Hugunin and called Numeric. […] new
package called Numarray was written as a more flexible replacement for
Numeric. Like Numeric, it too is now deprecated. […] In early 2005,
NumPy developer Travis Oliphant wanted to unify the community around a
single array package and ported Numarray’s features to Numeric,
releasing the result as NumPy 1.0 in 2006.”</p>
</blockquote>
<p><a
href="https://en.wikipedia.org/wiki/Pandas_(software)#History">Pandas_(software)</a></p>
<blockquote>
<p>“Developer Wes McKinney started working on pandas in 2008 while at
AQR Capital Management out of the need for a high performance, flexible
tool to perform quantitative analysis on financial data. Before leaving
AQR he was able to convince management to allow him to open source the
library.”</p>
</blockquote>
<p><a
href="https://jrvcomputing.wordpress.com/2016/11/14/migrating-from-r-to-python/">Migrating
from R to python</a></p>
<blockquote>
<p>“Python is a full fledge programming language but it is missing
statistical and plotting libraries. Vectors are an after thought in
python most functionality can be reproduced using operator overloading,
but some functionality looks clumsy.”</p>
</blockquote>
</div>
<div id="numpy-and-r" class="section level2">
<h2>Numpy and R</h2>
<p>R session showing a division by zero returning an infinite value.</p>
<pre><code>&gt; 1/0
[1] Inf</code></pre>
<p>Python session showing a division by zero error for normal integer
division and the same operation on a numpy array returning an infinite
value with a warning.</p>
<pre><code>In [1]: 1/0
---------------------------------------------------------------------------
ZeroDivisionError                         Traceback (most recent call last)
&lt;ipython-input-1-9e1622b385b6&gt; in &lt;module&gt;
----&gt; 1 1/0

ZeroDivisionError: division by zero

In [2]: import numpy as np

In [3]: np.array([1]) / 0
/home/paul/.local/bin/ipython:1: RuntimeWarning: divide by zero encountered in true_divide
  #!/usr/bin/python3
Out[3]: array([inf])</code></pre>
</div>
<div id="pandas-comparison-with-r" class="section level2">
<h2>Pandas comparison with R</h2>
<p>R data frame to be used for examples:</p>
<pre><code>df = data.frame(x = 1:3, y = c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;), stringsAsFactors = FALSE)</code></pre>
<p>Pandas data frame to be used for examples:</p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;x&#39; : [1,2,3], &#39;y&#39; : [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})</code></pre>
<table>
<colgroup>
<col width="25%" />
<col width="27%" />
<col width="47%" />
</colgroup>
<thead>
<tr class="header">
<th>Base R</th>
<th>python or pandas</th>
<th>SO questions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>df[df$y %in% c('a','b'),]</code></td>
<td><code>df[df['y'].isin(['a','b'])]</code></td>
<td><a
href="https://stackoverflow.com/questions/12096252/use-a-list-of-values-to-select-rows-from-a-pandas-dataframe">list
of values to select a row</a></td>
</tr>
<tr class="even">
<td><code>dput(df)</code></td>
<td><code>df.to_dict(orient="list")</code></td>
<td><a
href="https://stackoverflow.com/questions/47450931/print-pandas-data-frame-for-reproducible-example-equivalent-to-dput-in-r">Print
pandas data frame for reproducible example</a></td>
</tr>
<tr class="odd">
<td><code>expand.grid(df$x,df$y)</code></td>
<td><code>itertools.product</code></td>
<td>see section below</td>
</tr>
<tr class="even">
<td><code>ifelse</code></td>
<td><code>df.where()</code></td>
<td>[ifelse in pandas]</td>
</tr>
<tr class="odd">
<td><code>gsub</code></td>
<td><code>df.x.replace(regex=True)</code></td>
<td><a
href="https://stackoverflow.com/questions/21834293/equivalent-of-gsub-for-pandas-series-dataframe/56547104?noredirect=1#comment99677847_56547104">gsub
in pandas</a></td>
</tr>
<tr class="even">
<td></td>
<td>or df.x.str.replace()</td>
<td></td>
</tr>
<tr class="odd">
<td><code>length(df)</code> and <code>dim(df)</code></td>
<td><code>df.shape</code></td>
<td><a
href="https://stackoverflow.com/questions/15943769/how-do-i-get-the-row-count-of-a-pandas-dataframe">row
count of a data frame</a></td>
</tr>
<tr class="even">
<td><code>rbind</code></td>
<td><code>pandas.concat</code></td>
<td><a
href="https://stackoverflow.com/questions/14988480/pandas-version-of-rbind">Pandas
version of rbind</a></td>
</tr>
<tr class="odd">
<td><code>rep(1,3)</code></td>
<td><code>[1]*3</code></td>
<td></td>
</tr>
<tr class="even">
<td><code>seq(1:5)</code></td>
<td><code>np.array(range(0,5))</code></td>
<td><a href="https://stackoverflow.com/a/60753578/2641825">numpy
function to generate sequences</a></td>
</tr>
<tr class="odd">
<td><code>summary</code></td>
<td><code>describe</code></td>
<td></td>
</tr>
<tr class="even">
<td><code>str</code></td>
<td><code>df.info()</code></td>
<td><a
href="https://stackoverflow.com/questions/27637281/what-are-python-pandas-equivalents-for-r-functions-like-str-summary-and-he">pandas
equivalents for R functions like str summary and head</a></td>
</tr>
</tbody>
</table>
<p><a
href="https://stackoverflow.com/questions/43391591/if-else-function-in-pandas-dataframe">ifelse
in pandas</a></p>
<p>The mapping of tidyverse to pandas is:</p>
<table>
<colgroup>
<col width="24%" />
<col width="47%" />
<col width="28%" />
</colgroup>
<thead>
<tr class="header">
<th>tidyverse</th>
<th>pandas</th>
<th>Help or SO questions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>arrange</td>
<td>df.sort_values(by=“y”, ascending=False)</td>
<td></td>
</tr>
<tr class="even">
<td>df %&gt;% select(-a,-b)</td>
<td>df.drop(columns=[‘x’, ‘y’])</td>
<td></td>
</tr>
<tr class="odd">
<td>select(a)</td>
<td>df.filter(items=[‘x’])</td>
<td></td>
</tr>
<tr class="even">
<td>select(contains(“a”))</td>
<td>df.filter(regex=‘x’)</td>
<td></td>
</tr>
<tr class="odd">
<td>filter</td>
<td>df.query(“y==‘b’”)</td>
<td></td>
</tr>
<tr class="even">
<td>group_by</td>
<td>groupby</td>
<td></td>
</tr>
<tr class="odd">
<td>lag</td>
<td><a
href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html">shift</a></td>
<td><a
href="https://stackoverflow.com/questions/23664877/pandas-equivalent-of-oracle-lead-lag-function">pandas
lag function</a></td>
</tr>
<tr class="even">
<td>mutate</td>
<td>df.assign(e = lambda x: x[“a”] * 3)</td>
<td><a
href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html">assign</a></td>
</tr>
<tr class="odd">
<td>pivot_longer</td>
<td><a
href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html">melt</a>
or <a
href="https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html">wide_to_long</a></td>
<td></td>
</tr>
<tr class="even">
<td>pivot_wider</td>
<td><a
href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html">pivot</a></td>
<td></td>
</tr>
<tr class="odd">
<td>rename</td>
<td>df.rename(columns={‘a’:‘new’})</td>
<td></td>
</tr>
<tr class="even">
<td>separate</td>
<td>df[‘b’,‘c’] = df.a.str.split(‘,’,1,expand=True)</td>
<td><a href="https://stackoverflow.com/a/57823566">pandas separate</a>
str section</td>
</tr>
<tr class="odd">
<td>summarize</td>
<td>agg</td>
<td></td>
</tr>
<tr class="even">
<td>unite</td>
<td>df[“z”] = df.y + df.y</td>
<td><a
href="https://stackoverflow.com/questions/19377969/combine-two-columns-of-text-in-pandas-dataframe">pandas
unite</a></td>
</tr>
<tr class="odd">
<td>unnest</td>
<td><a
href="https://pandas.pydata.org/pandas-docs/version/0.25/reference/api/pandas.DataFrame.explode.html">explode</a></td>
<td><a href="https://stackoverflow.com/a/53218939/2641825">unnest in
pandas</a></td>
</tr>
</tbody>
</table>
<p>Methods to use inside the .groupby().agg() method:</p>
<ul>
<li><code>sum</code></li>
<li><code>count</code></li>
<li><code>mean</code></li>
<li><code>', '.join</code> <a
href="https://stackoverflow.com/questions/17841149/pandas-groupby-how-to-get-a-union-of-strings">to
get a union of strings</a></li>
</ul>
<div id="expand-grid-in-pandas" class="section level3">
<h3>Expand grid in pandas</h3>
<p>This <a href="https://stackoverflow.com/a/60371544/2641825">SO
answer</a> provides an implementation of expand grid using
itertools:</p>
<pre><code>import itertools
import pandas
countries = [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;]
years = range(1990, 2020)
expand_grid = list(itertools.product(countries, years))
df = pandas.DataFrame(expand_grid, columns=(&#39;country&#39;, &#39;year&#39;))</code></pre>
<p>Another <a href="https://stackoverflow.com/a/64449660/2641825">SO
answer on the same topic</a></p>
</div>
<div id="blogs-and-quotes-on-pandas-and-r" class="section level3">
<h3>Blogs and quotes on Pandas and R</h3>
<ul>
<li><a
href="https://www.kdnuggets.com/2017/02/moving-r-python-libraries.html">Moving
from R to python</a></li>
</ul>
<blockquote>
<p>“One thing that is a blessing and a curse in R is that the machine
learning algorithms are generally segmented by package. […] it can be a
pain for day-to-day use where you might be switching between algorithms.
[…] scikit-learn provides a common set of ML algorithms all under the
same API.</p>
</blockquote>
<blockquote>
<p>“one thing that R still does better than Python is plotting. Hands
down, R is better in just about every facet. Even so, Python plotting
has matured though it’s a fractured community.”</p>
</blockquote>
<ul>
<li><p>pandas.pydata.org <a
href="https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html">Comparison
with R</a></p></li>
<li><p><a
href="https://stmorse.github.io/journal/tidyverse-style-pandas.html">Tydiverse
style pandas</a></p></li>
</ul>
<blockquote>
<p>“Tidyverse allows a mix of quoted and unquoted references to variable
names. In my (in)experience, the convenience this brings is accompanied
by equal consternation. It seems to me a lot of the problems solved by
tidyeval would not exist if all variables were quoted all the time, as
in pandas, but there are likely deeper truths I’m missing here…”</p>
</blockquote>
<p>Help of the R function unite from the tidyr package:</p>
<blockquote>
<p>“col: The name of the new column, as a string or symbol. This
argument is passed by expression and supports quasiquotation (you can
unquote strings and symbols). The name is captured from the expression
with ‘rlang::ensym()’ (note that <strong>this kind of interface where
symbols do not represent actual objects is now discouraged</strong> in
the tidyverse; we support it here for backward compatibility).”</p>
</blockquote>
<p>The use of symbols which do not represent actual objects was was
frustrating at first when using pandas, because we hat to use df[“x”] to
assign vectors to new column names whereas we could use df.x to display
them.</p>
</div>
</div>
<div id="personal-reflection" class="section level2">
<h2>Personal reflection</h2>
<p>R is great for statistical analysis and plotting. You can also use it
to elaborate a pipeline to load data, prepare it and analyse it. But
when things start to get complicated, such as loading json data from
APIs, or dealing with http requests issues, or understanding lazy
evaluation, or the consequences of non standard evaluation, moving down
the rabbit whole can get really complicated with R. The rabbit hole
slide is smoother with python. I have the feeling that I keep a certain
level of understanding at all steps. It’s just a matter of taste
anyway.</p>
<p>The Python language can be more verbose on some aspects, but it
allows for greater programmability, it is also more predictable because
non standard evaluation doesn’t create scoping problems and it enables
to dive deeper into input/output issues such as URL request headers for
example. R remains very good for data exploration, statistical analysis
and plotting because non standard evaluation makes it possible to call
variables without quotes and to pass formulas to plotting and estimation
functions.</p>
<p>I see R more like the bash command line. It’s great for scripts, but
you wouldn’t want to write large applications in bash.</p>
<p>Non standard evaluation doesn’t exist in python. - An email thread
discussing <a
href="https://www.mail-archive.com/python-ideas@python.org/msg15694.html">the
idea of non standard evaluation in python</a>. - A <a
href="https://third-bit.com/2018/11/16/non-standard-evaluation/">comparison
of a python implementation and an R implementation using non standard
evaluation</a>.</p>
</div>
</div>
<div id="string" class="section level1">
<h1>String</h1>
<p>See also string operations in pandas character vectors.</p>
<p><a
href="https://stackoverflow.com/questions/25675943/how-can-i-concatenate-str-and-int-objects">SO
answer</a> providing various ways to concatenate python strings.</p>
<div id="number-formatting-in-strings" class="section level2">
<h2>Number formatting in strings</h2>
<p><a href="https://stackoverflow.com/a/10742904/2641825">How to print
number with commas as thousands separators?</a></p>
<pre><code>f&#39;{1e6:,}&#39; </code></pre>
<p>See also string operations in pandas with df[“x”].str methods.</p>
</div>
<div id="regex-substitution" class="section level2">
<h2>Regex substitution</h2>
<p><a href="https://docs.python.org/3/library/re.html">Documentation of
the re package</a>.</p>
<p>Replace one or more consecutive non alphanumeric characters by an
underscore.</p>
<pre><code>re.sub(r&#39;\W+&#39;, &#39;_&#39;, &#39;bla: bla**(bla)&#39;)</code></pre>
<p>Insert a suffix in a file name before the extension <a
href="https://stackoverflow.com/a/2763772/2641825">SO anwser</a></p>
<pre><code>import re
re.sub(r&#39;(?:_a)?(\.[^\.]*)$&#39; , r&#39;_suff\1&#39;,&quot;long.file.name.jpg&quot;)</code></pre>
</div>
<div id="regex-search" class="section level2">
<h2>Regex search</h2>
<p>Search for patterns</p>
<pre><code>import re
re.findall(r&#39;\bf[a-z]*&#39;, &#39;which foot or hand fell fastest&#39;)
[&#39;foot&#39;, &#39;fell&#39;, &#39;fastest&#39;]

re.findall(r&#39;(\w+)=(\d+)&#39;, &#39;set width=20 and height=10&#39;)
[(&#39;width&#39;, &#39;20&#39;), (&#39;height&#39;, &#39;10&#39;)]</code></pre>
<p>Search for ab in baba:</p>
<pre><code>re.search(&quot;ab&quot;, &quot;baba&quot;)</code></pre>
<p>Search for the numeric after “value_”</p>
<pre><code>re.findall(&quot;value_(\d+)&quot;, &quot;value_2022&quot;)</code></pre>
<p>Search for the group values occurrence of the numeric after
“value_”</p>
<pre><code>re.search(&quot;(value)_(\d+)&quot;, &quot;value_2022&quot;).group(0)
re.search(&quot;(value)_(\d+)&quot;, &quot;value_2022&quot;).group(1)
re.search(&quot;(value)_(\d+)&quot;, &quot;value_2022&quot;).group(2)</code></pre>
<p>Search charcters that are not value</p>
<pre><code>l = [&quot;value123&quot;, &quot;a&quot;, &quot;b&quot;]
[x for x in l if not re.search(&quot;value&quot;, x)]</code></pre>
</div>
<div id="split" class="section level2">
<h2>Split</h2>
<p><a href="https://stackoverflow.com/a/172454/2641825">Split lines in a
string</a></p>
<pre><code>input = &quot;&quot;&quot;bla
bla
bla&quot;&quot;&quot;
for line in input.splitlines():
    print(line, &quot;\n&quot;)</code></pre>
</div>
</div>
<div id="statistics" class="section level1">
<h1>Statistics</h1>
<div id="linear-programming-solvers" class="section level2">
<h2>Linear programming solvers</h2>
<p>Real Python <a
href="https://realpython.com/linear-programming-python/#what-is-linear-programming">What
is linear programing</a></p>
<blockquote>
<p>Several free Python libraries are specialized to interact with linear
or mixed-integer linear programming solvers:</p>
</blockquote>
<p><a
href="https://docs.scipy.org/doc/scipy/reference/optimize.html">SciPy
Optimization and Root Finding</a></p>
<p><a href="https://www.coin-or.org/PuLP/solvers.html">PuLP</a></p>
<p><a
href="https://pyomo.readthedocs.io/en/stable/solving_pyomo_models.html#supported-solvers">Pyomo</a></p>
<p><a
href="https://cvxopt.org/userguide/coneprog.html#optional-solvers">CVXOPT</a></p>
</div>
<div id="scaling" class="section level2">
<h2>Scaling</h2>
<p><a
href="http://benalexkeen.com/feature-scaling-with-scikit-learn/">Feature
scaling with scikit learn</a></p>
<ul>
<li>StandardScaler</li>
<li>MinMaxScaler</li>
<li>RobustScaler</li>
<li>Normalizer</li>
</ul>
</div>
</div>
<div id="style-guide-and-linter" class="section level1">
<h1>Style guide and linter</h1>
<div id="black" class="section level2">
<h2>Black</h2>
<p><a href="https://github.com/psf/black">Black</a> is “the
uncompromising Python code formater”</p>
<p>Run <code>black</code> as a pre commit hook with
<code>pre-commit</code> as explained below.</p>
<p>In vim, you can run black on the current file with:</p>
<pre><code>:!black %</code></pre>
</div>
<div id="flake-8" class="section level2">
<h2>Flake 8</h2>
<p>Flake 8 looks at more than just formatting.</p>
<p><a
href="https://pypi.org/project/flake8/1.6.1/#warning-error-codes">List
of FLake8 warnings and error codes</a></p>
</div>
<div id="pep-python-enhancement-proposals" class="section level2">
<h2>PEP Python Enhancement Proposals</h2>
<p><a
href="https://legacy.python.org/dev/peps/pep-0008/#version-bookkeeping">PEP
8 Style Guide for Python Code</a></p>
<blockquote>
<p>“A style guide is about consistency. Consistency with this style
guide is important. Consistency within a project is more important.
Consistency within one module or function is the most important.”</p>
</blockquote>
<blockquote>
<p>“However, <strong>know when to be inconsistent</strong> – sometimes
style guide recommendations just aren’t applicable. When in doubt, use
your best judgment. Look at other examples and decide what looks best.
And don’t hesitate to ask!”</p>
</blockquote>
<blockquote>
<p>“In particular: do not break backwards compatibility just to comply
with this PEP!”</p>
</blockquote>
</div>
<div id="pre-commit-hooks" class="section level2">
<h2>Pre commit hooks</h2>
<p>Blog:</p>
<ul>
<li><a
href="https://ljvmiranda921.github.io/notebook/2018/06/21/precommits-using-black-and-flake8/">pre
commits using black and flake8</a></li>
</ul>
<div id="install-pre-commit-hooks" class="section level3">
<h3>Install pre commit hooks</h3>
<p>Install <code>pre-commit</code></p>
<pre><code>pip install pre-commit</code></pre>
<p>Set up <code>pre-commit</code> in a repository</p>
<pre><code>cd path_to_repository
# Add the &quot;pre-commit&quot; python module to a requirements file
vim requirements.txt 
# Create a configuration file
vim .pre-commit-config.yaml </code></pre>
<p>Configuration options such as</p>
<pre><code>repos:
-   repo: https://github.com/ambv/black
    rev: 21.6b0
    hooks:
    - id: black
      language_version: python3.7
-   repo: https://gitlab.com/pycqa/flake8
    rev: 3.7.9
    hooks:
    - id: flake8</code></pre>
<p>Update <a
href="https://pre-commit.com/#using-the-latest-version-for-a-repository">hook
repositories to the latest version</a></p>
<pre><code>pre-commit autoupdate</code></pre>
<p>Install git hooks in your .git/ directory.</p>
<pre><code>pre-commit install</code></pre>
</div>
<div id="usage-in-continuous-integration" class="section level3">
<h3>Usage in Continuous integration</h3>
<p><a
href="https://pre-commit.com/#usage-in-continuous-integration">Usage in
Continuous integration</a> has a gitlab example:</p>
<pre><code>    my_job:
      variables:
        PRE_COMMIT_HOME: ${CI_PROJECT_DIR}/.cache/pre-commit
      cache:
        paths:
          - ${PRE_COMMIT_HOME}</code></pre>
</div>
<div id="un-install-pre-commit-hooks" class="section level3">
<h3>Un install pre-commit hooks</h3>
<p>Uninstall</p>
<pre><code>pre-commit uninstall</code></pre>
</div>
</div>
<div id="pylint" class="section level2">
<h2>Pylint</h2>
<p>Edit the configuration file</p>
<pre><code>vim ~/.pylintrc</code></pre>
<p>List of good names that shouldn’t give a “short name” warning</p>
<pre><code>[pylint]
good-names=df</code></pre>
<p>Generate a configuration file</p>
<pre><code>pylint --generate-rcfile</code></pre>
<p>Blog</p>
<ul>
<li>Reddit <a
href="https://www.reddit.com/r/Python/comments/82hgzm/any_advantages_of_flake8_over_pylint/">Any
advantages of Flake8 over PyLint</a> some answers suggest keeping
both.</li>
</ul>
<div id="dangerous-default-argument" class="section level3">
<h3>Dangerous default argument</h3>
<ul>
<li>[SO answer][<a
href="https://stackoverflow.com/questions/101268/hidden-features-of-python#113198"
class="uri">https://stackoverflow.com/questions/101268/hidden-features-of-python#113198</a>)</li>
<li><a href="https://github.com/PyCQA/pylint/issues/3642">pylint
issues</a></li>
</ul>
<blockquote>
<p>I understand the dangerous of using a mutable default value and I
suggest switching the warning message for something like “Dangerous
mutable default value as argument”. However, this is dangerous for all
sorts of scenarios? (I know that pylint isn’t supposed to check the
functionality of my code, just trying to clarify this anti-pattern)</p>
</blockquote>
<pre><code>&gt;&gt;&gt; def find(_filter={&#39;_id&#39;: 0}):
...     print({**find.__defaults__[0], **_filter})
...
&gt;&gt;&gt; find()
{&#39;_id&#39;: 0}
&gt;&gt;&gt; find({&#39;a&#39;: 1})
{&#39;_id&#39;: 0, &#39;a&#39;: 1}
&gt;&gt;&gt; find()
{&#39;_id&#39;: 0}
&gt;&gt;&gt; find({&#39;a&#39;: 1, &#39;b&#39;: 2})
{&#39;_id&#39;: 0, &#39;a&#39;: 1, &#39;b&#39;: 2}</code></pre>
<blockquote>
<p>One might argue that the following should be used and I tend to
agree:</p>
</blockquote>
<pre><code>&gt;&gt;&gt; def find(_filter=None):
...     if _filter is None:
...             _filter = {&#39;_id&#39;: 0}
...     else:
...             _filter[&#39;_id&#39;] = 0
...     print(_filter)
...
&gt;&gt;&gt; find()
{&#39;_id&#39;: 0}
&gt;&gt;&gt; find({&#39;a&#39;: 1})
{&#39;a&#39;: 1, &#39;_id&#39;: 0}
&gt;&gt;&gt; find()
{&#39;_id&#39;: 0}
&gt;&gt;&gt; find({&#39;a&#39;: 1, &#39;b&#39;: 2})
{&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;_id&#39;: 0}</code></pre>
</div>
<div id="using-with-for-resource-allocation" class="section level3">
<h3>Using with for resource allocation</h3>
<p>Pylint message</p>
<blockquote>
<p>Consider using ‘with’ for resource-allocating operations</p>
</blockquote>
<p>Explained in a <a
href="https://stackoverflow.com/a/67419279/2641825">SO answer</a></p>
<blockquote>
<p>suppose you are opening a file:</p>
</blockquote>
<pre><code>file_handle = open(&quot;some_file.txt&quot;, &quot;r&quot;)
...
...
file_handle.close()</code></pre>
<blockquote>
<p>You need to close that file manually after required task is done. If
it’s not closed, then resource (memory/buffer in this case) is wasted.
If you use <code>with</code> in the above example:</p>
</blockquote>
<pre><code>with open(&quot;some_file.txt&quot;, &quot;r&quot;) as file_handle:
    ...
    ...</code></pre>
<blockquote>
<p>there is no need to close that file. Resource de-allocation
automatically happens when you use with.</p>
</blockquote>
</div>
</div>
</div>
<div id="system-information" class="section level1">
<h1>System information</h1>
<p>Platform type</p>
<pre><code>import sys
sys.platform</code></pre>
<p>or</p>
<pre><code>import os
os.name</code></pre>
<p>Sys and os return different results ‘linux’ or ‘posix’.</p>
<p>More details are given by</p>
<pre><code>os.uname()</code></pre>
<div id="environment-variables" class="section level2">
<h2>Environment variables</h2>
<p>Get an environment variable</p>
<pre><code>import os
os.environ[&quot;XYZ&quot;]</code></pre>
<p>Set an environment variable</p>
<pre><code>os.environ[&quot;XYZ&quot;]  = &quot;/tmp&quot;</code></pre>
</div>
<div id="memory" class="section level2">
<h2>Memory</h2>
<div id="memory-usage-of-a-python-object" class="section level3">
<h3>Memory usage of a python object</h3>
<p>To display the memory usage of a python object</p>
<pre><code>import sys
a = 1
print(sys.getsizeof(a))</code></pre>
<p>See also the section on memory usage of pandas data frames under
columns / memory usage.</p>
</div>
<div id="out-of-memory-error" class="section level3">
<h3>Out of memory error</h3>
<p>Sometimes when a python process runs out of memory, it can get killed
by the Linux Kernel. In that case the error message is short “killed”
and there is no python trace back printed. You can check that it is
indeed a memory error by calling</p>
<pre><code>sudo dmesg</code></pre>
<p>Here is a typical message:</p>
<pre><code>[85962.510533] Out of memory: Kill process 16035 (ipython3) score 320 or sacrifice child
[85962.510554] Killed process 16035 (ipython3) total-vm:7081812kB, anon-rss:4536336kB, file-rss:0kB, shmem-rss:8kB
[85962.687468] oom_reaper: reaped process 16035 (ipython3), now anon-rss:0kB, file-rss:0kB, shmem-rss:8kB</code></pre>
<p>Various related Stack Overflow questions <a
href="https://stackoverflow.com/questions/19189522/what-does-killed-mean-when-a-processing-of-a-huge-csv-with-python-which-sudde">what
does “kill” mean</a>, <a
href="https://stackoverflow.com/questions/47408608/how-can-i-find-the-reason-that-python-script-is-killed">How
can I find the reason that python script is killed?</a>, <a
href="https://stackoverflow.com/questions/1811173/why-does-my-python-script-randomly-get-killed">Why
does python script randomly gets killed?</a>.</p>
</div>
</div>
</div>
<div id="test-driven-development" class="section level1">
<h1>Test driven development</h1>
<p>A good post about TDD <a
href="https://medium.com/@Cyrdup/unit-testing-youre-doing-it-wrong-407a07692989">Unit
testing your doing it wrong</a></p>
<blockquote>
<p>“TDD is actually about every form of tests. For example, I often
write performance tests as part of my TDD routine; end-to-end tests as
well. Furthermore, this is about behaviours, not implementation: you
write a new test when you need to fulfil a requirement. You do not write
a test when you need to code a new class or a new method. Subtle, but
important nuance. For example, you should not write a new test just
because you refactored the code. If you have to, it means you were not
really doing TDD.” […] “Good tests must test a behavior in isolation to
other tests. Calling them unit, system or integration has no relevance
to this. Kent Beck says this much better than I would ever do. ’‘’From
this perspective, the integration/unit test frontier is a frontier of
design, not of tools or frameworks or how long tests run or how many
lines of code we wrote get executed while running the test.’’’ Kent
Beck”</p>
</blockquote>
<div id="assertions" class="section level2">
<h2>Assertions</h2>
<ul>
<li><a href="https://blog.regehr.org/archives/1091">Use of
Assertions</a></li>
</ul>
</div>
<div id="unit-tests" class="section level2">
<h2>Unit tests</h2>
<p>See</p>
<ul>
<li><p><a
href="https://github.com/okken/markdown.py/blob/master/test_markdown_unittest.py">python
markdown unit tests</a></p></li>
<li><p><a
href="https://stackoverflow.com/questions/2085953/unit-testing-with-singletons">Unit
testing with singleton</a></p></li>
</ul>
</div>
<div id="pytest" class="section level2">
<h2>pytest</h2>
<p>Numpy moved from nose to pytest as explained in their <a
href="https://docs.scipy.org/doc/numpy/reference/testing.html">testing
guidelines</a>:</p>
<blockquote>
<p>“Until the 1.15 release, NumPy used the nose testing framework, it
now uses the pytest framework. The older framework is still maintained
in order to support downstream projects that use the old numpy
framework, but all tests for NumPy should use pytest.”</p>
</blockquote>
<p>Save this function in a file names test_numpy.py</p>
<pre><code>def test_numpy_closeness():
    assert [1,2] == [1,2]
    assert (np.array([1,2]) == np.array([1,2])).all()
    np.testing.assert_allclose(np.array([1,2]),np.array([1,3]))</code></pre>
<p>Save the file to test_nn.py</p>
<pre><code>import neural_nets as nn
import numpy as np

def test_rectified_linear_unit():
    x = np.array([[1,0],
                  [-1,-3]])
    expected = np.array([[1,0],
                         [0,0]])
    provided = nn.rectified_linear_unit(x)
    assert np.allclose(expected, provided), &quot;test failed&quot;</code></pre>
<p>Execute the test suite from bash with py.test as follows:</p>
<pre><code>cd ~/rp/course_machine_learning/projects/project_2_3_mnist/part2-nn
py.test</code></pre>
<p>Test pandas data frame with</p>
<pre><code>assert_frame_equal
assert_series_equal # tricky to use</code></pre>
<div id="expected-exceptions" class="section level3">
<h3>Expected exceptions</h3>
<p>pytest <a
href="https://docs.pytest.org/en/6.2.x/assert.html">assert</a></p>
<blockquote>
<p>“In order to write assertions about raised exceptions, you can use
pytest.raises() as a context manager like this:”</p>
</blockquote>
<pre><code>import pytest
def test_zero_division():
    with pytest.raises(ZeroDivisionError):
        1 / 0</code></pre>
<blockquote>
<p>“and if you need to have access to the actual exception info you may
use:”</p>
</blockquote>
<pre><code>def test_recursion_depth():
    with pytest.raises(RuntimeError) as excinfo:

        def f():
            f()

        f()
    assert &quot;maximum recursion&quot; in str(excinfo.value)</code></pre>
<blockquote>
<p>“excinfo is an ExceptionInfo instance, which is a wrapper around the
actual exception raised. The main attributes of interest are .type,
.value and .traceback.”</p>
</blockquote>
</div>
</div>
<div id="test-use-in-projects" class="section level2">
<h2>Test use in projects</h2>
<ul>
<li><p><a href="https://pypi.org/project/tabulate/">tabulate</a></p>
<blockquote>
<p>“uses pytest testing framework and <a
href="https://tox.wiki/en/latest/">tox</a> to automate testing in
different environments.”</p>
</blockquote></li>
</ul>
</div>
</div>
<div id="web" class="section level1">
<h1>Web</h1>
<div id="back-end-api" class="section level2">
<h2>Back-end API</h2>
<ul>
<li><p><a href="https://fastapi.tiangolo.com/"
class="uri">https://fastapi.tiangolo.com/</a> seems to be a recommended
way to create python APIs.</p></li>
<li><p>Django API</p></li>
<li><p>Flask API</p></li>
</ul>
</div>
<div id="frameworks" class="section level2">
<h2>Frameworks</h2>
<p><a
href="asynchrosnus://www.codementor.io/garethdwyer/flask-vs-django-why-flask-might-be-better-4xs7mdf8v">Flask
vs. Django</a></p>
<p>Note: <a
href="http://pgjones.gitlab.io/quart/flask_evolution.html#flask-evolution">Flask
Evolution into Quart</a> to support <a
href="http://pgjones.gitlab.io/quart/asyncio.html#asyncio">asyncio</a>
This last link contains a nice, simple example of how asyncio works with
a simulated delay to fetch a web page.</p>
</div>
</div>
<div id="media-and-organizations" class="section level1">
<h1>Media and organizations</h1>
<div id="blogs" class="section level2">
<h2>Blogs</h2>
<ul>
<li><p>Julio Biason <a
href="https://blog.juliobiason.me/thoughts/things-i-learnt-the-hard-way/">Things
I Learnt The Hard Way (in 30 Years of Software Development)</a></p></li>
<li><p>Daniel Lemire <a
href="https://lemire.me/blog/2016/06/21/i-do-not-use-a-debugger/">I do
not use a debugger</a></p>
<blockquote>
<p>“Debuggers don’t remove bugs. They only show them in slow
motion.”</p>
</blockquote>
<p><a href="https://lwn.net/2000/0914/a/lt-debugger.php3">Linus Toarvald
doesn’t use a debugger</a></p></li>
<li><p>Wes McKinney</p>
<ul>
<li><p>2017 <a
href="https://wesmckinney.com/blog/apache-arrow-pandas-internals/">Apache
Arrow and the 10 things I hate about pandas</a></p>
<blockquote>
<p>“pandas rule of thumb: have 5 to 10 times as much RAM as the size of
your dataset”</p>
</blockquote></li>
<li><p>2018 <a
href="https://wesmckinney.com/blog/announcing-ursalabs/">Announcing
Ursalabs</a></p>
<blockquote>
<p>“It has long been a frustration of mine that it isn’t easier to share
code and systems between R and Python. This is part of why working on
Arrow has been so important for me; it provides a path to sharing of
systems code outside of Python by enabling free interoperability at the
data level.”</p>
</blockquote>
<blockquote>
<p>“Critically, RStudio has avoided the “<strong>startup trap</strong>”
and managed to build a sustainable business while still investing the
vast majority of its engineering resources in <strong>open source
development</strong>. Nearly 9 years have passed since J.J. started
building the RStudio IDE, but in many ways he and Hadley and others feel
like they are just getting started.”</p>
</blockquote></li>
</ul></li>
<li><p>Dotan Nahum <a
href="https://jondot.medium.com/functional-programming-with-python-for-people-without-time-1eebdbd9526c">Functional
Programming with Python for People Without Time</a></p>
<blockquote>
<p>“Cracks in the Ice - We ended the previous part with stating that
with a good measure of abstraction, functional programming doesn’t offer
a considerable advantage over the “traditional” way of design, object
oriented. It’s a lie. […] In our pipeline example above with our
Executors — how do you feed in the output of one executor as the input
for the next one? well, you have to build that infrastructure. With
functional programming, those abstractions are not abstractions that you
have to custom build. They’re part of the language, mindset, and
ecosystem. Generically speaking — it’s all about impedence mismatch and
leaky abstractions and when it comes to data and functions; there’s no
mismatch because it’s built up from the core. The thesis is — that to
build a functional programming approach over an object-oriented
playground — is going to crash and burn at one point or another: be it
bad modeling of abstractions, performance problems, bad developer
ergonomics, and the worst — wrong mindset. Being able to model problems
and solutions in a functional way, transcends above traditional
abstraction; the object-oriented approach, in comparison, is crude,
inefficient and prone to maintenance problems.”</p>
</blockquote></li>
<li><p>Christopher Rackauckas <a
href="https://www.stochasticlifestyle.com/why-numba-and-cython-are-not-substitutes-for-julia/">Why
numba and cython are no substitute for Julia</a> discusses the
advantages of the Julia language over Python for large code
bases.</p></li>
<li><p>Ethan Rosenthal <a
href="https://www.ethanrosenthal.com/2022/02/01/everything-gets-a-package/">Everything
Gets a Package: My Python Data Science Setup</a></p></li>
<li><p><a
href="https://bashtage.github.io/linearmodels/panel/examples/data-formats.html">Data
Formats for Panel Data Analysis</a></p></li>
</ul>
<blockquote>
<p>There are two primary methods to express data:</p>
<ul>
<li><p>MultiIndex DataFrames where the outer index is the entity and the
inner is the time index. This requires using pandas.</p></li>
<li><p>3D structures were dimension 0 (outer) is variable, dimension 1
is time index and dimension 2 is the entity index. It is also possible
to use a 2D data structure with dimensions (t, n) which is treated as a
3D data structure having dimensions (1, t, n). These 3D data structures
can be pandas, NumPy or xarray.</p></li>
</ul>
</blockquote>
<ul>
<li><a href="https://python.quantecon.org/pandas_panel.html">Pandas for
panel data</a></li>
</ul>
<p>Explains multi index with stacking and unstacking.</p>
<ul>
<li><a
href="https://www.zverovich.net/2016/06/16/rst-vs-markdown.html">Sphinx
reStructuredText vs markdown for project documentation</a></li>
</ul>
</div>
<div id="foundations" class="section level2">
<h2>Foundations</h2>
<ul>
<li><p><a href="https://www.coin-or.org/projects/">COIN-OR project</a>
“open source for the operations research community”</p>
<blockquote>
<p>“Without open source implementations of existing algorithms, testing
new ideas built on existing ones typically requires the time-consuming
and error-prone process of re-implementing (and re-debugging and
re-testing) the original algorithm. If the original algorithm were
publicly available in a community repository, imagine the productivity
gains from software reuse! Science evolves when previous results can be
easily replicated”</p>
</blockquote></li>
<li><p><a href="https://www.python.org/psf-landing/">Python software
foundation</a></p>
<blockquote>
<p>“We support and maintain python.org, The Python Package Index, Python
Documentation, and many other services the Python Community relies
on.”</p>
</blockquote></li>
</ul>
</div>
<div id="interviews" class="section level2">
<h2>Interviews</h2>
<p><a
href="https://mappingthejourney.com/single-post/2017/06/21/episode-2-interview-with-alex-martelli-python-guru/">Interview
with Alex Martelli</a></p>
<blockquote>
<p>“Larry Page in his dormitory at Stanford had written or tried to
write a web spider to get a copy of some subset of the web on his
computers so he could try his famous Page algorithm. He was trying to
use the brand-new language Java in 1.0 beta version, and it kept
crashing. So he asked for help from his roommate and his roommate took a
look at said ‘oh you’re using that Java disaster’. Of course, it crashed
and did it in 100 lines of Python. It runs perfectly, and that’s how
Google became possible through 100 lines of Python. But I had no idea
until about five years ago that it had played so crucial role so early
on.”</p>
</blockquote>
<blockquote>
<p>” Similarly, if I hadn’t heard it from the mouth of Guido himself, I
would never have known that Python was at the heart of the web. The very
first Web server and web browser were written by the inventor of the
World Wide Web, HTTP, and HTML in Python. He wasn’t really a programmer;
he was a physicist and Python was far easier to use than anything
else.”</p>
</blockquote>
</div>
<div id="podcasts" class="section level2">
<h2>Podcasts</h2>
<p><a href="https://talkpython.fm/">talk python to me</a></p>
<ul>
<li><p><a
href="https://talkpython.fm/episodes/show/193/data-science-year-in-review-2018-edition">Data
science year in review</a></p></li>
<li><p>Interesting how Samuel Colvin talks about serialization <a
href="https://talkpython.fm/episodes/show/313/automate%20your%20data%20exchange%20with%20pydantic">automate
your data exchange with pydantic</a></p></li>
</ul>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
