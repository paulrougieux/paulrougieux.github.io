<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Paul Rougieux" />

<meta name="date" content="2017-08-17" />

<title>Python Commands</title>

<script src="site_libs/header-attrs-2.23/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.0/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.0/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Paul Rougieux</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-wrench"></span>
     
    Tools
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="bash.html">Bash</a>
    </li>
    <li>
      <a href="communication.html">Communication</a>
    </li>
    <li>
      <a href="debian.html">Debian</a>
    </li>
    <li>
      <a href="docker.html">Docker</a>
    </li>
    <li>
      <a href="git.html">Git</a>
    </li>
    <li>
      <a href="latex_and_lyx.html">Latex and Lyx</a>
    </li>
    <li>
      <a href="markdown.html">Markdown</a>
    </li>
    <li>
      <a href="mysql.html">MySQL</a>
    </li>
    <li>
      <a href="postgresql.html">PostgreSQL</a>
    </li>
    <li>
      <a href="publish.html">Publish</a>
    </li>
    <li>
      <a href="python.html">Python</a>
    </li>
    <li>
      <a href="R.html">R</a>
    </li>
    <li>
      <a href="vim.html">Vim</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-microchip"></span>
     
    Algos
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="carbon_budget_model.html">Carbon Budget Model</a>
    </li>
    <li>
      <a href="musical_scales.html">Musical scales</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-line-chart"></span>
     
    Data
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="explore.html">Explore</a>
    </li>
    <li>
      <a href="datasources.html">Sources</a>
    </li>
  </ul>
</li>
<li>
  <a href="events.html">
    <span class="fa fa-users"></span>
     
    Events
  </a>
</li>
<li>
  <a href="publications.html">
    <span class="fa fa-book"></span>
     
    Publications
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Python Commands</h1>
<h4 class="author">Paul Rougieux</h4>
<h4 class="date">17 August 2017</h4>

</div>


<div id="aa-packages" class="section level1">
<h1>AA Packages</h1>
<div id="install-with-pip" class="section level2">
<h2>Install with Pip</h2>
<p>pypi.org <a href="https://pypi.org/project/pip/">pip</a>:</p>
<blockquote>
<p>“pip is the package installer for Python. You can use pip to install
packages from the Python Package Index and other indexes.”</p>
</blockquote>
<p>Run at the command line or from an ipython prompt:</p>
<pre><code>pip install packagename</code></pre>
<p><a
href="https://stackoverflow.com/questions/7948494/whats-the-difference-between-a-python-module-and-a-python-package">What
is the difference between a python module and a python package</a></p>
<blockquote>
<p>“A package is a collection of modules in directories that give a
package hierarchy.”</p>
</blockquote>
<p><a
href="https://stackoverflow.com/questions/1471994/what-is-setup-py">What
is setup.py?</a></p>
<div id="check-the-version-number-of-a-package" class="section level3">
<h3>Check the version number of a package</h3>
<p>In Python check the version of a package with the
<code>__version__</code> attribute, however it’s not always
available.</p>
<pre><code>&gt;&gt;&gt; import pandas
&gt;&gt;&gt; print(pandas.__version__)</code></pre>
<p>You can also use <code>importlib</code></p>
<pre><code>&gt;&gt;&gt; from importlib.metadata import version
&gt;&gt;&gt; version(&#39;pandas&#39;)</code></pre>
<p><a
href="https://stackoverflow.com/questions/20180543/how-do-i-check-the-versions-of-python-modules">SO
answer</a> suggestion a command line way to display the same
information</p>
<pre><code>pip freeze | grep pandas</code></pre>
<div id="location-of-a-package" class="section level4">
<h4>Location of a package</h4>
<p>Check the location of a package</p>
<pre><code>import eu_cbm_hat
eu_cbm_hat.__file__</code></pre>
</div>
</div>
<div id="install-an-old-version" class="section level3">
<h3>Install an old version</h3>
<p>For example to install pandas 0.24.2</p>
<pre><code>python3 -m pip install --user pandas==0.24.2 </code></pre>
<p>or</p>
<pre><code>pip3 install --user pandas==0.24.2</code></pre>
<p>Sometimes you need to overwrite the existing version with I.</p>
<pre><code>pip install -I  package==version</code></pre>
</div>
<div id="install-a-local-version" class="section level3">
<h3>Install a local version</h3>
<p>To <a href="https://stackoverflow.com/a/18021540/2641825">install the
local version of a package with pip</a></p>
<pre><code>pip install -e /develop/MyPackage</code></pre>
<p>According to <code>man pip</code>, the <code>-e</code> option
“installs a project in editable mode (i.e. setuptools”develop mode”)
from a local project path or a VCS url”.</p>
<div id="uninstall-a-local-version" class="section level4">
<h4>Uninstall a local version</h4>
<p>When uninstalling a package installed locally, you might get this
error message:</p>
<pre><code>uninstall localpackage
# Found existing installation: localpackage 0.0.1
# Can&#39;t uninstall &#39;localpackage&#39;. No files were found to uninstall.</code></pre>
<p>You can show the location of the package with</p>
<pre><code>pip show localpackage</code></pre>
<p>Then remove it manually with</p>
<pre><code>rm -rf ~/.local/lib/python3.9/site-packages/localpackage*</code></pre>
<p>And maybe this as well</p>
<pre><code>rm -rf ~/.local/lib/python3.9/site-packages/build/lib/localpackage*</code></pre>
</div>
</div>
<div id="install-from-a-git-repository" class="section level3">
<h3>Install from a git repository</h3>
<p>Install from the dev branch of a private repo on gitlab using ssh</p>
<pre><code>pip install git+ssh://git@gitlab.com/bioeconomy/forobs/biotrade.git@dev</code></pre>
<p>Install from the dev branch of a private repo on gitlab using an <a
href="https://docs.gitlab.com/ee/user/project/deploy_tokens/index.html">authentication
token</a></p>
<pre><code>pip install git+https://gitlab+deploy-token-833444:ByW1T2bJZRtYhWuGrauY@gitlab.com/bioeconomy/forobs/biotrade.git@dev</code></pre>
<p>Install from the compressed <code>tar.gz</code> version of a
repository that doesn’t require git to be installed on your laptop:</p>
<pre><code>pip install --force-reinstall https://github.com/ytdl-org/youtube-dl/archive/refs/heads/master.tar.gz

pip install --force-reinstall https://github.com/mwaskom/seaborn/archive/refs/heads/master.tar.gz</code></pre>
<p><a
href="https://packaging.python.org/en/latest/tutorials/installing-packages/#installing-from-pypi">Installing
from Pypi</a></p>
</div>
</div>
<div id="install-with-anaconda" class="section level2">
<h2>Install with Anaconda</h2>
<p>Use conda update command to check to see if a new update is
available. If conda tells you an update is available, you can then
choose whether or not to install it.</p>
<ul>
<li><p><a
href="https://docs.conda.io/projects/conda/en/latest/commands.html#conda-vs-pip-vs-virtualenv-commands">conda
vs pip vs virtualenv commands</a></p>
<blockquote>
<p>“If you have used pip and virtualenv in the past, you can use conda
to perform all of the same operations. Pip is a package manager and
virtualenv is an environment manager. conda is both.”</p>
</blockquote></li>
</ul>
<div id="channels" class="section level3">
<h3>Channels</h3>
<p>In case a python package is not available in the default conda
channel use, you can change the channel to <a
href="https://conda-forge.org/docs/user/introduction.html">conda-forge</a>
as follows:</p>
<pre><code>conda install -c conda-forge &lt;package_name&gt;</code></pre>
<p><a
href="https://conda-forge.org/docs/user/introduction.html">conda-forge</a>:</p>
<pre><code>&gt; - &quot;The conda team, from Anaconda, Inc., packages a multitude of packages and
&gt; provides them to all users free of charge in their default channel.&quot;

&gt; &quot;conda-forge is a community effort that tackles these issues:
&gt;  - All packages are shared in a single channel named conda-forge.
&gt;  - Care is taken that all packages are up-to-date.
&gt;  - Common standards ensure that all packages have compatible versions.
&gt;  - By default, we build packages for macOS, Linux AMD64 and Windows
&gt;    AMD64.&quot;</code></pre>
</div>
<div id="install" class="section level3">
<h3>Install</h3>
<p>Documentation conda.io <a
href="https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html#installing-packages">installing
packages</a></p>
<blockquote>
<p>To install a specific package such as SciPy into an existing
environment “myenv”:</p>
</blockquote>
<pre><code>conda install --name myenv scipy</code></pre>
<blockquote>
<p>If you do not specify the environment name, which in this example is
done by –name myenv, the package installs into the current
environment:</p>
</blockquote>
<pre><code>conda install scipy</code></pre>
<blockquote>
<p>To install a specific version of a package such as SciPy:</p>
</blockquote>
<pre><code>conda install scipy=0.15.0</code></pre>
<blockquote>
<p>To install multiple packages at once, such as SciPy and cURL:</p>
</blockquote>
<pre><code>conda install scipy curl</code></pre>
<blockquote>
<p>Note: It is best to install all packages at once, so that all of the
dependencies are installed at the same time.</p>
</blockquote>
</div>
<div id="pip-and-conda" class="section level3">
<h3>Pip and conda</h3>
<ul>
<li><p><a
href="https://www.anaconda.com/blog/using-pip-in-a-conda-environment">Using
pip in a conda environment</a></p>
<blockquote>
<p>“Use pip only after conda. Install as many requirements as possible
with conda, then use pip”</p>
</blockquote></li>
</ul>
</div>
<div id="update" class="section level3">
<h3>Update</h3>
<p>Documentation conda.io <a
href="https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html#updating-packages">updating
packages</a></p>
<blockquote>
<p>Use the terminal or an Anaconda Prompt for the following steps.</p>
</blockquote>
<blockquote>
<p>To update a specific package:</p>
</blockquote>
<pre><code>conda update biopython</code></pre>
<blockquote>
<p>To update Python:</p>
</blockquote>
<pre><code>conda update python</code></pre>
<blockquote>
<p>To update conda itself:</p>
</blockquote>
<pre><code>conda update conda</code></pre>
</div>
<div id="remove" class="section level3">
<h3>Remove</h3>
<ul>
<li><a
href="https://docs.conda.io/projects/conda/en/latest/commands/remove.html"
class="uri">https://docs.conda.io/projects/conda/en/latest/commands/remove.html</a></li>
</ul>
<p>Remove the package ‘scipy’ from the currently-active environment:</p>
<pre><code>conda remove scipy</code></pre>
<p>Remove a list of packages from an environemnt ‘myenv’:</p>
<pre><code>conda remove -n myenv scipy curl wheel</code></pre>
</div>
<div id="environment-file" class="section level3">
<h3>Environment file</h3>
<p>Creating an environment file manually</p>
<p>You can create an environment file (environment.yml) manually to
share with others.</p>
<p>EXAMPLE: A simple environment file:</p>
<p>name: stats dependencies: - numpy - pandas</p>
<p>EXAMPLE: A more complex environment file:</p>
<p>name: stats2 channels: - javascript dependencies: - python=3.6 # or
2.7 - bokeh=0.9.2 - numpy=1.9.<em> - nodejs=0.10.</em> - flask - pip: -
Flask-Testing</p>
<p>Note</p>
<p>Note the use of the wildcard * when defining the patch version
number. Defining the version number by fixing the major and minor
version numbers while allowing the patch version number to vary allows
us to use our environment file to update our environment to get any bug
fixes whilst still maintaining consistency of software environment.</p>
</div>
<div id="mamba" class="section level3">
<h3>Mamba</h3>
<p>The mamba solver can speed up the dependency resolution process. It
doesn’t require a special mamba installation You can switch the default
solver in a normal conda installation:</p>
<pre><code>conda install -n base -c defaults conda-libmamba-solver
conda config --set solver libmamba</code></pre>
</div>
</div>
<div id="install-with-the-oss-package-manager" class="section level2">
<h2>Install with the OS’s package manager</h2>
<p>Some packages can be installed with the OS’s package manager. Such as
for example on Debian:</p>
<pre><code>sudo apt install python3-pip</code></pre>
</div>
<div id="discussion-pip-conda-apt" class="section level2">
<h2>Discussion pip, conda, apt</h2>
<ul>
<li><p>Venv or Anaconda? <a
href="https://www.reddit.com/r/Python/comments/xhbhbh/venv_or_anaconda/"
class="uri">https://www.reddit.com/r/Python/comments/xhbhbh/venv_or_anaconda/</a></p></li>
<li><p>What are the downsides of using Anaconda versus <a
href="https://www.reddit.com/r/Python/comments/6vq2m4/what_are_the_downsides_of_using_anaconda_vs/?rdt=43570&amp;onetap_auto=true"
class="uri">https://www.reddit.com/r/Python/comments/6vq2m4/what_are_the_downsides_of_using_anaconda_vs/?rdt=43570&amp;onetap_auto=true</a></p></li>
<li><p>Conda in production? <a
href="https://www.reddit.com/r/Python/comments/58n9ox/conda_in_production/"
class="uri">https://www.reddit.com/r/Python/comments/58n9ox/conda_in_production/</a></p>
<ul>
<li><p>User 1</p>
<blockquote>
<p>“At my company we use conda to manage our entire python stack across
multiple platforms (OSX, Windows and Linux) and we haven’t had any
issues. Typically we have a metapackage that defines the specific
requirements of a project.”</p>
</blockquote></li>
<li><p>Another user</p>
<blockquote>
<p>“We distribute a Python 3 GUI application on Mac, Windows, and Linux
that uses PyQt4, gdal, matplotlib, pyopengl, etc. We use conda for all
of our developers and beta testers and use pyinstaller to create an
installer for each OS that we support.”</p>
</blockquote></li>
</ul></li>
</ul>
</div>
<div id="create-a-package" class="section level2">
<h2>Create a package</h2>
<div id="publish-to-pypi" class="section level3">
<h3>Publish to pypi</h3>
<p>To upload a package to pypi, you need a pypi account. The <a
href="https://packaging.python.org/tutorials/packaging-projects/#uploading-the-distribution-archives">instructions
on uploading distribution archives explain how to upload the package to
test.pypi</a>:</p>
<pre><code>python3 -m twine upload --repository testpypi dist/*</code></pre>
<p>I updated the following package before running this</p>
<pre><code>pip install --upgrade build
pip install --upgrade twine</code></pre>
<p>I built the package with</p>
<pre><code>cd forobs/biotrade
python3 -m build</code></pre>
<p><code>twine</code> uses kde wallet to store the password, press
cancel if you can’t use kde wallet, it will then ask for the password at
the command line. There is a <a
href="https://github.com/pypa/twine/issues/338">twine issue related to
the use of keyring</a>.</p>
<p>Register an account on pypi (it’s a different server than test.pypi).
Create a token under account settings. Then upload to pypi itself</p>
<pre><code>cd repository
python3 -m build
twine upload dist/*</code></pre>
<p>To use the API token:</p>
<pre><code>Set your username to __token__
Set your password to the token value, including the pypi- prefix</code></pre>
</div>
<div id="test-install-in-a-virtual-environment" class="section level3">
<h3>Test install in a virtual environment</h3>
<p>In bash, create a virtual environment to test installation and remove
the python path otherwise my local version is seen</p>
<pre><code>mkdir /tmp/biotrade_env/
cd /tmp/biotrade_env/
python3 -m venv /tmp/biotrade_env/
source /tmp/biotrade_env/bin/activate
PYTHONPATH=&quot;&quot;
python3</code></pre>
<p>In python check that the package is not there</p>
<pre><code>&gt;&gt;&gt; import biotrade
&gt;&gt;&gt; import pandas</code></pre>
<p>Back to the shell test the installation from test.pypi</p>
<pre><code>pip install -i https://test.pypi.org/simple/ biotrade
# ERROR: Could not find a version that satisfies the requirement pandas (from biotrade)
# ERROR: No matching distribution found for pandas</code></pre>
<p>Installing biotrade’s dependencies directly generates an error
because pandas is not available in the test repository. You can install
them from the pypi directly with <code>pip install pandas</code>.</p>
<p>Install from a wheel</p>
<pre><code>cd ~/repos/forobs/biotrade/dist
pip install biotrade-0.2.2-py3-none-any.whl
# Or 
pip install biotrade-0.2.2.tar.gz</code></pre>
</div>
<div id="publish-to-conda-forge" class="section level3">
<h3>Publish to Conda Forge</h3>
<ul>
<li>Blog post <a
href="https://levelup.gitconnected.com/publishing-your-python-package-on-conda-and-conda-forge-309a405740cf">publish
your package on conda forge</a></li>
</ul>
<p>On <a href="https://conda-forge.org/docs/maintainer/adding_pkgs.html"
class="uri">https://conda-forge.org/docs/maintainer/adding_pkgs.html</a>
conda recommends <a href="https://github.com/conda-incubator/grayskull"
class="uri">https://github.com/conda-incubator/grayskull</a> to create
the recipe</p>
<blockquote>
<p>“Presently Grayskull can generate recipes for Python packages
available on PyPI and also those not published on PyPI but available as
GitHub repositories.”</p>
</blockquote>
</div>
<div id="authorship" class="section level3">
<h3>Authorship</h3>
<p>It’s only possible to specify one author field in setup.py. The
recommendation is to use a mailing list when there are multiple authors
and to set separate files for attribution.</p>
<p><a
href="https://stackoverflow.com/questions/9999829/how-to-specify-multiple-authors-emails-in-setup-py">How
to specify multiple authords in setup.py?</a></p>
</div>
<div id="add-non-code-files" class="section level3">
<h3>Add non code files</h3>
<p>The Python packaging documentation on <a
href="https://python-packaging.readthedocs.io/en/latest/non-code-files.html">adding
non code files</a></p>
<blockquote>
<p>“The mechanism that provides this is the MANIFEST.in file. This is
relatively quite simple: MANIFEST.in is really just a list of relative
file paths specifying files or globs to include.:</p>
</blockquote>
<pre><code>include README.rst
include docs/*.txt
include funniest/data.json</code></pre>
<blockquote>
<p>“In order for these files to be copied at install time to the
package’s folder inside site-packages, you’ll need to supply
include_package_data=True to the setup() function.”</p>
</blockquote>
<blockquote>
<p>“Files which are to be used by your installed library (e.g. data
files to support a particular computation method) should usually be
placed inside of the Python module directory itself. E.g. in our case, a
data file might be at <code>funniest/funniest/data.json</code>. That
way, code which loads those files can easily specify a relative path
from the consuming module’s <code>__file__</code> variable.”</p>
</blockquote>
<p>The Python packaging <a
href="https://packaging.python.org/en/latest/guides/using-manifest-in/">documentation
on the Manifest commands</a> The syntax of recursive-include graft
commands.</p>
<blockquote>
<p>Add all files under directories matching dir-pattern that match any
of the listed patterns</p>
</blockquote>
<pre><code>recursive-include dir-pattern pat1 pat2</code></pre>
<blockquote>
<p>Add all files under directories matching dir-pattern</p>
</blockquote>
<pre><code>graft dir-pattern</code></pre>
<p>The Python packaging documentation on <a
href="https://docs.python.org/3/distutils/sourcedist.html">source
dist</a> gives an example of the patterns</p>
<pre><code>include *.txt
recursive-include examples *.txt *.py
prune examples/sample?/build</code></pre>
<blockquote>
<p>” The meanings should be fairly clear: include all files in the
distribution root matching <code>*.txt</code>, all files anywhere under
the examples directory matching <code>*.txt</code> or <code>*.py</code>,
and exclude all directories matching examples/sample?/build.</p>
</blockquote>
</div>
<div id="version" class="section level3">
<h3>Version</h3>
<p><a
href="https://stackoverflow.com/questions/17583443/what-is-the-correct-way-to-share-package-version-with-setup-py-and-the-package">SO
What is the correct way to share package version with setup.py and the
package?</a></p>
<p>The version of a package has to be set both in <code>setup.py</code>
and <code>__init__py</code> it’s crazy the number of options that people
have thought about. <a
href="https://stackoverflow.com/a/61960231/2641825">This answers</a>
summarizes the state of the art in 7 options, including a link to the <a
href="https://packaging.python.org/en/latest/guides/single-sourcing-package-version/">python
packaging user guide</a></p>
<div id="bump-version" class="section level4">
<h4>Bump version</h4>
<p>Install bumpversion</p>
<pre><code>pip install bumpversion</code></pre>
<p>Increment the version number both in setup.py and
<strong>init</strong>.py with the command line tool bumpversion. First
create a configuration file <code>.bumpversion.cfg</code> where the
<code>current_version</code> matches the versions in
<code>setup.py</code> and <code>packagename/__init__.py</code></p>
<pre><code>[bumpversion]
current_version = 0.0.5
commit = True
tag = True

[bumpversion:file:setup.py]
[bumpversion:file:biotrade/__init__.py]</code></pre>
<p>Increment the version number in all files and the git tag with:</p>
<pre><code>bumpversion patch
# Or to increment minor or major versions
bumpversion minor
bumpversion major</code></pre>
<p>Push the corresponding tags to the remote repository</p>
<pre><code>git push origin --tags</code></pre>
<p>Check the updated version in setup.py</p>
<pre><code>python setup.py --version </code></pre>
<p>Start an ipython prompt to test the package version</p>
<pre><code>ipython
import packagename
packagename.__version__</code></pre>
</div>
</div>
<div id="documentation" class="section level3">
<h3>Documentation</h3>
<div id="pdoc" class="section level4">
<h4>Pdoc</h4>
<p>Generate the documentation of a package with <a
href="https://pdoc.dev/docs/pdoc.html">pdoc</a>:</p>
<pre><code>pdoc -o public ./biotrade</code></pre>
<p>This can be added to a <code>.gitlab-ci.yml</code> file in order to
generate the documentation on a Continuous Integration system:</p>
<pre><code>pages:
  stage: document
  script:
  # GitLab Pages will only publish files in the public directory
  - pdoc -o public ./biotrade
  artifacts:
    paths:
    - public
  only:
  - main
  interruptible: true</code></pre>
</div>
</div>
<div id="packaging-tools" class="section level3">
<h3>Packaging tools</h3>
<ul>
<li><p><a href="https://flit.pypa.io/en/latest/rationale.html"
class="uri">https://flit.pypa.io/en/latest/rationale.html</a></p>
<blockquote>
<p>” The existence of Flit spurred the development of new standards,
like PEP 518 and PEP 517, which are now used by other packaging tools
such as Poetry and Enscons.”</p>
</blockquote></li>
</ul>
</div>
<div id="setup.py-legacy" class="section level3">
<h3>Setup.py (legacy)</h3>
<ul>
<li><p><a
href="https://pip.pypa.io/en/stable/reference/build-system/setup-py/"
class="uri">https://pip.pypa.io/en/stable/reference/build-system/setup-py/</a></p>
<blockquote>
<p>“Prior to the introduction of pyproject.toml-based builds (in PEP 517
and PEP 518), pip had only supported installing packages using setup.py
files that were built using setuptools.”</p>
</blockquote>
<blockquote>
<p>“The interface documented here is retained currently solely for
legacy purposes, until the migration to pyproject.toml-based builds can
be completed.”</p>
</blockquote></li>
</ul>
</div>
<div id="pyproject-toml" class="section level3">
<h3>Pyproject-toml</h3>
<ul>
<li><p><a
href="https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/"
class="uri">https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/</a></p></li>
<li><p><a href="https://peps.python.org/pep-0518/"
class="uri">https://peps.python.org/pep-0518/</a> (from 2016 already) is
worth looking at. It discusses why they didn’t choose other
configuration file formats JSON, YAML or python literals such as dict.
They chose TOML in the end (its used for RUST package metadata). Details
of each format in <a
href="https://gist.github.com/njsmith/78f68204c5d969f8c8bc645ef77d4a8f"
class="uri">https://gist.github.com/njsmith/78f68204c5d969f8c8bc645ef77d4a8f</a></p></li>
</ul>
</div>
</div>
<div id="location-or-path" class="section level2">
<h2>Location or path</h2>
<div id="of-a-package" class="section level3">
<h3>Of a package</h3>
<p>The location of a package can be obtained from
<code>package_name.__file__</code>.</p>
</div>
<div id="of-the-python-executable" class="section level3">
<h3>Of the python executable</h3>
<p><a
href="https://stackoverflow.com/questions/749711/how-to-get-the-python-exe-location-programmatically">Get
the location of the python executable</a> with</p>
<pre><code>&gt;&gt;&gt; import sys
&gt;&gt;&gt; print(sys.executable)</code></pre>
<p>In virtual env, it can return the symlink to another folder. In that
case, the path can be deduced from</p>
<pre><code>&gt;&gt;&gt; import os
&gt;&gt;&gt; os.__file__</code></pre>
</div>
</div>
<div id="virtual-environments" class="section level2">
<h2>Virtual environments</h2>
<ul>
<li><p><a href="https://docs.python.org/3/library/venv.html">venv</a> is
available by default in Python 3.3+</p>
<ul>
<li><p>Installation</p>
<p>sudo apt install python3-venv</p></li>
<li><p>Usage</p>
<pre><code>mkdir /tmp/testenv
python3 -m venv /tmp/testenv
source /tmp/testenv/bin/activate</code></pre></li>
</ul></li>
<li><p><a href="https://pipenv.pypa.io/en/latest/">Pipenv</a> makes pip
and virtual environments work together.</p>
<blockquote>
<p>“There is a subtle but very important distinction to be made between
applications and libraries. This is a very common source of confusion in
the Python community.”</p>
</blockquote>
<blockquote>
<p>“Libraries provide reusable functionality to other libraries and
applications (let’s use the umbrella term projects here). They are
required to work alongside other libraries, all with their own set of
sub-dependencies. They define abstract dependencies. To avoid version
conflicts in sub-dependencies of different libraries within a project,
libraries should never ever pin dependency versions. Although they may
specify lower or (less frequently) upper bounds, if they rely on some
specific feature/fix/bug. Library dependencies are specified via
install_requires in setup.py.”</p>
</blockquote>
<blockquote>
<p>“Libraries are ultimately meant to be used in some application.
Applications are different in that they usually are not depended on by
other projects. They are meant to be deployed into some specific
environment and only then should the exact versions of all their
dependencies and sub-dependencies be made concrete. To make this process
easier is currently the main goal of Pipenv.”</p>
</blockquote>
<ul>
<li><p>Install on Debian</p>
<p>sudo apt install pipenv</p></li>
</ul></li>
<li><p><a href="https://github.com/pyenv/pyenv">pyenv</a> makes it
possible to manage different python versions. But within the containing
environment you can also install different packages with pip.</p></li>
<li><p>Illustration of the complementarity between pyenv and
pipenv.</p></li>
</ul>
<div id="remove-environment-variables" class="section level3">
<h3>Remove environment variables</h3>
<p>To test a fresh install of a package or test it in conditions where
some environmental variables are not defined.</p>
<p>For example remove environment variables with <code>unset</code>.</p>
<pre><code>unset BIOTRADE_DATABASE_URL</code></pre>
</div>
</div>
</div>
<div id="applications" class="section level1">
<h1>Applications</h1>
<ul>
<li>towardsdatascience.com <a
href="https://towardsdatascience.com/plotly-dash-vs-streamlit-which-is-the-best-library-for-building-data-dashboard-web-apps-97d7c98b938c">Plotly
Dash versus Streamlit</a></li>
</ul>
<div id="streamlit" class="section level2">
<h2>Streamlit</h2>
<p>Example application with select boxes and a slider. Use the
<code>index</code> argument to select a default value.</p>
<pre><code>import streamlit
reporter = streamlit.sidebar.selectbox(
    &quot;Select a reporter Country&quot;, options=df[&quot;reporter&quot;].unique()
)
products = streamlit.sidebar.multiselect(
    &quot;Select some products&quot;, options=df[&quot;product_name&quot;].unique()
)
element = streamlit.sidebar.selectbox(
    &quot;Select a variable for the Y Axis&quot;, options=[&quot;net_weight&quot;, &quot;price&quot;, &quot;trade_value&quot;]
)
flow = streamlit.sidebar.selectbox(
    &quot;Select a flow direction&quot;, options=[&quot;import&quot;, &quot;export&quot;]
)
n_partners = streamlit.sidebar.slider(
    &quot;Select N First Partners&quot;, min_value=1, max_value=10, value=5
)</code></pre>
</div>
</div>
<div id="compilers" class="section level1">
<h1>Compilers</h1>
<div id="numba-just-in-time-compiler" class="section level2">
<h2>Numba just-in-time compiler</h2>
<p><a
href="https://numba.readthedocs.io/en/stable/user/5minguide.html">Numba
User Manual</a></p>
<blockquote>
<p>“When a call is made to a Numba-decorated function it is compiled to
machine code “just-in-time” for execution and all or part of your code
can subsequently run at native machine code speed!”</p>
</blockquote>
</div>
<div id="pythran-ahead-of-time-compiler" class="section level2">
<h2>Pythran Ahead of time compiler</h2>
<p><a href="https://github.com/serge-sans-paille/pythran"
class="uri">https://github.com/serge-sans-paille/pythran</a></p>
<blockquote>
<p>“Pythran is an ahead of time compiler for a subset of the Python
language, with a focus on scientific computing. It takes a Python module
annotated with a few interface descriptions and turns it into a native
Python module with the same interface, but (hopefully) faster.”</p>
</blockquote>
</div>
</div>
<div id="control-flow" class="section level1">
<h1>Control flow</h1>
<div id="if" class="section level2">
<h2>If</h2>
<p>dotnetperls: <a href="https://www.dotnetperls.com/not-python">not
python</a></p>
<p>Sample code with a function and if conditions:</p>
<pre><code>def function(condition):
    if condition:
        print(&quot;Hi&quot;)
    if not condition:
        print(&quot;Bye&quot;)
function(True)
function(False)
function(&#39;&#39;)
function(&#39;lalala&#39;)</code></pre>
</div>
<div id="for-loop" class="section level2">
<h2>For loop</h2>
<p>A for loop with a <code>continue</code> statement</p>
<pre><code>print(&quot;I print all numbers in the range except 2.&quot;)
for i in range(5):
    if i==2:
        continue
    print(i)</code></pre>
</div>
</div>
<div id="command-line" class="section level1">
<h1>Command line</h1>
<div id="parsing-arguments-with-argparse" class="section level2">
<h2>Parsing arguments with argparse</h2>
<p><a href="https://docs.python.org/3/howto/argparse.html#">Argparse
Tutorial</a> explain how to create a python program that processes
command line arguments. Save the following in <code>prog.py</code></p>
<pre><code>import argparse
parser = argparse.ArgumentParser()
parser.add_argument(&quot;square&quot;, type=int,
                    help=&quot;display a square of a given number&quot;)
parser.add_argument(&quot;-v&quot;, &quot;--verbosity&quot;, type=int,
                    help=&quot;increase output verbosity&quot;)
args = parser.parse_args()
answer = args.square**2
if args.verbosity == 2:
    print(f&quot;the square of {args.square} equals {answer}&quot;)
elif args.verbosity == 1:
    print(f&quot;{args.square}^2 == {answer}&quot;)
else:
    print(answer)</code></pre>
<p>Usage</p>
<pre><code>$ python3 prog.py 4
16
$ python3 prog.py 4 -v
usage: prog.py [-h] [-v VERBOSITY] square
prog.py: error: argument -v/--verbosity: expected one argument
$ python3 prog.py 4 -v 1
4^2 == 16
$ python3 prog.py 4 -v 2
the square of 4 equals 16
$ python3 prog.py 4 -v 3
16</code></pre>
<p><a href="https://stackoverflow.com/a/42829692/2641825">SO answer</a>
explains that when using <strong>ipython</strong>, you need to separate
ipython arguments from your script arguments using <code>--</code>.</p>
</div>
<div id="other-command-line-tools" class="section level2">
<h2>Other command line tools</h2>
<ul>
<li><p><a href="https://www.pyinvoke.org/"
class="uri">https://www.pyinvoke.org/</a></p></li>
<li><p><a href="https://click.palletsprojects.com/en/8.1.x/"
class="uri">https://click.palletsprojects.com/en/8.1.x/</a></p></li>
<li><p><a href="http://docopt.org/"
class="uri">http://docopt.org/</a></p></li>
</ul>
<p>Click looks like a rising star <a
href="https://star-history.com/#docopt/docopt&amp;pallets/click&amp;pyinvoke/invoke&amp;Date"
class="uri">https://star-history.com/#docopt/docopt&amp;pallets/click&amp;pyinvoke/invoke&amp;Date</a></p>
</div>
</div>
<div id="databases" class="section level1">
<h1>Databases</h1>
<div id="sql-alchemy" class="section level2">
<h2>SQL Alchemy</h2>
<p>SQL Alchemy is a database abstraction layer. Interaction with the
database is built upon <a
href="https://docs.sqlalchemy.org/en/14/core/schema.html">metadata
objects</a>:</p>
<blockquote>
<p>The core of SQLAlchemy’s query and object mapping operations are
supported by <strong>database metadata</strong>, which is comprised of
Python objects that describe tables and other schema-level objects.
These objects are at the core of three major types of operations -
issuing CREATE and DROP statements (known as DDL), constructing SQL
queries, and expressing information about structures that already exist
within the database. Database metadata can be expressed by explicitly
naming the various components and their properties, using constructs
such as Table, Column, ForeignKey and Sequence, all of which are
imported from the sqlalchemy.schema package. It can also be generated by
SQLAlchemy using a process called reflection, which means you start with
a single object such as Table, assign it a name, and then instruct
SQLAlchemy to load all the additional information related to that name
from a particular engine source.</p>
</blockquote>
<p><a
href="https://docs.sqlalchemy.org/en/14/core/reflection.html">Reflecting
database objects</a></p>
<pre><code>from sqlalchemy import MetaData
from sqlalchemy import Table
meta = MetaData(schema = &quot;raw_comtrade&quot;)
meta.bind = comtrade.database.engine
yearly_hs2 = Table(&#39;yearly_hs2&#39;, meta, autoload_with=comtrade.database.engine)</code></pre>
<p>SQL Alchemy has an <a
href="https://docs.sqlalchemy.org/en/14/orm/extensions/automap.html">automap</a>
feature which generates mapped classes and relationships from a database
schema.</p>
<p>I used <a
href="https://pypi.org/project/sqlacodegen/">sqlacodegen</a> to
automatically generate python code from an existing PostGreSQl database
table as follows</p>
<pre><code>sqlacodegen --schema raw_comtrade --tables yearly_hs2 postgresql://rdb@localhost/biotrade</code></pre>
<div id="check-for-table-existence" class="section level3">
<h3>Check for table existence</h3>
<p>Paul’s <a href="https://stackoverflow.com/a/69224576/2641825">SO
Answer</a>. SQL Alchemy’s recommended way to check for the presence of a
table is to create an inspector object and use its
<code>has_table()</code> method. The following example was copied from
<a
href="https://docs.sqlalchemy.org/en/14/core/reflection.html#sqlalchemy.engine.reflection.Inspector.has_table">sqlalchemy.engine.reflection.Inspector.has_table</a>,
with the addition of an SQLite engine to make it reproducible:</p>
<pre><code>from sqlalchemy import create_engine, inspect
from sqlalchemy import MetaData, Table, Column, Text
engine = create_engine(&#39;sqlite://&#39;)
meta = MetaData()
meta.bind = engine
user_table = Table(&#39;user&#39;, meta, 
                   Column(&quot;name&quot;, Text),
                   Column(&quot;full_name&quot;, Text))
user_table.create()
inspector = inspect(engine)
inspector.has_table(&#39;user&#39;)</code></pre>
<p>You can also use the <code>user_table</code> metadata element
<code>name</code> to check if it exists as such:</p>
<pre><code>inspector.has_table(user_table.name)</code></pre>
</div>
<div id="connection" class="section level3">
<h3>Connection</h3>
<p>Create a connection and execute a select statement, it’s a read only
operation</p>
<p>Create a connection and execute a create statement followed by a
commit:</p>
<pre><code>with engine.connect() as conn:
    if not engine.dialect.has_schema(conn, schema):
        conn.execute(CreateSchema(schema))
        conn.commit()</code></pre>
</div>
<div id="migration-to-version-2" class="section level3">
<h3>Migration to version 2</h3>
<ul>
<li><p><a
href="https://docs.sqlalchemy.org/en/14/changelog/migration_20.html"
class="uri">https://docs.sqlalchemy.org/en/14/changelog/migration_20.html</a></p>
<blockquote>
<p>“As a means of both proving the 2.0 architecture as well as allowing
a fully iterative transition environment, the entire scope of 2.0’s new
APIs and features are present and available within the 1.4 series;”</p>
</blockquote></li>
<li><p><a
href="https://docs.sqlalchemy.org/en/14/changelog/migration_20.html#migration-20-implicit-execution"
class="uri">https://docs.sqlalchemy.org/en/14/changelog/migration_20.html#migration-20-implicit-execution</a></p>
<blockquote>
<p>“For schema level patterns, explicit use of an Engine or Connection
is required.”</p>
</blockquote>
<p>with engine.connect() as connection: # create tables, requires
explicit begin and/or commit: with connection.begin():
metadata_obj.create_all(connection)</p>
<pre><code>  # reflect all tables
  metadata_obj.reflect(connection)

  # reflect individual table
  t = Table(&quot;t&quot;, metadata_obj, autoload_with=connection)

  # execute SQL statements
  result = conn.execute(t.select())</code></pre></li>
</ul>
</div>
<div id="orm-querying-guide" class="section level3">
<h3>ORM querying guide</h3>
<div id="select-where" class="section level4">
<h4>Select where</h4>
<p>SQL Alchemy <a
href="https://docs.sqlalchemy.org/en/14/orm/queryguide.html">Object
Relational Model Querying Guide</a></p>
<pre><code>from sqlalchemy import select
stmt = select(user_table).where(user_table.c.name == &#39;spongebob&#39;)
print(stmt)</code></pre>
<p>Since version 1.4 <code>.where()</code> is a synonym of
<code>.filter()</code> as explained in <a
href="https://docs.sqlalchemy.org/en/14/orm/query.html#sqlalchemy.orm.Query.where">sqlalchemy.orm.Query.where</a>.</p>
<p>To select only one column you can use <a
href="https://docs.sqlalchemy.org/en/14/core/selectable.html#sqlalchemy.sql.expression.Select.with_only_columns">Select.with_only_columns</a>:</p>
<pre><code>from sqlalchemy import MetaData, Table, Column, Text
meta = MetaData()
table = Table(&#39;user&#39;, meta, 
              Column(&quot;name&quot;, Text),
              Column(&quot;full_name&quot;, Text))
stmt = (table.select()
        .with_only_columns([table.c.name])
       )
print(stmt)</code></pre>
<p>Entering columns in the <code>select</code> method returns an error.
Although it should be valid according to the documentation.</p>
<pre><code>print(table.select([table.c.name]))
# ArgumentError: SQL expression for WHERE/HAVING role expected, 
# got [Column(&#39;name&#39;, Text(), table=&lt;user&gt;)].</code></pre>
</div>
<div id="insert" class="section level4">
<h4>Insert</h4>
<p><a
href="https://docs.sqlalchemy.org/en/14/core/dml.html#sqlalchemy.sql.expression.insert">Insert</a>
some data into the <code>user</code> table</p>
<pre><code>from sqlalchemy import insert
from sqlalchemy.orm import Session
stmt = (
    insert(user_table).
    values(name=&#39;Bob&#39;, full_name=&#39;Sponge Bob&#39;)
)
with Session(engine) as session:
    result = session.execute(stmt)
    session.commit()</code></pre>
</div>
</div>
<div id="orm-query-to-pandas" class="section level3">
<h3>ORM query to pandas</h3>
<p>The <a
href="https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-sql-method">pandas.to_sql</a>
method uses sqlalchemy to write pandas data frame to a PostgreSQL
database.</p>
<blockquote>
<p>“The pandas.io.sql module provides a collection of query wrappers to
both facilitate data retrieval and to reduce dependency on DB-specific
API. Database abstraction is provided by SQLAlchemy if installed. In
addition you will need a driver library for your database. Examples of
such drivers are psycopg2 for PostgreSQL or pymysql for MySQL. For
SQLite this is included in Python’s standard library by default.”</p>
</blockquote>
<div id="table.select-select-or-a-session" class="section level4">
<h4>table.select(), select() or a session</h4>
<p>Repeat the example table defined above, read the result of a <a
href="https://docs.sqlalchemy.org/en/14/tutorial/data_select.html#the-select-sql-expression-construct">select</a>
statement into a pandas data frame:</p>
<pre><code>import pandas
from sqlalchemy import create_engine
from sqlalchemy import MetaData, Table, Column, Text
from sqlalchemy.orm import Session
# Define metadata and create the table
engine = create_engine(&#39;sqlite://&#39;)
meta = MetaData()
meta.bind = engine
user_table = Table(&#39;user&#39;, meta,
                   Column(&quot;name&quot;, Text),
                   Column(&quot;full_name&quot;, Text))
user_table.create()
# Insert data into the user table
stmt = user_table.insert().values(name=&#39;Bob&#39;, full_name=&#39;Sponge Bob&#39;)
with Session(engine) as session:
    result = session.execute(stmt)
    session.commit()
# Select data into a pandas data frame
stmt = user_table.select().where(user_table.c.name == &#39;Bob&#39;)
df = pandas.read_sql_query(stmt, engine)</code></pre>
<p>Another way importing the select statement:</p>
<pre><code>from sqlalchemy import select
stmt = select(user_table).where(user_table.c.name == &#39;Bob&#39;)
df = pandas.read_sql_query(stmt, engine)</code></pre>
<p>Another way using a session</p>
<pre><code>with Session(engine) as session:
    df2 = pandas.read_sql(session.query(user_table).filter(user_table.name==&quot;Bob&quot;).statement, session.bind)</code></pre>
<p>Read the whole table into pandas</p>
<pre><code>df3 = pandas.read_sql_table(&quot;user&quot;, engine)</code></pre>
<p><a href="https://stackoverflow.com/a/69812326/2641825">Stack Overflow
Answer</a></p>
</div>
<div id="define-and-insert-the-iris-dataset" class="section level4">
<h4>Define and insert the iris dataset</h4>
<p>Define an ORM structure for the iris dataset, then use pandas to
insert the data into an SQLite database. Pandas inserts with
<code>if_exists="append"</code> argument so that it keeps the structure
defined in SQL Alchemy.</p>
<pre><code>import seaborn
import pandas
from sqlalchemy import create_engine
from sqlalchemy import MetaData, Table, Column, Text, Float
from sqlalchemy.orm import Session</code></pre>
<p>Define metadata and create the table</p>
<pre><code>engine = create_engine(&#39;sqlite://&#39;)
meta = MetaData()
meta.bind = engine
iris_table = Table(&#39;iris&#39;,
                   meta,
                   Column(&quot;sepal_length&quot;, Float),
                   Column(&quot;sepal_width&quot;, Float),
                   Column(&quot;petal_length&quot;, Float),
                   Column(&quot;petal_width&quot;, Float),
                   Column(&quot;species&quot;, Text))
iris_table.create()</code></pre>
<p>Load data into the table</p>
<pre><code>iris = seaborn.load_dataset(&quot;iris&quot;)
iris.to_sql(name=&quot;iris&quot;,
            con=engine,
            if_exists=&quot;append&quot;,
            index=False,
            chunksize=10 ** 6,
            )</code></pre>
</div>
<div id="unique-values" class="section level4">
<h4>Unique values</h4>
<p>The SQL ALchemy <code>iris_table</code> from above can be used to
build a select statement that extracts unique values:</p>
<pre><code>from sqlalchemy import distinct, select
stmt = select(distinct(iris_table.c.species))
df = pandas.read_sql_query(stmt, engine)</code></pre>
</div>
</div>
</div>
<div id="postgresql" class="section level2">
<h2>PostgreSQL</h2>
<p>Create a database engin with SQLalchemy</p>
<pre><code>from sqlalchemy import create_engine
engine = create_engine(&#39;postgresql://myusername:mypassword@myhost:5432/mydatabase&#39;)</code></pre>
<p>Blogs and Stackoverflow</p>
<ul>
<li><p><a
href="https://hakibenita.com/fast-load-data-python-postgresql">Load data
into postgreSQL using python</a> (without pandas)</p></li>
<li><p><a
href="https://medium.com/@apoor/quickly-load-csvs-into-postgresql-using-python-and-pandas-9101c274a92f">Load
CSVs into PostgreSQL using python and pandas</a></p></li>
<li><p><a
href="https://stackoverflow.com/questions/413228/pygresql-vs-psycopg2">SO
question pygresql-vs-psycopg2</a></p></li>
<li><p><a
href="https://medium.com/poka-techblog/5-different-ways-to-backup-your-postgresql-database-using-python-3f06cea4f51">5
ways to backup your postgreSQl database using python</a> Mentions the <a
href="https://pypi.org/project/sh/">sh package</a>, a subprocess
replacement.</p></li>
</ul>
</div>
<div id="sqlite" class="section level2">
<h2>SQLite</h2>
<p>Create an SQLITE in memory database and add a table to it.</p>
<pre><code>In [17]: from sqlalchemy import create_engine, inspect
    ...: from sqlalchemy import MetaData, Table, Column, Text
    ...: engine = create_engine(&#39;sqlite://&#39;)
    ...: meta = MetaData()
    ...: meta.bind = engine
    ...: user_table = Table(&#39;user&#39;, meta, Column(&quot;name&quot;, Text))
    ...: user_table.create()
    ...: inspector = inspect(engine)
    ...: inspector.has_table(&#39;user&#39;)
Out[17]: True</code></pre>
<p>Create a file based database at a specific path:</p>
<pre><code># absolute path
e = create_engine(&#39;sqlite:////path/to/database.db&#39;)</code></pre>
</div>
</div>
<div id="editors" class="section level1">
<h1>Editors</h1>
<div id="spyder" class="section level2">
<h2>Spyder</h2>
<p>I have set the following shortcuts to be similar to RStudio:</p>
<ul>
<li><p>Ctrl+H find and replace dialog</p></li>
<li><p>Ctrl+R run selection or current line</p></li>
<li><p>Ctrl+Shift+C comment/uncomment code block</p></li>
<li><p>F1 inspect current object (i.e. display function and classes
documentation)</p></li>
<li><p>F2 go to function definition</p></li>
<li><p>Spyder has a data frame explorer <a
href="https://docs.spyder-ide.org/current/panes/variableexplorer.html#dataframes"
class="uri">https://docs.spyder-ide.org/current/panes/variableexplorer.html#dataframes</a></p>
<blockquote>
<p>“DataFrames, like Numpy arrays, display in a viewer where you can
show or hide”heatmap” colors, change the format and resize the rows and
columns either manually or automatically”</p>
</blockquote></li>
</ul>
</div>
<div id="vim" class="section level2">
<h2>Vim</h2>
<p>I use Vim to edit python code and vim-slime to send the code to an
ipython interpreter that runs inside a tmux pane. For more information,
see my page on <a href="vim.html">vim.html</a>.</p>
</div>
</div>
<div id="input-output" class="section level1">
<h1>Input Output</h1>
<div id="comparison-of-io-files-formats" class="section level2">
<h2>Comparison of IO files formats</h2>
<ul>
<li><p>CSV minimal common denominator works every where. Great for small
datasets to be shared across many languages and platforms.</p></li>
<li><p>NetCDF Supports rich metadata, complex data types, and is
especially good at handling large datasets efficiently. Also supports
various types of compression.</p></li>
<li><p>Parquet Columnar storage, efficient compression, and encoding
schemes. Optimized for query performance.</p></li>
</ul>
</div>
<div id="csv" class="section level2">
<h2>CSV</h2>
<p>Read and write csv</p>
<div id="compressed-csv" class="section level3">
<h3>Compressed csv</h3>
<p>Write a compressed csv file as a gzip archive</p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;x&#39;:range(0,3), &#39;y&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})
df.to_csv(&quot;/tmp/df.csv.gz&quot;, index=False, compression=&quot;gzip&quot;)</code></pre>
<p>Write a compressed csv file as a zip archive, using a dict with the
option “archive_name” (works only for the zip format)</p>
<pre><code>compression_opts = dict(method=&#39;zip&#39;, archive_name=&#39;out.csv&#39;)
df.to_csv(&#39;/tmp/df.csv.zip&#39;, index=False, compression=compression_opts)</code></pre>
<p>Read compressed csv files</p>
<pre><code>df1 = pandas.read_csv(&quot;/tmp/df.csv.gz&quot;)
df.equals(df1)
df2 = pandas.read_csv(&quot;/tmp/df.csv.zip&quot;)
df.equals(df2)</code></pre>
<div id="many-files-in-one-zip-archive" class="section level4">
<h4>Many files in one zip archive</h4>
<p><code>pandas.read_csv</code> can only read zip archive that contain
one file only. If there are more than one file in the archive, you can
use a <code>ZipFile</code> object to provide access to the correct file
inside the archive, see <a
href="https://stackoverflow.com/a/56786517/2641825">SO answer</a>.</p>
<pre><code>import zipfile
import pandas
zf = zipfile.ZipFile(&quot;archive_name.zip&quot;)
print(&quot;Files in the archive:&quot;, zf.namelist())
df = pandas.read_csv(zf.open(&quot;file_name.csv&quot;))</code></pre>
</div>
</div>
<div id="pyarrow.csv" class="section level3">
<h3>pyarrow.csv</h3>
<ul>
<li><p><a href="https://en.wikipedia.org/wiki/CPU_time"
class="uri">https://en.wikipedia.org/wiki/CPU_time</a></p>
<blockquote>
<p>“If a program uses parallel processing, total CPU time for that
program would be more than its elapsed real time.”</p>
</blockquote></li>
</ul>
</div>
<div id="from-an-api" class="section level3">
<h3>From an API</h3>
<p>Pandas data frames can be used to read CSV files from the <a
href="https://comtrade.un.org/Data/">Comtrade data API</a>. For example,
using the default API URL for all countries:</p>
<pre><code>import pandas
df1 = pandas.read_csv(&#39;http://comtrade.un.org/api/get?max=500&amp;type=C&amp;freq=A&amp;px=HS&amp;ps=2020&amp;r=all&amp;p=0&amp;rg=all&amp;cc=TOTAL&amp;fmt=csv&#39;)

df2 = pandas.read_csv(&#39;http://comtrade.un.org/api/get?max=500&amp;type=C&amp;freq=A&amp;px=HS&amp;ps=2020&amp;r=all&amp;p=0&amp;rg=all&amp;cc=01&amp;fmt=csv&#39;,
                       # Force the id column to remain a character column,
                       # otherwise str &quot;01&quot; becomes an int 1.
                       dtype={&#39;Commodity Code&#39;: str, &#39;bli&#39;: str})</code></pre>
<p>Then use df.to_csv to write the data frame to a csv file</p>
<pre><code> df1.to_csv(&quot;/tmp/comtrade.csv&quot;)</code></pre>
</div>
</div>
<div id="data-sources" class="section level2">
<h2>Data sources</h2>
<div id="eurostat" class="section level3">
<h3>Eurostat</h3>
<p>Load Eurostat population projection data Eurostat tab separated
values have a peculiar way to be a mix of tab separated and command
separated values. This is annoying when loading data into pandas.</p>
<p>Here is how to load the population projection dataset available at <a
href="https://ec.europa.eu/eurostat/databrowser/view/PROJ_23NP/"
class="uri">https://ec.europa.eu/eurostat/databrowser/view/PROJ_23NP/</a>
into pandas</p>
</div>
</div>
<div id="feather" class="section level2">
<h2>Feather</h2>
<p>Load a sample data frame and save it to a feather file</p>
<pre><code>import pandas
import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
iris.to_feather(&quot;/tmp/iris.feather&quot;)</code></pre>
<p>Load the data from the feather file</p>
<pre><code>iris2 = pandas.read_feather(&quot;/tmp/iris.feather&quot;)
iris2.equals(iris)</code></pre>
</div>
<div id="gamms-gdx" class="section level2">
<h2>Gamms GDX</h2>
<p>GDX files store data for the GAMMS modelling platform. They can be
loaded into pandas data frames with the gdxpds package as explained in
the <a
href="https://nrel.github.io/gdx-pandas/overview.html#direct-conversion">gdpxpds
documentation</a>:</p>
<pre><code>import gdxpds
gdx_file = &#39;C:\path_to_my_gdx\data.gdx&#39;
dataframes = gdxpds.to_dataframes(gdx_file)
for symbol_name, df in dataframes.items():
    print(&quot;Doing work with {}.&quot;.format(symbol_name))</code></pre>
</div>
<div id="markdown" class="section level2">
<h2>Markdown</h2>
<p>Print a data frame to markdown, without the scientific notation <a
href="https://stackoverflow.com/questions/66713432/suppress-scientific-notation-in-to-markdown-in-pandas"
class="uri">https://stackoverflow.com/questions/66713432/suppress-scientific-notation-in-to-markdown-in-pandas</a></p>
<pre><code>import pandas
df = pandas.DataFrame({&quot;x&quot; : [1,1e7], &quot;y&quot;:[1e-5,100]})
print(df.to_markdown())
print(df.to_markdown(floatfmt=&#39;.0f&#39;, index=False))</code></pre>
</div>
<div id="netcdf" class="section level2">
<h2>Netcdf</h2>
<p>You can use the command line tool ncdump to view the content of
netcdf files</p>
<pre><code>sudo apt install netcdf-bin
ncdump fuel.nc</code></pre>
<ul>
<li><a
href="https://stackoverflow.com/questions/35422862/speeding-up-reading-of-very-large-netcdf-file-in-python">How
to read netcdf files in chunks with Xarray and Dask</a></li>
</ul>
</div>
<div id="open-a-text-file" class="section level2">
<h2>Open a text file</h2>
<p>Open a text file and print lines containing “error”</p>
<pre><code>with open(&#39;filename.txt&#39;, &#39;r&#39;) as file:
    for line in file:
        if &quot;error&quot; in line.lower():
            print(line)</code></pre>
</div>
<div id="parquet" class="section level2">
<h2>Parquet</h2>
<p>Write to one file defaults to [snappy compression](<a
href="https://en.wikipedia.org/wiki/Snappy_(compression)"
class="uri">https://en.wikipedia.org/wiki/Snappy_(compression)</a></p>
<pre><code>import pandas
import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
iris.to_parquet(&quot;/tmp/iris.parquet&quot;)</code></pre>
<p>Read back the file</p>
<pre><code>iris3 = pandas.read_parquet(&quot;/tmp/iris.parquet&quot;)
iris3.equals(iris)</code></pre>
<p>You can also use gzip compression for a smaller file size (but slower
read and write times)</p>
<pre><code>iris.to_parquet(&quot;/tmp/iris.parquet.gzip&quot;, compression=&#39;gzip&#39;) </code></pre>
<div id="partition-column" class="section level3">
<h3>Partition column</h3>
<p>Write to multiple files along a column used as partition variable</p>
<pre><code>iris.to_parquet(&quot;/tmp/iris&quot;,partition_cols=&quot;species&quot;) </code></pre>
<p>The partitioned dataset is saved under a sub directory for each
unique value of the partition variable. For example there is a sub
directory for each species in the <code>/tmp/iris</code> directory</p>
<pre><code>iris
├── species=setosa
│   └── 1609afe5535d4e2b94e65f1892210269.parquet
├── species=versicolor
│   └── 18dd7ae6d0794fd48dad37bf8950d813.parquet
└── species=virginica
    └── e0a9786251f54eed9f16380c8f5c3db3.parquet</code></pre>
<p>On can read a single file in memory</p>
<pre><code>virginica = pandas.read_parquet(&quot;/tmp/iris/species=virginica&quot;)</code></pre>
<p>Note it has lost the species column</p>
<p>Read all files in memory</p>
<pre><code>iris4 = pandas.read_parquet(&quot;/tmp/iris&quot;)</code></pre>
<p>Note the data frame is slightly different. Values are the same but
the species columns has become a categorical variable.</p>
<pre><code>iris4.equals(iris)
# False
iris4.species
# ...
# Name: species, Length: 150, dtype: category
# Categories (3, object): [&#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39;]</code></pre>
<p>Changing it back to a strings makes the 2 data frames equals
again.</p>
<pre><code>iris4[&quot;species&quot;] = iris4[&quot;species&quot;].astype(&quot;str&quot;)
iris4.equals(iris)
# True</code></pre>
</div>
<div id="filters" class="section level3">
<h3>Filters</h3>
<p>Read only part of the content from parquet files with a filter. See
<code>help(pyarrow.parquet.read_pandas)</code> for arguments concerning
the pyarrow engine. Reusing example files from the previous section:</p>
<pre><code>selection = [(&quot;species&quot;, &quot;in&quot;, [&quot;versicolor&quot;,&quot;virginica&quot;])]
iris5 = pandas.read_parquet(&quot;/tmp/iris&quot;, filters=selection)</code></pre>
<p>In fact, the filter variable doesn’t have to be a partition
variable.</p>
<pre><code>selection = [(&quot;species&quot;, &quot;in&quot;, [&quot;versicolor&quot;,&quot;virginica&quot;]), 
             (&quot;petal_width&quot;, &quot;&gt;&quot;, 2.4)]
iris6 = pandas.read_parquet(&quot;/tmp/iris&quot;, filters=selection)</code></pre>
<p>This works as well on the single file version</p>
<pre><code>iris7 = pandas.read_parquet(&quot;/tmp/iris.parquet&quot;, filters=selection)
# Change column type for the comparison
iris6[&quot;species&quot;] = iris6[&quot;species&quot;].astype(&quot;str&quot;)
iris7.equals(iris6)</code></pre>
<p>Depending on whether or not the query is on the partition variable,
read time can be increased by a lot. See experiment in the next
section.</p>
</div>
<div
id="experiment-with-the-parquet-format-using-filters-and-partition-columns."
class="section level3">
<h3>Experiment with the parquet format using filters and partition
columns.</h3>
<p>Note the detaset to perform these comparisons is not made available
here. I keep these for information purposes.</p>
<p>Compare a read of 2 countries with the read of the whole dataset</p>
<pre><code># start_time = timeit.default_timer()
# selection = [(&quot;reporter&quot;, &quot;in&quot;, [&quot;France&quot;,&quot;Germany&quot;])]
# ft_frde = pandas.read_parquet(la_fo_data_dir / &quot;comtrade_forest_footprint.parquet&quot;,
#                                             filters=selection)
# print(&quot;Reading 2 countries took:&quot;,timeit.default_timer() - start_time)
#
# start_time = timeit.default_timer()
# ft2 = pandas.read_parquet(la_fo_data_dir / &quot;comtrade_forest_footprint.parquet&quot;)
# print(&quot;Reading the whole dataset took:&quot;,timeit.default_timer() - start_time)
#</code></pre>
<p>Time comparison when the reporter is used as a partition column It’s
about 10 times faster!</p>
<pre><code># ft.to_parquet(&quot;/tmp/ft&quot;, partition_cols=&quot;reporter&quot;)
# start_time = timeit.default_timer()
# selection = [(&quot;reporter&quot;, &quot;in&quot;, [&quot;France&quot;,&quot;Germany&quot;])]
# ft_frde2 = pandas.read_parquet(&quot;/tmp/ft&quot;, filters=selection)
# print(&quot;Reading 2 countries took:&quot;,timeit.default_timer() - start_time)
#
# # Save to a compressed csv file in biotrade_data
# # file_path = la_fo_data_dir / &quot;comtrade_forest_footprint.csv.gz&quot;
# # ft.to_csv(file_path, index=False, compression=&quot;gzip&quot;)</code></pre>
<p>Also try the feather format.</p>
<pre><code># # Save to a feather file
# ft.to_feather(la_fo_data_dir / &quot;comtrade_forest_footprint.feather&quot;)
#
# # Read time of a feather file
# start_time = timeit.default_timer()
# ft_frde2 = pandas.read_feather(la_fo_data_dir / &quot;comtrade_forest_footprint.feather&quot;)
# print(&quot;Reading a feather file took:&quot;,timeit.default_timer() - start_time)</code></pre>
</div>
<div id="what-is-the-difference-between-apache-arrow-and-apache-parquet"
class="section level3">
<h3>What is the difference between Apache Arrow and Apache Parquet?</h3>
<p><a
href="https://arrow.apache.org/faq/#what-about-the-feather-file-format">Apache
Arrow FAQ</a></p>
<blockquote>
<p>Parquet is a storage format designed for maximum space efficiency,
using advanced compression and encoding techniques. It is ideal when
wanting to minimize disk usage while storing gigabytes of data, or
perhaps more. This efficiency comes at the cost of relatively expensive
reading into memory, as Parquet data cannot be directly operated on but
must be decoded in large chunks.</p>
</blockquote>
<blockquote>
<p>Conversely, Arrow is an in-memory format meant for direct and
efficient use for computational purposes. Arrow data is not compressed
(or only lightly so, when using dictionary encoding) but laid out in
natural format for the CPU, so that data can be accessed at arbitrary
places at full speed.</p>
</blockquote>
<blockquote>
<p>Therefore, Arrow and Parquet complement each other and are commonly
used together in applications. Storing your data on disk using Parquet
and reading it into memory in the Arrow format will allow you to make
the most of your computing hardware.”</p>
</blockquote>
<blockquote>
<p>What about “Arrow files” then?</p>
</blockquote>
<blockquote>
<p>Apache Arrow defines an inter-process communication (IPC) mechanism
to transfer a collection of Arrow columnar arrays (called a “record
batch”). It can be used synchronously between processes using the Arrow
“stream format”, or asynchronously by first persisting data on storage
using the Arrow “file format”.</p>
</blockquote>
<blockquote>
<p>The Arrow IPC mechanism is based on the Arrow in-memory format, such
that there is no translation necessary between the on-disk
representation and the in-memory representation. Therefore, performing
analytics on an Arrow IPC file can use memory-mapping, avoiding any
deserialization cost and extra copies.</p>
</blockquote>
<blockquote>
<p>Some things to keep in mind when comparing the Arrow IPC file format
and the Parquet format:</p>
</blockquote>
<blockquote>
<pre><code>Parquet is designed for long-term storage and archival purposes, meaning
if you write a file today, you can expect that any system that says they
can “read Parquet” will be able to read the file in 5 years or 10 years.
While the Arrow on-disk format is stable and will be readable by future
versions of the libraries, it does not prioritize the requirements of
long-term archival storage.</code></pre>
</blockquote>
<blockquote>
<pre><code>Reading Parquet files generally requires efficient yet relatively complex
decoding, while reading Arrow IPC files does not involve any decoding
because the on-disk representation is the same as the in-memory
representation.</code></pre>
</blockquote>
<blockquote>
<pre><code>Parquet files are often much smaller than Arrow IPC files because of the
columnar data compression strategies that Parquet uses. If your disk
storage or network is slow, Parquet may be a better choice even for
short-term storage or caching.</code></pre>
</blockquote>
</div>
<div id="one-large-parquet-file-or-many-smaller-files"
class="section level3">
<h3>One large parquet file or many smaller files?</h3>
<p><a href="https://stackoverflow.com/a/59535659/2641825">Is it better
to have one large parquet file or lots of smaller parquet files?</a></p>
<blockquote>
<p>“Notice that Parquet files are internally split into row groups <a
href="https://parquet.apache.org/documentation/latest/"
class="uri">https://parquet.apache.org/documentation/latest/</a> So by
making parquet files larger, row groups can still be the same if your
baseline parquet files were not small/tiny. There is no huge direct
penalty on processing, but opposite, there are more opportunities for
readers to take advantage of perhaps larger/ more optimal row groups if
your parquet files were smaller/tiny for example as row groups can’t
span multiple parquet files.”</p>
</blockquote>
<blockquote>
<p>“Also larger parquet files don’t limit parallelism of readers, as
each parquet file can be broken up logically into multiple splits
(consisting of one or more row groups).”</p>
</blockquote>
<blockquote>
<p>“The only downside of larger parquet files is it takes more memory to
create them. So you can watch out if you need to bump up Spark
executors’ memory.”</p>
</blockquote>
</div>
<div id="see-also" class="section level3">
<h3>See also</h3>
<ul>
<li><p>It’s not possible to <a
href="https://stackoverflow.com/questions/50456673/storing-multiple-dataframes-of-different-widths-with-parquet">store
multiple data frames of different widths with parquet</a></p></li>
<li><p><a
href="https://stackoverflow.com/questions/59972588/control-row-groups-with-pandas-dataframe-to-parquet">Control
row groups size with pandas df.to_parquet</a></p></li>
<li><p><a
href="https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d">Benchmark
of feather, hdf, msgpack, parquet and pickle</a></p></li>
</ul>
</div>
</div>
<div id="pickle" class="section level2">
<h2>Pickle</h2>
<p>Store a dictionary to a pickle file</p>
<pre><code>import pickle
d = {&quot;lkj&quot;:1}
with open(&#39;/tmp/d.pickle&#39;, &#39;wb&#39;) as file:
    pickle.dump(d, file)</code></pre>
<p>Read from a pickle file</p>
<pre><code>with open(&quot;/tmp/d.pickle&quot;, &quot;rb&quot;) as file:
    e = pickle.load(file)
d == e</code></pre>
</div>
</div>
<div id="neural-networks" class="section level1">
<h1>Neural Networks</h1>
<div id="pytorch" class="section level2">
<h2>Pytorch</h2>
<p>Print the size of the output layer</p>
<pre><code>import torch
import torch.nn as nn
x = torch.randn(28,28).view(-1,1,28,28)
model = nn.Sequential(
      nn.Conv2d(1, 32, (3, 3)),
      nn.ReLU(),
      nn.MaxPool2d((2, 2)),
      nn.Conv2d(32, 64, (3, 3)),
)
print(model(x).shape)</code></pre>
</div>
</div>
<div id="objects" class="section level1">
<h1>Objects</h1>
<div id="aa-object-types" class="section level2">
<h2>AA object types</h2>
<p><code>type()</code> displays the type of an object.</p>
<pre><code>i = 1
print(type(i))
# &lt;type &#39;int&#39;&gt;
x = 1.2
print(type(x))
# &lt;type &#39;float&#39;&gt;
t = (1,2)
print(type(t))
# &lt;type &#39;tuple&#39;&gt;
l = [1,2]
print(type(l))
# &lt;type &#39;list&#39;&gt;</code></pre>
<div id="check-object-types" class="section level3">
<h3>Check object types</h3>
<p>Check if a variable is a string, int or float</p>
<pre><code>isinstance(&quot;a&quot;, str)
isinstance(1,  int)
isinstance(1.2, float)</code></pre>
</div>
<div id="convert-between-object-types" class="section level3">
<h3>Convert between object types</h3>
<p>Character to numeric</p>
<pre><code>int(&quot;3&quot;)
float(&quot;3.33&quot;)
int(&quot;3.33&quot;)</code></pre>
<p>Numeric to character</p>
<pre><code>str(2)</code></pre>
<p>Convert a list to a comma separated string</p>
<pre><code>&quot;,&quot;.join([&quot;a&quot;,&quot;b&quot;,&quot;c&quot;])</code></pre>
<p>Another example with the list of the last 5 years</p>
<pre><code>import datetime
year = datetime.datetime.today().year
# Create a numeric list of years
YEARS = [year - i for i in range(1,6)]
# Convert each element of the list to a string
YEARS = [str(x) for x in YEARS]
&quot;,&quot;.join(YEARS)</code></pre>
</div>
<div id="dictionary" class="section level3">
<h3>Dictionary</h3>
<p>Create a dictionary with curly braces</p>
<pre><code>ceci = {&#39;x&#39;:1, &#39;y&#39;:2, &#39;z&#39;:3}</code></pre>
<p>Converts 2 lists into a dictionary with the <code>dict</code> built
in function</p>
<pre><code>dict(zip([&#39;x&#39;, &#39;y&#39;, &#39;z&#39;], [1, 2, 3]))</code></pre>
<p>Dictionary comprehension</p>
<pre><code>d = {n: True for n in range(5)}</code></pre>
<p>Loop over the key and values of a dictionary</p>
<pre><code>for key, value in ceci.items():
    print(key, &quot;has the value&quot;, value)</code></pre>
<p>Invert keys and values</p>
<pre><code>{value:key for key,value in ceci.items()}</code></pre>
</div>
<div id="iterator" class="section level3">
<h3>Iterator</h3>
<p>The <code>map</code> function makes an iterator object of type
<code>map</code></p>
<pre><code>iter = map(lambda x:x+1,range(3))
type(iter)
[i for i in iter]</code></pre>
</div>
<div id="list" class="section level3">
<h3>List</h3>
<p>Create a list</p>
<pre><code>l1 = [1, 2, 3]
l2 = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]</code></pre>
<p>Create a list of strings using split (seen in <a
href="https://stackoverflow.com/a/52110266/2641825">this answer</a>)</p>
<pre><code>&quot;slope, intercept, r_value, p_value, std_err&quot;.split(&quot;, &quot;)</code></pre>
<div id="remove-an-item-from-a-list" class="section level4">
<h4>Remove an item from a list</h4>
<p><a href="https://stackoverflow.com/a/31077838/2641825">Remove an
element from a list of strings</a></p>
<pre><code>myList = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]
myList.remove(&#39;c&#39;)
myList
[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;]</code></pre>
</div>
<div id="list-of-tuples" class="section level4">
<h4>List of tuples</h4>
<p><a
href="https://stackoverflow.com/questions/10632839/transform-list-of-tuples-into-a-flat-list-or-a-matrix">How
to flatten a list of tuples</a></p>
<pre><code>nested_list = [(1, 2, 4), (0, 9)]</code></pre>
<p>Using <code>reduce</code>:</p>
<pre><code>reduce(lambda x,y:x+y, map(list, nested_list))                                                                                                                              
[1, 2, 4, 0, 9]</code></pre>
<p>Using itertools.chain:</p>
<pre><code>import itertools
list(itertools.chain.from_iterable(nested_list))</code></pre>
<p>Using <code>extend</code>:</p>
<pre><code>flat_list = []
for a_tuple in nested_list:
    flat_list.extend(list(a_tuple))                                                                                                                                     
flat_list
[1, 2, 4, 0, 9]</code></pre>
</div>
</div>
<div id="set-operations" class="section level3">
<h3>Set operations</h3>
<div id="difference-between-sets" class="section level4">
<h4>Difference between sets</h4>
<p>Difference between two sets:</p>
<pre><code>set1 = {1,2,3}
set2 = {2,3,4}
set1 - set2
# {1}
set2 - set1
# {4}</code></pre>
</div>
<div id="intersection-and-common-set-elements" class="section level4">
<h4>Intersection and common set elements</h4>
<p>Return a new set with elements common to the set and all others.</p>
<pre><code>intersection(*others)
set &amp; other &amp; ...

bli = {1,2,3}
bli.intersection({1,2})
# {1, 2}
bli.intersection({1,2}, {1})

difference(*others)
set - other - ...

    Return a new set with elements in the set that are not in the others.

symmetric_difference(other)
set ^ other

    Return a new set with elements in either the set or other but not both.</code></pre>
</div>
<div id="subset-and-superset" class="section level4">
<h4>Subset and superset</h4>
<p>Instances of <a
href="https://docs.python.org/3/library/stdtypes.html#set">set</a>
provide the following operations:</p>
<pre><code>issubset(other)
set &lt;= other</code></pre>
<p>Test whether every element in the set is in other. For example <a
href="https://stackoverflow.com/a/3931655/2641825">SO answer using
issubset</a></p>
<pre><code>l = [1,2,3]
m = [1,2]
set(m).issubset(l)
# True

seta = {1,2,3}
setb = {1,2}
setb.issubset(seta)

set &lt; other

    Test whether the set is a proper subset of other, that is, set &lt;= other and set != other.

issuperset(other)
set &gt;= other

    Test whether every element in other is in the set.

set &gt; other

    Test whether the set is a proper superset of other, that is, set &gt;= other and set != other.</code></pre>
</div>
<div id="union-of-sets" class="section level4">
<h4>Union of sets</h4>
<p>Return a new set with elements from the set and all others.</p>
<pre><code>union(*others)
set | other | ...</code></pre>
<p>Example</p>
<pre><code>{1,2}.union({3,4}, {10})</code></pre>
<p>Note the following perform a union:</p>
<pre><code>set(range(3,10)).union(set(range(5)))
set(range(3,10)) | set(range(5))</code></pre>
<p>But this is not a union:</p>
<pre><code>set(range(3,10)) or set(range(5))</code></pre>
</div>
</div>
<div id="type-hints" class="section level3">
<h3>Type hints</h3>
<p>For example</p>
<pre><code>import panda
from pathlib import Path
def csv_to_df(path: [str, Path]) -&gt; pandas.DataFrame:
    return pd.read_csv(path)</code></pre>
<ul>
<li><p>Issue with <a
href="https://medium.com/virtuslab/pandas-stubs-how-we-enhanced-pandas-with-type-annotations-1f69ecf1519e"
class="uri">https://medium.com/virtuslab/pandas-stubs-how-we-enhanced-pandas-with-type-annotations-1f69ecf1519e</a></p>
<p>pandas.DataFrame and spark.sql.DataFrame</p></li>
</ul>
</div>
</div>
<div id="meta-programming" class="section level2">
<h2>Meta programming</h2>
<div id="class-decorators" class="section level3">
<h3>Class decorators</h3>
<p>See also function decorators in another section below.</p>
</div>
<div id="meta-class" class="section level3">
<h3>Meta class</h3>
<ul>
<li><p><a
href="https://stackoverflow.com/questions/2005878/what-are-python-metaclasses-useful-for"
class="uri">https://stackoverflow.com/questions/2005878/what-are-python-metaclasses-useful-for</a></p>
<blockquote>
<p>according to this Metaclass programming in Python you might not need
them ( yet )</p>
</blockquote>
<blockquote>
<blockquote>
<p>Metaclasses are deeper magic than 99% of users should ever worry
about. If you wonder whether you need them, you don’t (the people who
actually need them know with certainty that they need them, and don’t
need an explanation about why).</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>– Python Guru Tim Peters</p>
</blockquote>
</blockquote></li>
<li><p><a
href="https://developer.ibm.com/tutorials/ba-metaprogramming-python/"
class="uri">https://developer.ibm.com/tutorials/ba-metaprogramming-python/</a>
provides an example with a class that has camel case and another class
that has snake case attributes.</p></li>
</ul>
</div>
</div>
<div id="programming-objects" class="section level2">
<h2>Programming objects</h2>
<div id="inheritance-and-composition" class="section level3">
<h3>Inheritance and composition</h3>
<p>Below is an example of object inheritance where a Car and a Boat
classes inherit from a Vehicle class.</p>
<pre><code>class Vehicle(object):

    def __init__(self, color, speed_max, garage=None):
        self.color = color
        self.speed_max = speed_max
        self.garage = garage

    def paint(self, new_color):
        self.color = new_color

    def go_back_home(self, new_color):
        self.position = self.go_to(self.parent.location)

class Car(Vehicle):

    def open_door(self):
        pass

class Boat(Vehicle):

    def open_balast(self):
        pass

honda = Car(&#39;bleu&#39;, 60)
gorgeoote = Boat(&#39;rouge&#39;, 30)
honda.paint(&#39;purple&#39;)</code></pre>
<p>Note that the object should be able to access it’s parent properties
through the super() method.</p>
<p>Below an example of object composition where the Garage class is
parent to many Vehicle objects.</p>
<pre><code>class Garage(object):

    def __init__(self, all_vehicles):
        self.all_vehicles = all_vehicles

    def mass_paint(self, new_color):
        for v in self.all_vehicles: v.paint(new_color)

    def build_car(self, color):
        new_car = Car(color, 90, self)
        self.all_vehicles.append(new_car)
        return new_car

    @property
    def location(self):
        return &#39;10, 18&#39;


mike = Garage([honda, gorgeoote])

mike.mass_paint()

sport_car = mike.build_car(&#39;rouge&#39;)</code></pre>
</div>
<div id="why-do-python-classes-inherit-object" class="section level3">
<h3>Why do Python classes inherit object?</h3>
<p><a
href="https://stackoverflow.com/questions/4015417/why-do-python-classes-inherit-object">Why
do Python classes inherit object?</a></p>
<blockquote>
<p>So, what should you do?</p>
</blockquote>
<blockquote>
<p>In Python 2: always inherit from object explicitly. Get the
perks.</p>
</blockquote>
<blockquote>
<p>In Python 3: inherit from object if you are writing code that tries
to be Python agnostic, that is, it needs to work both in Python 2 and in
Python 3. Otherwise don’t, it really makes no difference since Python
inserts it for you behind the scenes.</p>
</blockquote>
</div>
</div>
</div>
<div id="git" class="section level1">
<h1>Git</h1>
<p>Get the active branch name in a git repository with <a
href="https://pypi.org/project/GitPython/">GitPython</a>:</p>
<pre><code>import git
hat = git.Repo(path=&quot;~/repos/eu_cbm/eu_cbm_hat&quot;)
hat.active_branch.name</code></pre>
<p>Find the location of git repositories for libcbm_py and eu_cbm_hat,
then create git repository objects with them:</p>
<pre><code>import sys
import git
def find_sys_path(path_contains):
    &quot;&quot;&quot;Find path that contains the given characters.
    Raise an error if there&#39;s not exactly one matching path&quot;&quot;&quot;
    matching_paths = [path for path in sys.path if path_contains in path]
    if len(matching_paths) != 1:
        msg = f&quot;Expected one path containing {path_contains}, &quot;
        msg += f&quot;found {len(matching_paths)}\n&quot;
        msg += f&quot;{matching_paths}&quot;
        raise ValueError(msg)
    return matching_paths[0]
repo_eu_cbm_hat = git.Repo(find_sys_path(&quot;eu_cbm_hat&quot;))</code></pre>
<p>Checkout a branch if the repository is clean (no changes)</p>
<pre><code>def checkout_branch(git_repo:git.repo.base.Repo, branch_name:str):
    &quot;&quot;&quot;Check if a repository has any changes and checkout the given branch
    &quot;&quot;&quot;
    if git_repo.is_dirty(untracked_files=True):
        msg = f&quot;There are changes in {git_repo}.\n&quot;
        msg += f&quot;Not checking out the &#39;{branch_name}&#39; branch.&quot;
        raise RuntimeError(msg)
    git_repo.git.checkout(branch_name)
    print(f&quot;Checked out branch: {branch_name} of {git_repo}.&quot;)

#Usage
checkout_branch(repo_libcbm_py, &quot;2.x&quot;)</code></pre>
</div>
<div id="http" class="section level1">
<h1>HTTP</h1>
<div id="file-download" class="section level2">
<h2>File download</h2>
<div id="zipped-csv-files" class="section level3">
<h3>Zipped csv files</h3>
<p>The following example uses urllib.request.urlopen to download a zip
file containing Oceania’s crop production data from the FAO statistical
database. In that example, it is necessary to define a minimal header,
otherwise FAOSTAT throws an <code>Error 403: Forbidden</code>. It was
posted as a <a
href="https://stackoverflow.com/a/68804963/2641825">StackOverflow
Answer</a>.</p>
<pre><code>import shutil
import urllib.request
import tempfile

# Create a request object with URL and headers    
url = &quot;http://fenixservices.fao.org/faostat/static/bulkdownloads/Production_Crops_Livestock_E_Oceania.zip&quot;
header = {&#39;User-Agent&#39;: &#39;Mozilla/5.0 (X11; Linux x86_64) &#39;}
req = urllib.request.Request(url=url, headers=header)

# Define the destination file
dest_file = tempfile.gettempdir() + &#39;/&#39; + &#39;crop.zip&#39;
print(f&quot;File located at:{dest_file}&quot;)

# Create an http response object
with urllib.request.urlopen(req) as response:
    # Create a file object
    with open(dest_file, &quot;wb&quot;) as f:
        # Copy the binary content of the response to the file
        shutil.copyfileobj(response, f)</code></pre>
<p>Based on <a href="https://stackoverflow.com/a/48691447/2641825"
class="uri">https://stackoverflow.com/a/48691447/2641825</a> and <a
href="https://stackoverflow.com/a/66591873/2641825"
class="uri">https://stackoverflow.com/a/66591873/2641825</a>, see also
the documentation at <a
href="https://docs.python.org/3/howto/urllib2.html"
class="uri">https://docs.python.org/3/howto/urllib2.html</a></p>
</div>
<div id="json-files" class="section level3">
<h3>JSON files</h3>
<p>The following loads a JSON file into a pandas data frame from the
Comtrade API.</p>
<pre><code>import urllib.request
import json
import pandas

url_reporter = &quot;https://comtrade.un.org/Data/cache/reporterAreas.json&quot;
url_partner = &quot;https://comtrade.un.org/Data/cache/partnerAreas.json&quot;

# attempt with pandas.io, with an issue related to nested json
pandas.io.json.read_json(url_reporter, encoding=&#39;utf-8-sig&#39;)
pandas.io.json.read_json(url_partner)
# `results` is a character column containing {&#39;id&#39;: &#39;4&#39;, &#39;text&#39;: &#39;Afghanistan&#39;}.
# Is there a way to tell read_json to load the id and text columns directly instead?</code></pre>
<p><a href="https://stackoverflow.com/a/68988284/2641825">SO
answer</a></p>
<blockquote>
<p>“Since the whole processing is done in the pd.io.json.read_json
method, we cannot select the keys to direct to the actual data that we
are after. So you need to run this additional code to get your desired
results:”</p>
</blockquote>
<pre><code>df = pandas.io.json.read_json(url_reporter, encoding=&#39;utf-8-sig&#39;)
df2 = pandas.json_normalize(df.results.to_list())</code></pre>
<p>Other attempt using lower level packages</p>
<pre><code>req = urllib.request.Request(url=url_reporter)
with urllib.request.urlopen(req) as response:
    json_content = json.load(response)
    df = pandas.json_normalize(json_content[&#39;results&#39;])

In [17]: df
Out[17]:
      id                    text
0    all                     All
1      4             Afghanistan
2      8                 Albania
3     12                 Algeria
4     20                 Andorra
..   ...                     ...
252  876  Wallis and Futuna Isds
253  887                   Yemen
254  894                  Zambia
255  716                Zimbabwe
256  975                   ASEAN</code></pre>
<ul>
<li><p>Related question I asked on SO.: <a
href="https://stackoverflow.com/questions/68985729/how-to-load-a-nested-data-frame-with-pandas-io-json-read-json">How
to load a nested data frame with pandas.io.json.read_json?</a></p></li>
<li><p>Enconding issue <a
href="https://stackoverflow.com/questions/57152985/what-is-the-difference-between-utf-8-and-utf-8-sig">What
is the difference between utf-8 and utf-8-sig?</a></p></li>
<li><p><a
href="https://stackoverflow.com/questions/2223882/whats-the-difference-between-utf-8-and-utf-8-without-bom">What’s
the difference between UTF-8 and UTF-8 without BOM?</a></p></li>
</ul>
</div>
</div>
</div>
<div id="ipython" class="section level1">
<h1>ipython</h1>
<p>Add these options at the ipyhton command line to reload objects
automatically while you are coding</p>
<pre><code>%load_ext autoreload   
%autoreload 2         </code></pre>
<div id="autoindent" class="section level2">
<h2>Autoindent</h2>
<p>When pasting from another place, turn off auto indentation in
ipython</p>
<pre><code>%autoindent off</code></pre>
</div>
<div id="debugging-in-ipython" class="section level2">
<h2>Debugging in ipython</h2>
<p>Once an error occurs at the ipython command line. Press
<code>debug</code> then you can move up the stack trace with:</p>
<pre><code>`u`</code></pre>
<p>Move down the stack trace with:</p>
<pre><code>`d` </code></pre>
<p>Show code context of the error:</p>
<pre><code>`l` </code></pre>
<p>Show available variable in the current context:</p>
<pre><code>`a` </code></pre>
</div>
<div id="breakpoint" class="section level2">
<h2>Breakpoint</h2>
<p>To break at every step in a loop, use the <code>breakpoint()</code>
function in any part of the code as explained in <a
href="https://stackoverflow.com/questions/16867347/step-by-step-debugging-with-ipython">setp
by step debuging with ipython</a>.</p>
<pre><code>continue</code></pre>
</div>
<div id="profiling-in-ipython" class="section level2">
<h2>Profiling in ipython</h2>
<p>See also the main section profiling and measuring time.</p>
<p><a
href="https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-prun">Magic
prun</a>:</p>
<pre><code>%prun statement
# Store the profiler output to a file
%prun -T /tmp/profiler.txt </code></pre>
<p>Run a script with profiling enabled from the ipython console</p>
<pre><code>%run -i -p script.py</code></pre>
</div>
<div id="running-from-ipython" class="section level2">
<h2>Running from ipython</h2>
<p>Run a file from the ipython console</p>
<pre><code>%run -i test.py</code></pre>
<p><a href="https://github.com/ipython/ipython/issues/1001"
class="uri">https://github.com/ipython/ipython/issues/1001</a></p>
</div>
</div>
<div id="jupyter-notebooks-and-lab" class="section level1">
<h1>Jupyter notebooks and lab</h1>
<div id="call-bash-from-a-notebook" class="section level2">
<h2>Call bash from a notebook</h2>
<p>Prefix the bash call with an exclamation mark, for example:</p>
<pre><code>!df -h</code></pre>
<p>In fact the question mark also works from an ipython shell. See also
<a
href="https://stackoverflow.com/questions/45784499/difference-between-and-in-jupyter-notebooks">Difference
between ! and % in Jupyter Notebooks</a></p>
</div>
<div id="convert-and-execute-notebooks-programmatically"
class="section level2">
<h2>Convert and execute notebooks programmatically</h2>
<div id="at-the-shell" class="section level3">
<h3>At the shell</h3>
<p>To work from the ipython command line it’s useful to load execute the
whole notebook inside the ipython shell with</p>
<pre><code>ipython -c &quot;%run notebook.ipynb&quot;</code></pre>
<p>It’s also possible to convert the long notebooks to a python script
with:</p>
<pre><code>jupyter nbconvert --to script notebook.ipynb</code></pre>
<p>Then run the whole notebook and start an interactive shell with:</p>
<pre><code>ipython -i notebook.py</code></pre>
<p>Otherwise I also sometimes open the synchronized markdown version of
the notebook and execute a few cells using Vim slime to sent them to a
tmux pane where ipython is running.</p>
</div>
<div id="convert-notebooks-to-html" class="section level3">
<h3>Convert notebooks to html</h3>
<p>Notebooks can be converted from the File / Save and Export Notebook
As / HTML menu. Or <a
href="https://nbconvert.readthedocs.io/en/latest/usage.html#convert-html">at
the command line with nbconvert</a></p>
<pre><code>jupyter nbconvert --to html notebook.ipynb</code></pre>
</div>
<div id="from-python" class="section level3">
<h3>From python</h3>
<p>Run an ipython notebook from python using <a
href="https://nbconvert.readthedocs.io/en/latest/execute_api.html#example">nbconver</a>’s
execute API:</p>
<pre><code>import nbformat
from nbconvert.preprocessors import ExecutePreprocessor
import jupytext

####################
# Run one notebook #
####################
filename = &#39;notebook.ipynb&#39;
with open(filename) as ff:
    nb_in = nbformat.read(ff, nbformat.NO_CONVERT)

# Read a notebook from the markdown file synchronized by jupytext
nb_md = jupytext.read(&#39;notebook.md&#39;)

# Run the notebook
ep = ExecutePreprocessor(timeout=600, kernel_name=&#39;python3&#39;)
nb_out = ep.preprocess(nb_in)

# Save the output notebook
with open(filename, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f:
    nbformat.write(nb_out, f)</code></pre>
<p>Saving fails in my case.</p>
</div>
</div>
<div id="dashboards-and-widgets" class="section level2">
<h2>Dashboards and widgets</h2>
<ul>
<li><p><a href="https://github.com/voila-dashboards/voila">Voila
dashboard</a></p>
<ul>
<li>Examples dasboards and applications in the <a
href="https://voila-gallery.org/">Voilà gallery</a></li>
</ul></li>
<li><p><a
href="https://github.com/jupyter-widgets/ipywidgets">ipywidgets</a></p>
<blockquote>
<p>“interactive HTML widgets for Jupyter notebooks and the IPython
kernel.”</p>
</blockquote></li>
</ul>
<div id="interactive-widgets" class="section level3">
<h3>Interactive widgets</h3>
<p><a
href="https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html">Documentation
of interactive widgets</a></p>
<p>Create a text box</p>
<pre><code>def print_name(name):
    return(&quot;Name: &quot; + name)
interact(print_name, name=&quot;Paul&quot;)</code></pre>
<p>Create a drop down list for an interactive plot</p>
<pre><code>import matplotlib.pyplot as plt
import seaborn
from ipywidgets import interact
iris = seaborn.load_dataset(&quot;iris&quot;).set_index(&quot;species&quot;)

def plot_iris(species):
    &quot;&quot;&quot;Plot the given species&quot;&quot;&quot;
    df = iris.loc[species]
    ax = df.plot.scatter(x=&#39;petal_length&#39;, y=&#39;petal_width&#39;, title=species)
    ax.set_xlim(0,8)
    ax.set_ylim(0,4)

interact(plot_iris, species=list(iris.index.unique()))</code></pre>
<p>Use the <code>@interact</code> decorator</p>
<pre><code>@interact(species=list(iris.index.unique()))
def plot_iris(species):
    &quot;&quot;&quot;Plot the given species&quot;&quot;&quot;
    df = iris.loc[species]
    ax = df.plot.scatter(x=&#39;petal_length&#39;, y=&#39;petal_width&#39;, title=species)
    ax.set_xlim(0,8)
    ax.set_ylim(0,4)</code></pre>
</div>
</div>
<div id="display-options-for-pandas-data-frames" class="section level2">
<h2>Display options for pandas data frames</h2>
<p><a
href="https://pandas.pydata.org/docs/user_guide/options.html#frequently-used-options"
class="uri">https://pandas.pydata.org/docs/user_guide/options.html#frequently-used-options</a></p>
<p>Round all numbers</p>
<pre><code>pandas.set_option(&#39;display.precision&#39;, 0)</code></pre>
<p>Precision with 2 digit</p>
<pre><code>pandas.set_option(&#39;display.precision&#39;, 2)</code></pre>
<p>Scientific notation with 2 significant digits after the dot</p>
<pre><code>pandas.set_option(&#39;display.float_format&#39;, &#39;{:.2e}&#39;.format)</code></pre>
<div id="display-all-rows-and-columns-of-a-data-frame"
class="section level3">
<h3>Display all rows and columns of a data frame</h3>
<p>Display all columns</p>
<pre><code>pandas.options.display.max_columns = None</code></pre>
<p>Display max rows</p>
<pre><code>pandas.set_option(&#39;display.max_rows&#39;, 500)</code></pre>
<p>With a context manager <a
href="https://stackoverflow.com/a/47113685/2641825">as in this
answer</a></p>
<pre><code>with pd.option_context(&#39;display.max_rows&#39;, 100, &#39;display.max_columns&#39;, 10):
some pandas stuff

with pandas.option_context(&#39;display.max_rows&#39;, 100, &#39;display.max_columns&#39;, 10):
    display(large_prod)</code></pre>
</div>
</div>
<div id="docker-stacks" class="section level2">
<h2>Docker stacks</h2>
<p><a
href="https://jupyter-docker-stacks.readthedocs.io/en/latest/">Docker
stacks for Jupyter notebooks</a></p>
<p><a
href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#core-stacks">Selecting
an image</a></p>
</div>
<div id="download-data-from-a-jupyter-notebook" class="section level2">
<h2>Download data from a jupyter notebook</h2>
<p>I wrote this csv download function in an <a
href="https://stackoverflow.com/a/57613621/2641825">SO answer</a></p>
<pre><code>def csv_download_link(df, csv_file_name, delete_prompt=True):
    &quot;&quot;&quot;Display a download link to load a data frame as csv from within a Jupyter notebook&quot;&quot;&quot;
    df.to_csv(csv_file_name, index=False)
    from IPython.display import FileLink
    display(FileLink(csv_file_name))
    if delete_prompt:
        a = input(&#39;Press enter to delete the file after you have downloaded it.&#39;)
        import os
        os.remove(csv_file_name)</code></pre>
<p>To get a link to a csv file, enter the above function and the code
below in a jupyter notebook cell :</p>
<pre><code>csv_download_link(df, &#39;df.csv&#39;)</code></pre>
</div>
<div id="documentation-with-jupyter" class="section level2">
<h2>Documentation with Jupyter</h2>
<p><a
href="https://hub.packtpub.com/using-jupyter-write-documentation/">Using
jupyter to write documentation</a></p>
</div>
<div id="help-in-a-jupyter-notebook" class="section level2">
<h2>Help in a jupyter notebook</h2>
<p>To get help on a function, enter <code>function_name?</code> in a
cell. Quick hep can also be obtained by pressing SHIFT + TAB.</p>
</div>
<div id="install-jupyter" class="section level2">
<h2>Install Jupyter</h2>
<p>To <a href="https://jupyter.org/install">install Jupyter</a>
notebooks on python3:</p>
<pre><code>pip3 install jupyter notebook</code></pre>
<p>Then start the notebook server as such:</p>
<pre><code>jupyter notebook</code></pre>
</div>
<div id="plots-in-notebooks" class="section level2">
<h2>Plots in notebooks</h2>
<p>It is <a
href="https://stackoverflow.com/a/24884342/2641825">sometimes necessary
to add the following</a> at the beginning of a jupyter notebook so that
plots are displayed inline</p>
<pre><code>%matplotlib inline</code></pre>
<p>Change the size of a plot displayed in a notebook</p>
<pre><code>import seaborn
p = seaborn.lineplot(x=&quot;year&quot;, y=&quot;value&quot;, hue=&quot;source&quot;, data=df1)
p.figure.set_figwidth(15)</code></pre>
</div>
<div id="security-and-authentication-on-a-public-server"
class="section level2">
<h2>Security and authentication on a public server</h2>
<p><a
href="https://stackoverflow.com/questions/37808410/ipython-jupyter-notebook-with-authentication">Jupyter
notebook with authentication</a></p>
</div>
<div id="toc-table-of-content-in-your-notebooks" class="section level2">
<h2>TOC Table of content in your notebooks</h2>
<p>Install <a
href="https://github.com/ipython-contrib/jupyter_contrib_nbextensions">jupyter_contrib_nbextensions</a></p>
<pre><code>python3 -m pip install --user jupyter_contrib_nbextensions
python3 -m jupyter contrib nbextension install --user</code></pre>
<p>Activate the table of content extension:</p>
<pre><code>python3 -m jupyter nbextension enable toc2/main</code></pre>
<p>There are many other extensions available in this package.
<strong>Optionally</strong> you can install the jupyter notebook
extension configurator (not needed)</p>
<pre><code>python3 -m pip install --user jupyter_nbextensions_configurator
jupyter nbextensions_configurator enable --user</code></pre>
<p>This will make a configuration interface available at:</p>
<pre><code>http://localhost:8888/nbextensions</code></pre>
<p>Using the old Table of Content extension <a
href="https://github.com/minrk/ipython_extensions#table-of-contents">jupyter
table of content extension</a></p>
<pre><code>jupyter nbconvert --to markdown mynotebook.ipynb
jupyter nbconvert --to html mynotebook.ipynb</code></pre>
<p>For a colleague using Anaconda <a
href="https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html">Installing
jupyter_contrib_nbextensions</a> specifies that</p>
<blockquote>
<p>“There are conda packages for the notebook extensions and the
jupyter_nbextensions_configurator available from conda-forge. You can
install both using”</p>
</blockquote>
<pre><code>conda install -c conda-forge jupyter_contrib_nbextensions</code></pre>
</div>
<div id="jupyter-and-git-version-control" class="section level2">
<h2>Jupyter and git version control</h2>
<ul>
<li>Star history comparison between nbstripout and jupytext <a
href="https://star-history.com/#mwouts/jupytext&amp;kynan/nbstripout&amp;Date"
class="uri">https://star-history.com/#mwouts/jupytext&amp;kynan/nbstripout&amp;Date</a></li>
</ul>
<div id="jupytext-with-markdown-and-git" class="section level3">
<h3>Jupytext with markdown and git</h3>
<p>Convert notebooks to markdown so they are easier to track in git.</p>
<p>Install <a href="https://github.com/mwouts/jupytext"
class="uri">https://github.com/mwouts/jupytext</a></p>
<pre><code>python3 -m pip install --user jupytext</code></pre>
<p>More commands:</p>
<pre><code>python3 -m jupyter notebook --generate-config
vim ~/.jupyter/jupyter_notebook_config.py</code></pre>
<p>Add this line:</p>
<pre><code>c.NotebookApp.contents_manager_class = &quot;jupytext.TextFileContentsManager&quot;</code></pre>
<p>And also this line if you always want to pair notebooks with their
markdown counterparts:</p>
<pre><code>c.ContentsManager.default_jupytext_formats = &quot;ipynb,md&quot;</code></pre>
<p>More commands:</p>
<pre><code>python3 -m jupyter nbextension install jupytext --py --user
python3 -m jupyter nbextension enable  jupytext --py --user</code></pre>
<p>Add syncing to a given notebook:</p>
<pre><code># Markdown sync
jupytext --set-formats ipynb,md --sync ~/repos/example_repos/notebooks/test.ipynb
# Python sync
jupytext --set-formats ipynb,py --sync ~/repos/example_repos/notebooks/test.ipynb</code></pre>
</div>
<div id="clear-cell-output-before-git-commit" class="section level3">
<h3>Clear cell output before git commit</h3>
<p>As an alternative to Jupytext, you can also clear the output of all
cells before committing the notebook. That way the notebooks only
contain code and not the output of tables and plots (which can sometimes
take several megabytes of data).</p>
<ul>
<li><p><a
href="https://janakiev.com/blog/jupyter-git-remove-output/">how to
remove Jupyter notebook output from terminal and when using
git</a>.</p></li>
<li><p>Clearing Jupyter output <a
href="https://zhauniarovich.com/post/2020/2020-10-clearing-jupyter-output-p3/"
class="uri">https://zhauniarovich.com/post/2020/2020-10-clearing-jupyter-output-p3/</a>
previous approaches were using a pre-commit hook, current approach uses
git attributes.</p></li>
</ul>
<div id="nbstripout" class="section level4">
<h4>nbstripout</h4>
<ul>
<li><p>nbstripout <a href="https://github.com/kynan/nbstripout"
class="uri">https://github.com/kynan/nbstripout</a></p>
<blockquote>
<p>“This does mostly the same thing as the Clear All Output command in
the notebook UI.”</p>
</blockquote>
<ul>
<li><p>In pre-commit mode</p>
<blockquote>
<p>“nbstripout is used as a git hook to strip any .ipynb files before
committing. This also modifies your working copy!”</p>
</blockquote></li>
<li><p>In regular mode</p>
<blockquote>
<p>“In its regular mode, nbstripout acts as a filter and only modifies
what git gets to see for committing or diffing. The working copy stays
intact.”</p>
</blockquote></li>
<li><p>It’s probably better to use the regular filter mode.</p></li>
</ul></li>
<li><p>nbstripout-fast <a
href="https://pypi.org/project/nbstripout-fast/"
class="uri">https://pypi.org/project/nbstripout-fast/</a> 200x faster
implementation in rust avoids python startup times. They advertise 40s
for git status with large repos, while their tool would speed it up to
1s.</p></li>
</ul>
</div>
</div>
</div>
</div>
<div id="errors-exceptions-and-logging" class="section level1">
<h1>Errors, exceptions and logging</h1>
<div id="handling-exceptions-with-try-and-except-statements"
class="section level2">
<h2>Handling Exceptions with try and except statements</h2>
<p>Python documentation on <a
href="https://docs.python.org/3/tutorial/errors.html#handling-exceptions">Handling
Exceptions</a>.</p>
<pre><code>while True:
    try:
        x = int(input(&quot;Please enter a number: &quot;))
        break
    except ValueError:
        print(&quot;Oops!  That was no valid number.  Try again...&quot;)</code></pre>
<p>Re-raise the exception using <code>from</code> to track the original
exception</p>
<pre><code>for i in [1,0]:
    try:
        print(1/i)
    except Exception as e:
        msg = f&quot;failed to compute: 1/{i} {str(e)}&quot;
        raise ValueError(msg) from e</code></pre>
<p>The error message will contain:</p>
<pre><code>&quot;The above exception was the direct cause of the following exception&quot;</code></pre>
<p>Same example Without “from”</p>
<pre><code>for i in [1,0]:
    try:
        print(1/i)
    except Exception as e:
        msg = f&quot;failed to compute: {str(e)}&quot;
        raise ValueError(msg)</code></pre>
<p>The error message will contain:</p>
<pre><code>&quot;During handling of the above exception, another exception occurred&quot;</code></pre>
<p>Simple <a
href="https://stackoverflow.com/a/4690655/2641825">Exception message
capturing</a> with a print statement</p>
<pre><code>for i in [1,0]:
    try:
        print(1/i)
    except Exception as e:
        print(&quot;Failed to compute:&quot;, str(e))</code></pre>
<div id="data-exceptions" class="section level3">
<h3>Data exceptions</h3>
<p>Handle empty data in pandas</p>
<pre><code>import pandas
try:
    df = gfpmx_data[s]
    columns = df.columns
except pandas.errors.EmptyDataError:
    print(f&quot;no data in file {s}&quot;)
    columns = []</code></pre>
<p>Capture the first few lines of an exception and re-raising it using
“from”:</p>
<pre><code>try:
    assert_allclose(
        ds[var].loc[COUNTRIES, t],
        ds_ref[var].loc[COUNTRIES, t],
        rtol=rtol,
    )
except AssertionError as e:
    first_line_of_error = &quot;, &quot;.join(str(e).split(&#39;\n&#39;)[:3])
    msg = f&quot;{ds.product}, {var}: {first_line_of_error}&quot;
    raise AssertionError(msg) from e</code></pre>
</div>
</div>
<div id="raising-exceptions" class="section level2">
<h2>Raising Exceptions</h2>
<p>Python documentation on <a
href="https://docs.python.org/3/tutorial/errors.html#raising-exceptions">Raising
Exceptions</a></p>
<pre><code>raise Exception(&#39;spam&#39;)
raise ValueError(&#39;Not an acceptable value&#39;)
raise NameError(&quot;Wrong name: %s&quot; % &quot;quack quack quack&quot;)</code></pre>
<p>Display variables in the error message:</p>
<pre><code>raise ValueError(&quot;This is wrong: %s&quot; % &quot;wrong_value&quot;)
msg = &quot;Value %s and value %s have problems.&quot;
raise ValueError(msg % (1, 2))</code></pre>
<div id="default-exception" class="section level3">
<h3>Default Exception</h3>
<p><a href="https://docs.python.org/3/library/exceptions.html">Built-in
Exceptions</a></p>
<ul>
<li><p><code>KeyError</code> is returned when a value is missing. For
example if an environment variable is undefined.</p>
<p>import os os.environ[“avarthatdoesntexist”]</p>
<ul>
<li><code>EnvironmentError</code> is the parent error to IO errors
related to the operating system. It is only kept for compatibility
purposes and should not be used for errors related to environment
variables according to an answer in <a
href="https://stackoverflow.com/questions/50869968/is-it-appropriate-to-raise-an-environmenterror-for-os-environ"
class="uri">https://stackoverflow.com/questions/50869968/is-it-appropriate-to-raise-an-environmenterror-for-os-environ</a></li>
</ul></li>
<li><p><code>ValueError</code> can be used to raise exceptions about
data issues.</p></li>
</ul>
</div>
</div>
<div id="warnings" class="section level2">
<h2>Warnings</h2>
<p>Send a warning to the user</p>
<pre><code>import warnings
warnings.warn(&quot;there is no data&quot;)</code></pre>
<div id="ignore-warnings" class="section level3">
<h3>Ignore warnings</h3>
<p>Do not display the following warnings:</p>
<pre><code>import warnings
warnings.filterwarnings(&quot;ignore&quot;, message=&quot;option is deprecated&quot;)
warnings.filterwarnings(&quot;ignore&quot;, &quot;.*layout has changed to tight.*&quot;, category=UserWarning)
# related to https://github.com/mwaskom/seaborn/issues/3462
warnings.filterwarnings(&quot;ignore&quot;, &quot;is_categorical_dtype&quot;) 
warnings.filterwarnings(&quot;ignore&quot;, &quot;use_inf_as_na&quot;)</code></pre>
</div>
</div>
<div id="logging" class="section level2">
<h2>Logging</h2>
<p>docs.python.org <a
href="https://docs.python.org/3/howto/logging-cookbook.html">logging
cookbook</a></p>
<p>Pylint error: Use lazy % formatting in logging functions</p>
<p><a href="https://stackoverflow.com/a/52012660/2641825">Answer to Lazy
evaluation of strings in python logging: comparing <code>%</code> with
<code>.format</code></a></p>
<p>The documentation <a
href="https://docs.python.org/2/library/logging.html"
class="uri">https://docs.python.org/2/library/logging.html</a> suggest
the following for lazy evaluation of string interpolation:</p>
<pre><code>logging.getLogger().debug(&#39;test: %i&#39;, 42)</code></pre>
</div>
</div>
<div id="functions" class="section level1">
<h1>Functions</h1>
<p>Functions in python can be defined with</p>
<pre><code>def add_one(x):
    return x + 1
add_one(1)

# 2</code></pre>
<div id="annotations" class="section level2">
<h2>Annotations</h2>
<p><a href="https://peps.python.org/pep-3107/">PEP 3107</a></p>
<blockquote>
<p>Annotations for parameters take the form of optional expressions that
follow the parameter name:</p>
</blockquote>
<pre><code>def foo(a: expression, b: expression = 5):
    ...</code></pre>
<blockquote>
<p>to annotate the type of a function’s return value. This is done like
so:</p>
</blockquote>
<pre><code>def sum() -&gt; expression:
    ...</code></pre>
<p><a href="https://stackoverflow.com/a/15073109/2641825">SO
example</a></p>
<pre><code>def kinetic_energy(m:&#39;in KG&#39;, v:&#39;in M/S&#39;)-&gt;&#39;Joules&#39;:
return 1/2_m_v**2

kinetic_energy.__annotations__
{&#39;m&#39;: &#39;in KG&#39;, &#39;v&#39;: &#39;in M/S&#39;, &#39;return&#39;: &#39;Joules&#39;}</code></pre>
<p>The pandas code base doesn’t use it everywhere, there are functions
that use the standard sphinx type of documentation <a
href="https://github.com/pandas-dev/pandas/blob/a2029ce7bdd640931cb2c19e8a2c2c5a258fa5f9/pandas/core/arrays/timedeltas.py#L1094">timedeltas.py#L1094</a>.
I have the impression that the annotation are used for the package
internal functions, while the sphinx documentation is used for the
functions that are exposed to the outside users. And in the same script,
they use both sphinx documentation and type annotations <a
href="https://github.com/pandas-dev/pandas/blob/a2029ce7bdd640931cb2c19e8a2c2c5a258fa5f9/pandas/core/arrays/timedeltas.py#L952">timedeltas.py#L952</a>.</p>
<p><a
href="https://www.blog.pythonlibrary.org/2020/04/15/type-checking-in-python/">Type
checking in python</a></p>
<blockquote>
<p>There are several things to know about up front when it comes to type
hinting in Python. Let’s look at the pros of type hinting first:</p>
<ul>
<li>Type hints are nice way to document your code in addition to
docstrings</li>
<li>Type hints can make IDEs and linters give better feedback and better
autocomplete</li>
<li>Adding type hints forces you to think about types, which may help
you make good decisions during the design of your applications.</li>
</ul>
<p>Adding type hinting isn’t all rainbows and roses though. There are
some downsides:</p>
<ul>
<li>The code is more verbose and arguably harder to write</li>
<li>Type hinting adds development time</li>
<li>Type hints only work in Python 3.5+. Before that, you had to use
type comments</li>
<li>Type hinting can have a minor start up time penalty in code that
uses it, especially if you import the typing module.</li>
</ul>
</blockquote>
</div>
<div id="call-by-reference-or-call-by-value" class="section level2">
<h2>Call by reference or call by value</h2>
<p>When using numpy arrays, python displays a behaviour of call by
reference</p>
<pre><code>a = np.array([1,2])

def changeinput(x, scalar):
    x[0] = scalar

changeinput(a,3)

a
# array([3, 2])</code></pre>
<p>This is really weird coming from R, which has a copy-on-modify
principle.</p>
<p>The R Language Definition says this (in section 4.3.3 Argument
Evaluation)</p>
<blockquote>
<p>“The semantics of invoking a function in R argument are
call-by-value. In general, supplied arguments behave as if they are
local variables initialized with the value supplied and the name of the
corresponding formal argument. Changing the value of a supplied argument
within a function will not affect the value of the variable in the
calling frame. [Emphasis added]”</p>
</blockquote>
</div>
<div id="decorators" class="section level2">
<h2>Decorators</h2>
<p>Decorators are a way to wrap a function around another function. It
is useful to repeat a pattern of behaviour around a function.</p>
<ul>
<li>Data camp <a
href="https://www.datacamp.com/community/tutorials/decorators-python">course
on decorators</a></li>
<li>Examples <a
href="https://www.oreilly.com/ideas/5-reasons-you-need-to-learn-to-write-python-decorators">5
use cases for decorators</a></li>
</ul>
<p>I have used decorators to cache the function output along a data
processing pipeline.</p>
<div id="property-and-cached-property" class="section level3">
<h3>Property and cached property</h3>
<p>Since python 3.8 there is also a <code>@cached_property</code>
decorator <a
href="https://docs.python.org/dev/library/functools.html#functools.cached_property">functools.cached_property</a></p>
<blockquote>
<p>“Transform a method of a class into a property whose value is
computed once and then cached as a normal attribute for the life of the
instance. Similar to property(), with the addition of caching. Useful
for expensive computed properties of instances that are otherwise
effectively immutable.”</p>
</blockquote>
<p>Example (by <a
href="https://www.perplexity.ai/search/5cc7a6e1-ef72-418d-b7ae-d9049815b6f8?s=c#5cc7a6e1-ef72-418d-b7ae-d9049815b6f8"
class="uri">https://www.perplexity.ai/search/5cc7a6e1-ef72-418d-b7ae-d9049815b6f8?s=c#5cc7a6e1-ef72-418d-b7ae-d9049815b6f8</a>):</p>
<pre><code>from functools import cached_property

class MyClass:
    def __init__(self):
        self._data = [1, 2, 3, 4, 5]

    @cached_property
    def sum(self):
        print(&quot;Computing sum...&quot;)
        return sum(self._data)</code></pre>
<p>Usage:</p>
<pre><code>obj = MyClass()
print(obj.sum)  # prints &quot;Computing sum... 15&quot;
print(obj.sum)  # prints &quot;15&quot;</code></pre>
<p>There is also a <code>@cache</code> decorator <a
href="https://docs.python.org/dev/library/functools.html#functools.cache">functools.cache</a>
that creates:</p>
<blockquote>
<p>“a thin wrapper around a dictionary lookup for the function
arguments. Because it never needs to evict old values, this is smaller
and faster than lru_cache() with a size limit.</p>
</blockquote>
</div>
</div>
<div id="deprecate-arguments" class="section level2">
<h2>Deprecate arguments</h2>
<p>Deprecate the old name of a function argument</p>
<pre><code>def agg_trade_eu_row(df, grouping_side=&quot;partner&quot;, index_side=None):
    if index_side is not None:
        warnings.warn(&quot;index_side is deprecated; use grouping_side&quot;, DeprecationWarning, 2)
        grouping_side = index_side</code></pre>
<p>This <a href="https://stackoverflow.com/q/49802412/2641825">SO
Questions</a> asks how to create an argument alias, without changing the
number of arguments to the function.</p>
</div>
<div id="docstring-documentation" class="section level2">
<h2>Docstring Documentation</h2>
<p>Document python functions with the sphinx convention <a
href="https://stackoverflow.com/a/40596167">SO Answer</a></p>
<pre><code>def send_message(sender, recipient, message_body, priority=1) -&gt; int:
   &quot;&quot;&quot;
   Send a message to a recipient

   :param str sender: The person sending the message
   :param str recipient: The recipient of the message
   :param str message_body: The body of the message
   :param priority: The priority of the message, can be a number 1-5
   :type priority: integer or None
   :return: the message id
   :rtype: int
   :raises ValueError: if the message_body exceeds 160 characters
   :raises TypeError: if the message_body is not a basestring
   &quot;&quot;&quot;</code></pre>
</div>
</div>
<div id="mapping" class="section level1">
<h1>Mapping</h1>
<div id="cartopy-drawing-maps" class="section level2">
<h2>Cartopy drawing maps</h2>
<ul>
<li><p><a href="https://pypi.org/project/Cartopy/"
class="uri">https://pypi.org/project/Cartopy/</a></p>
<blockquote>
<p>“A cartographic python library with Matplotlib support for
visualisation”</p>
</blockquote></li>
<li><p><a
href="https://geopandas.org/en/stable/gallery/cartopy_convert.html">Plotting
with cartopy and geopandas</a></p></li>
</ul>
</div>
<div id="raster" class="section level2">
<h2>Raster</h2>
<p>See the sections on</p>
<ul>
<li>Rasterio</li>
<li>xarray</li>
</ul>
</div>
<div id="geopandas---polygons-and-related-data" class="section level2">
<h2>Geopandas - Polygons and related data</h2>
<p>geopandas help topic</p>
<ul>
<li><a
href="https://geopandas.org/en/stable/docs/user_guide/io.html">Input
output</a> reading and writing files</li>
</ul>
<p>All geopandas examples below require the following imports:</p>
<pre><code>from matplotlib import pyplot as plt
import geopandas</code></pre>
<ul>
<li><a
href="https://geopandas.org/en/stable/gallery/geopandas_rasterio_sample.html">Using
geopandas with rasterio to sample point data</a></li>
</ul>
<div id="map-of-the-world" class="section level3">
<h3>Map of the World</h3>
<p>Plot a world map of GDP per capita</p>
<pre><code>world = geopandas.read_file(geopandas.datasets.get_path(&#39;naturalearth_lowres&#39;))
world = world[(world.pop_est&gt;0) &amp; (world.name!=&quot;Antarctica&quot;)]
world[&#39;gdp_per_cap&#39;] = world.gdp_md_est / world.pop_est
world.plot(column=&#39;gdp_per_cap&#39;)
plt.show()</code></pre>
</div>
<div id="map-of-europe" class="section level3">
<h3>Map of Europe</h3>
<p>Load the JSON data from the Eurostat <a
href="https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts#nuts21">NUTS
page</a> (Nomenclature of territorial units for statistics) using the
EPSG 3035 projection.</p>
<pre><code>nuts = geopandas.read_file(&quot;~/downloads/NUTS_RG_20M_2021_3035.geojson&quot;)
ax = nuts.plot()
ax.set_xlim(2000000, 8000000)
ax.set_ylim(1000000, 5500000)
nuts.boundary.plot(color=&quot;darkgreen&quot;, ax=ax)
plt.show()</code></pre>
<p>NUTS ID have either 2, 3, 4 or 5 characters</p>
<pre><code>nuts.NUTS_ID.str.len().unique()
# array([2, 3, 4, 5])
nuts[&quot;id_n&quot;] = nuts.NUTS_ID.str.len()
def map_borders(df):
    ax = df.plot()
    ax.set_xlim(2000000, 8000000)
    ax.set_ylim(1000000, 5500000)
    df.boundary.plot(color=&quot;grey&quot;, ax=ax)
    return(ax)</code></pre>
<p>Map NUTS 0 which has 2 character codes</p>
<pre><code>nuts0 = nuts.query(&quot;id_n == 2&quot;)
map_borders(nuts0)
plt.show()</code></pre>
<p>Map NUTS 1 which has 3 character codes</p>
<pre><code>nuts1 = nuts.query(&quot;id_n == 3&quot;)
map_borders(nuts1)
plt.show()</code></pre>
<p>Map NUTS 2 which has 4 character codes</p>
<pre><code>nuts2 = nuts.query(&quot;id_n == 4&quot;)
map_borders(nuts2)
plt.show()
# Drop the geometry and write the description columns to a csv file
nuts2.drop(columns=&quot;geometry&quot;).to_csv(&quot;/tmp/nuts2.csv&quot;)</code></pre>
<p>Blogs and help pages:</p>
<ul>
<li><p>Jan’s blog, a quick visual comparison of the EPSG 3035, EPSG 4326
and EPSG 3857 projections on <a
href="https://jan-46106.medium.com/plotting-maps-with-european-data-in-python-part-i-decd83837de4">plotting
maps with european data in python part i</a></p>
<ul>
<li>I chose EPSG 3035 because it represents areas in a comparable
way.</li>
<li>Use <code>.boundary.plot()</code>to plot boundaries.</li>
</ul></li>
<li><p>towardsdatascience.com <a
href="https://towardsdatascience.com/using-eurostat-statistical-data-on-europe-with-python-2d77c9b7b02b">using
eurostat statistical data on Europe with python</a> Setting x an y
limits to the map of continental Europe only</p></li>
</ul>
</div>
</div>
</div>
<div id="math" class="section level1">
<h1>Math</h1>
<p><a
href="https://www.digitalocean.com/community/tutorials/how-to-do-math-in-python-3-with-operators">How
to do maths in python 3 with operators</a></p>
<p>2 to the power of 3</p>
<pre><code>2**3
# 8</code></pre>
<div id="floor-division" class="section level2">
<h2>Floor division</h2>
<p>Floor division</p>
<pre><code>5//3
# 1
# Use it to extract the year of a Comtrade period
202105 // 100</code></pre>
</div>
<div id="modulo" class="section level2">
<h2>Modulo</h2>
<pre><code>5%3
# 2
12
# Use it to extract the last 2 digits of an integer
202105 % 100</code></pre>
</div>
<div id="sympy" class="section level2">
<h2>Sympy</h2>
<p><a href="https://www.sympy.org/en/index.html"
class="uri">https://www.sympy.org/en/index.html</a></p>
<blockquote>
<p>“SymPy is a Python library for symbolic mathematics. It aims to
become a full-featured computer algebra system (CAS) while keeping the
code as simple as possible in order to be comprehensible and easily
extensible. SymPy is written entirely in Python.”</p>
</blockquote>
</div>
</div>
<div id="modelling-and-statistics" class="section level1">
<h1>Modelling and statistics</h1>
<div id="optimization-with-pyomo" class="section level2">
<h2>Optimization with Pyomo</h2>
<ul>
<li><p>Wikipedia <a
href="https://en.wikipedia.org/wiki/Pyomo">pyomo</a></p></li>
<li><p><a href="https://pyomo.readthedocs.io/en/stable/">Pyomo
documentation</a></p></li>
<li><p><a
href="https://jckantor.github.io/ND-Pyomo-Cookbook/01.00-Getting-Started-with-Pyomo.html">Pyomo
Cookbook</a></p>
<blockquote>
<p>“Pyomo is well suited to modeling simple and complex systems that can
be described by linear or nonlinear algebraic, differential, and partial
differential equations and constraints.”</p>
</blockquote></li>
</ul>
</div>
<div id="openai-chat-completion" class="section level2">
<h2>OpenAI chat completion</h2>
<ul>
<li><p><a href="https://pypi.org/project/openai/"
class="uri">https://pypi.org/project/openai/</a></p>
<blockquote>
<p>“The library needs to be configured with your account’s secret key
which is available on the <a
href="https://platform.openai.com/account/api-keys">website</a>. […] Set
it as the OPENAI_API_KEY environment variable”</p>
</blockquote></li>
<li><p><a href="https://help.openai.com/en/"
class="uri">https://help.openai.com/en/</a></p></li>
</ul>
<p>Ask Chat GPT to complete a message</p>
<pre><code>import openai
response = openai.ChatCompletion.create(
    model=&quot;gpt-3.5-turbo&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What are the trade-offs around deadwood in forests?&quot;}]
)
print(response)</code></pre>
<p>Print available models</p>
<pre><code>models = openai.Model.list()
print([m[&quot;id&quot;] for m in models.data])</code></pre>
<ul>
<li><p>Note ChatGPT plus and the API have separate pricing: <a
href="https://help.openai.com/en/articles/7039783-how-can-i-access-the-chatgpt-api"
class="uri">https://help.openai.com/en/articles/7039783-how-can-i-access-the-chatgpt-api</a></p>
<blockquote>
<p>“Please note that the ChatGPT API is not included in the ChatGPT Plus
subscription and are billed separately. The API has its own pricing,
which can be found at <a href="https://openai.com/pricing"
class="uri">https://openai.com/pricing</a>. The ChatGPT Plus
subscription covers usage on chat.openai.com only and costs
$20/month.”</p>
</blockquote></li>
</ul>
</div>
<div id="econometrics" class="section level2">
<h2>Econometrics</h2>
<ul>
<li><p><a href="https://www.statsmodels.org/stable/index.html"
class="uri">https://www.statsmodels.org/stable/index.html</a></p>
<blockquote>
<p>“statsmodels is a Python module that provides classes and functions
for the estimation of many different statistical models, as well as for
conducting statistical tests, and statistical data exploration.”</p>
</blockquote></li>
<li><p>2020 paper <a
href="https://conference.scipy.org/proceedings/scipy2010/pdfs/seabold.pdf"
class="uri">https://conference.scipy.org/proceedings/scipy2010/pdfs/seabold.pdf</a></p>
<blockquote>
<p>“The current main developers of statsmodels are trained as economists
with a background in <strong>econometrics.</strong> As such, much of the
development over the last year has focused on econometric
applications.”</p>
</blockquote></li>
<li><p><a href="https://pypi.org/project/wooldridge/"
class="uri">https://pypi.org/project/wooldridge/</a></p>
<blockquote>
<p>“A Python package which contains 111 data sets from one of the most
famous econometrics textbooks for undergraduates. […] It is extensively
used in <a
href="https://py4etrics-github-io.translate.goog/?_x_tr_sl=auto&amp;_x_tr_tl=en&amp;_x_tr_hl=de">Learning
Introductory Econometrics with Python</a> (Japanese, translated). It is
also used in <a href="http://www.upfie.net/">Using Python for
Introductory Econometrics</a>, which is a sister book of ‘Using R for
Introductory Econometrics’.”</p>
</blockquote></li>
</ul>
<div id="panel-data-regressions" class="section level3">
<h3>Panel data regressions</h3>
<ul>
<li><p>The package <a
href="https://bashtage.github.io/linearmodels/panel/panel/linearmodels.panel.model.PanelOLS.html#linearmodels.panel.model.PanelOLS">linearmodels</a>
provides fixed effects estimator for panel data.</p></li>
<li><p>blog <a
href="https://towardsdatascience.com/a-guide-to-panel-data-regression-theoretics-and-implementation-with-python-4c84c5055cf8">Panel
data with python</a></p></li>
</ul>
</div>
</div>
</div>
<div id="numpy-vectors-and-matrices-arrays" class="section level1">
<h1>Numpy vectors and matrices (arrays)</h1>
<p>All examples below are based on the numpy package being imported as
np :</p>
<pre><code>import numpy as np</code></pre>
<div id="logical-operators-and-binary-operations"
class="section level2">
<h2>Logical operators and binary operations</h2>
<p>I mostly use <a
href="%3Chttps://numpy.org/doc/stable/reference/routines.bitwise.html">binary
operators</a> on boolean arrays for index selections in pandas data
frames.</p>
<p>Bitwise and</p>
<pre><code>np.array([True, True]) &amp; np.array([False, True])</code></pre>
<p>Bitwise not</p>
<pre><code>~np.array([True, False])</code></pre>
<p>They are equivalent to logical operators <a
href="https://numpy.org/doc/stable/reference/generated/numpy.logical_and.html">numpy.logical_and</a>,
<a
href="https://numpy.org/doc/stable/reference/generated/numpy.logical_not.html">numpy.logical_not</a>
for logical arrays.</p>
<p>A <a href="https://stackoverflow.com/a/54435820/2641825">SO
answer</a> quotes <a
href="https://www.numpy.org/devdocs/user/numpy-for-matlab-users.html#numpy-for-matlab-users-notes">the
NumPy v1.15 Manual</a></p>
<pre><code>&gt; If you know you have boolean arguments, you can get away with using
&gt; NumPy’s bitwise operators, but be careful with parentheses, like this:
&gt; `z = (x &gt; 1) &amp; (x &lt; 2)`. The absence of NumPy operator forms of
&gt; `logical_and` and `logical_or` is an unfortunate consequence of Python’s
&gt; design.</code></pre>
<blockquote>
<p>So one can also use <code>~</code> for <code>logical_not</code> and
<code>|</code> for <code>logical_or</code>.</p>
</blockquote>
<p><a
href="https://numpy.org/doc/stable/reference/generated/numpy.bitwise_and.html">Bitwise
and</a></p>
<blockquote>
<p>“The number 13 is represented by 00001101. Likewise, 17 is
represented by 00010001. The bit-wise AND of 13 and 17 is therefore
000000001, or 1”</p>
</blockquote>
<pre><code>np.bitwise_and(13, 17)
# 1</code></pre>
<p>The <code>&amp;</code> operator can be used as a shorthand for
np.bitwise_and on ndarrays.</p>
<pre><code>x1 = np.array([2, 5, 255])
x2 = np.array([3, 14, 16])
x1 &amp; x2</code></pre>
</div>
<div id="indexing-multi-dimensional-arrays-and-masks"
class="section level2">
<h2>Indexing Multi-dimensional arrays and masks</h2>
<p>Numpy <a
href="https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html">array
indexing</a></p>
<blockquote>
<p>“Basic slicing extends Python’s basic concept of slicing to N
dimensions. Basic slicing occurs when obj is a slice object (constructed
by start:stop:step notation inside of brackets), an integer, or a tuple
of slice objects and integers.” […] The basic slice syntax is i:j:k
where i is the starting index, j is the stopping index, and k is the
step (<span class="math inline">\(k\neq0\)</span>). “[…]”Advanced
indexing always returns a copy of the data (contrast with basic slicing
that returns a view).” “Integer array indexing allows selection of
arbitrary items in the array based on their N-dimensional index. Each
integer array represents a number of indexes into that dimension.”</p>
</blockquote>
<pre><code>x[0:3,0:2]
# array([[0.64174957, 0.18540429],
#        [0.97558697, 0.69314058],
#        [0.51646795, 0.71055115]])</code></pre>
<p>In this case because every row is selected, it is the same as:</p>
<pre><code>x[:,0:2]</code></pre>
<p>Examples modified from <a
href="https://docs.scipy.org/doc/numpy/user/basics.indexing.html"
class="uri">https://docs.scipy.org/doc/numpy/user/basics.indexing.html</a></p>
<pre><code>y = np.arange(35).reshape(5,7)
print(y[np.array([0,2,4]), np.array([0,1,2])])

print(&#39;With slice 1:3&#39;)
print(y[np.array([0,2,4]),1:3])
print(&#39;is equivalent to&#39;)
print(y[np.array([[0],[2],[4]]),np.array([[1,2]])])
# This one is the same but transposed, which is weird
print(y[np.array([[0,2,4]]),np.array([[1],[2]])])
# Notice the difference with the following
print(y[np.array([0,2,4]),np.array([1,2,3])])</code></pre>
<p>Masks <a
href="https://docs.scipy.org/doc/numpy/reference/maskedarray.generic.html">masked
array</a> We wish to mark the fourth entry as invalid. The easiest is to
create a masked array:</p>
<pre><code>x = np.array([1, 2, 3, -1, 5])
mx = np.ma.masked_array(x, mask=[0, 0, 0, 1, 0])
print(x.sum(), mx.sum())
# 10 11</code></pre>
</div>
<div id="matrix-creation-and-shapes" class="section level2">
<h2>Matrix creation and shapes</h2>
<p>Create a vector</p>
<pre><code>a = np.array([1,2,3])</code></pre>
<p>Create a matrix</p>
<pre><code>b = np.array([[1,2,3],[5,6,6]])</code></pre>
<p>Shape</p>
<pre><code>a.shape
# (3,)
b.shape
# (2, 3)</code></pre>
<p>Matrix of zeroes</p>
<pre><code>np.zeros([2,2])
#array([[0., 0.],
#       [0., 0.]])</code></pre>
<p>Create a matrix with an additional dimension</p>
<pre><code>np.zeros(b.shape + (2,))
array([[[0., 0.],
        [0., 0.],
        [0., 0.]],

       [[0., 0.],
        [0., 0.],
        [0., 0.]]])</code></pre>
<p>Transpose</p>
<pre><code>b.transpose()
# array([[1, 5],
#        [2, 6],
#        [3, 6]])
c = b.transpose()</code></pre>
<p>Math functions in numpy:</p>
<pre><code>np.cos()
np.sin()
np.tan()
np.exp()</code></pre>
<p>min and max</p>
<pre><code>x = np.array([1,2,3,4,5,-7,10,-8])
x.max()
# 10
x.min()
# -8</code></pre>
</div>
<div id="matrix-multiplication" class="section level2">
<h2>Matrix multiplication</h2>
<p>Matrix multiplication <a
href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html">matmul</a></p>
<pre><code>np.matmul(a,c)
# array([14, 35])

# Can also be written as
a @ c
# array([14, 35])</code></pre>
<p>Otherwise the multiplication symbol implements an element wise
multiplication, also called the</p>
<p><a
href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)">Hadamard
product</a>. It only works on 2 matrices of same dimensions.
Element-wise multiplication is used for example in convolution
kernels.</p>
<pre><code>b * b
# array([[ 1,  4,  9],
#        [25, 36, 36]])</code></pre>
<p>So here is again an example showing the difference between</p>
<pre><code>m = np.array([[0,1],[2,3]])</code></pre>
<p>Element wise multiplication :</p>
<pre><code>m * m 
# array([[0, 1],
#        [4, 9]])</code></pre>
<p>Matrix multiplication :</p>
<pre><code>m @ m
# array([[ 2,  3],
#        [ 6, 11]])</code></pre>
</div>
<div id="norm-of-a-matrix" class="section level2">
<h2>Norm of a matrix</h2>
<p>Linear algebra functionalities are provided by numpy.linalg For
example the norm of a matrix or vector:</p>
<pre><code>np.linalg.norm(x)
# 16.3707055437449
np.linalg.norm(np.array([3,4]))
# 5.0
np.linalg.norm(a)
# 3.7416573867739413</code></pre>
<p>Norm of the matrix for the regularization parameter in a machine
learning model</p>
<pre><code>bli = np.array([[1, 1, 0.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 0.0, 0.0],
                [0.0, 1, 0.0, 0.0, 0.0]])
sum(np.linalg.norm(bli, axis=0)**2) 3.0000000000000004
sum(np.linalg.norm(bli, axis=1)**2) 3.0000000000000004
np.linalg.norm(bli)**2 2.9999999999999996</code></pre>
<p>Append vs concatenate</p>
<pre><code>x = np.array([1,2])
print(np.append(x,x))
# [1 2 1 2]
print(np.concatenate((x,x),axis=None))
a = np.array([[1, 2], [3, 4]])
b = np.array([[5, 6]])
print(np.concatenate((a, b), axis=0))
print(np.concatenate((a, b.T), axis=1))
print(np.concatenate((a, b), axis=None))</code></pre>
</div>
<div id="power" class="section level2">
<h2>Power</h2>
<p>Power of an array</p>
<pre><code>import numpy as np
a = np.arange(4).reshape(2, 2)
print(a)
print(a**2)
print(a*a)
np.power(a, 2)</code></pre>
<p>Broadcast the power operator</p>
<pre><code>np.power(a, a)</code></pre>
</div>
<div id="random-vector-or-matrices" class="section level2">
<h2>Random vector or matrices</h2>
<pre><code>x = np.random.random([3,4])
x
# array([[0.64174957, 0.18540429, 0.7045183 , 0.44623567],
#        [0.97558697, 0.69314058, 0.32469324, 0.82612627],
#        [0.51646795, 0.71055115, 0.74864751, 0.2142459 ]])</code></pre>
<p>Random choice, with a given probability Choose zero with probability
0.1 and one with probability 0.9.</p>
<pre><code>for i in range(10):
    print(np.random.choice(2, p=[0.1, 0.9]))
    
print(np.random.choice(2, 10, p=[0.1, 0.9]))
print(np.random.choice(2, (10,10), p=[0.1, 0.9]))

[[1 1 1 1 1 1 1 1 1 0]
 [1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 0]
 [1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 0 1 1]
 [1 1 1 0 1 1 1 1 1 1]
 [1 1 0 1 1 1 1 1 0 1]
 [1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 0 1 1 0]
 [1 1 1 1 1 1 1 1 1 1]]</code></pre>
<p>Error if probabilities do not sum up to one</p>
<pre><code>print(np.random.choice(2, p=[0.1, 0.8]))

# ---------------------------------------------------------------------------
# ValueError                                Traceback (most recent call last)
# &lt;ipython-input-31-8a8665287968&gt; in &lt;module&gt;
# ----&gt; 1 print(np.random.choice(2, p=[0.1, 0.8]))

# mtrand.pyx in numpy.random.mtrand.RandomState.choice()

# ValueError: probabilities do not sum to 1</code></pre>
</div>
</div>
<div id="pandas-data-frames" class="section level1">
<h1>Pandas data frames</h1>
<p>All code below assumes you have imported pandas</p>
<pre><code>import pandas </code></pre>
<div id="assign-values" class="section level2">
<h2>Assign values</h2>
<div id="create-a-data-frame" class="section level3">
<h3>Create a data frame</h3>
<p>You can create a data frame by passing a <strong>dictionary of
lists</strong> with column names as keys</p>
<pre><code>df = pandas.DataFrame({&#39;x&#39;:range(0,3), 
                  &#39;y&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})

#      a  b
#   0  0  3
#   1  1  4
#   2  2  5</code></pre>
<p>Or by passing a list of tuples and defining the <code>columns</code>
argument</p>
<pre><code>pandas.DataFrame(
    list(zip(range(0,3), [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;])), 
    columns=[&quot;x&quot;, &quot;y&quot;]
)</code></pre>
<p>Random numbers</p>
<pre><code>import numpy as np
df = pandas.DataFrame({&#39;x&#39;:np.random.random(100)})</code></pre>
</div>
<div id="use-the-assign-method" class="section level3">
<h3>Use the assign method</h3>
<p>Create a new column based on another one</p>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:range(0,3), 
                       &#39;b&#39;:[&#39;p&#39;,&#39;q&#39;,&#39;r&#39;], 
                       &#39;c&#39;:[&#39;m&#39;,&#39;n&#39;,&#39;o&#39;]})
df[&quot;d&quot;] = df[&quot;a&quot;] * 2</code></pre>
<p>Use the <code>assign</code> method</p>
<pre><code>df.assign(e = lambda x: x[&quot;a&quot;] * 3)
df.assign(e = lambda x: x[&quot;a&quot;] / 1e3)</code></pre>
<div id="sum-columns-together-and-compute-a-share"
class="section level4">
<h4>Sum columns together and compute a share</h4>
<p>Sum all columns in an assign and use it to compute a share</p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;).set_index(&quot;species&quot;)
iris.assign(sp_sum = lambda x: x.sum(axis=1),
            sl_share = lambda x: x.sepal_length / x.sp_sum)</code></pre>
</div>
</div>
<div id="recursive-computation-xt-depends-on-xt-1"
class="section level3">
<h3>Recursive computation x(t) depends on x(t-1)</h3>
<p>A recursive function is difficult to vectorize because each input at
time t depends on the previous input at time t-1. When possible use a
year index for shorter selection with <code>.loc()</code>.</p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;year&#39;:range(2020,2024),&#39;a&#39;:range(3,7)})
df1 = df.copy()
# Set the initial value
t0 = min(df1.year)
df1.loc[df1.year==t0, &quot;x&quot;] = 0

# Doesn&#39;t work when the right side of the equation is a pandas.core.series.Series
for t in range (min(df1.year)+1, max(df1.year)+1):
    df1.loc[df1.year==t, &quot;x&quot;] = df1.loc[df1.year==t-1,&quot;x&quot;] + df1.loc[df1.year==t-1,&quot;a&quot;]
print(df1)
#    year  a    x
# 0  2020  3  0.0
# 1  2021  4  NaN
# 2  2022  5  NaN
# 3  2023  6  NaN
print(type(df1.loc[df1.year==t-1,&quot;x&quot;] + df1.loc[df1.year==t-1,&quot;a&quot;]))
# &lt;class &#39;pandas.core.series.Series&#39;&gt;

# Works when the right side of the equation is a numpy array
for t in range (min(df1.year)+1, max(df1.year)+1):
    df1.loc[df1.year==t, &quot;x&quot;] = (df1.loc[df1.year==t-1,&quot;x&quot;] + df1.loc[df1.year==t-1,&quot;a&quot;]).unique()
    #break
print(df1)
#    year  a     x
# 0  2020  3   0.0
# 1  2021  4   3.0
# 2  2022  5   7.0
# 3  2023  6  12.0
print(type((df1.loc[df1.year==t-1,&quot;x&quot;] + df1.loc[df1.year==t-1,&quot;a&quot;]).unique()))
# &lt;class &#39;numpy.ndarray&#39;&gt;

# Assignement works directly when the .loc() selection is using a year index
df2 = df.set_index(&quot;year&quot;).copy()
# Set the initial value
df2.loc[df2.index.min(), &quot;x&quot;] = 0
for t in range (df2.index.min()+1, df2.index.max()+1):
    df2.loc[t, &quot;x&quot;] = df2.loc[t-1, &quot;x&quot;] + df2.loc[t-1,&quot;a&quot;]
    #break
print(df2)
#       a     x
# year
# 2020  3   0.0
# 2021  4   3.0
# 2022  5   7.0
# 2023  6  12.0
print(type(df2.loc[t-1, &quot;x&quot;] + df2.loc[t-1,&quot;a&quot;]))
# &lt;class &#39;numpy.float64&#39;&gt;

#SO answer using cumsum</code></pre>
<p>Our real problem is more complicated since there is a multiplicative
and an additive component</p>
<pre><code>import pandas
df3 = pandas.DataFrame({&#39;year&#39;:range(2020,2024),&#39;a&#39;:range(3,7), &#39;b&#39;:range(8,12)})
df3 = df3.set_index(&quot;year&quot;).copy()
# Set the initial value
initial_value = 1
df3.loc[df3.index.min(), &quot;x&quot;] = initial_value
# Use a loop
for t in range (df3.index.min()+1, df3.index.max()+1):
    df3.loc[t, &quot;x&quot;] = df3.loc[t-1, &quot;x&quot;] * df3.loc[t-1, &quot;a&quot;] + df3.loc[t-1, &quot;b&quot;]
# Use cumsum and cumprod
df3[&quot;cumprod_a&quot;] = df3.a.cumprod().shift(1).fillna(1)
df3[&quot;cumsum_cumprod_a_b&quot;] = df3.cumprod_a.cumsum().shift(1).fillna(0) * df3.b
df3[&quot;x2&quot;] = df3.cumprod_a * initial_value + df3.cumsum_cumprod_a_b
print(df3)</code></pre>
<ul>
<li><p><code>type(df1.loc[df1.year==t-1,"x"] + df1.loc[df1.year==t-1,"a"])</code>
is a pandas series while
<code>type(df2.loc[t-1, "x"] + df2.loc[t-1,"a"])</code> is a numpy
float. Why are types different?</p></li>
<li><p>Is there a better way to write a recursive <code>.loc()</code>
assignment than to use <code>.unique()</code>?</p></li>
</ul>
<p>See also:</p>
<ul>
<li>related Question and Answer on <a
href="https://stackoverflow.com/a/38008937/2641825">recursive
assignment</a></li>
<li>related documentation on <a
href="https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#mutating-with-user-defined-function-udf-methods">Mutating
User Defined Function methods</a></li>
</ul>
<blockquote>
<p>“It is a general rule in programming that one should not mutate a
container while it is being iterated over. Mutation will invalidate the
iterator, causing unexpected behavior.” […] “To resolve this issue, one
can make a copy so that the mutation does not apply to the container
being iterated over.”</p>
</blockquote>
</div>
<div id="set-values-with-.loc" class="section level3">
<h3>Set values with .loc</h3>
<p>Create an example data frame</p>
<pre><code>import pandas
df = pandas.DataFrame([[1, 2], [4, 5], [7, 8]],
                      index=[&#39;cobra&#39;, &#39;viper&#39;, &#39;sidewinder&#39;],
                      columns=[&#39;max_speed&#39;, &#39;shield&#39;])</code></pre>
<p>Set value for all items matching the list of labels</p>
<pre><code>df.loc[[&#39;viper&#39;, &#39;sidewinder&#39;], [&#39;shield&#39;]] = 50

#             max_speed  shield
# cobra               1       2
# viper               4      50
# sidewinder          7      50</code></pre>
</div>
<div id="map-values-with-a-dictionary" class="section level3">
<h3>Map values with a dictionary</h3>
<pre><code>df = pandas.DataFrame({&#39;lettre&#39;:[&#39;p&#39;,&#39;q&#39;,&#39;r&#39;,&#39;r&#39;,&#39;s&#39;,&#39;v&#39;,&#39;p&#39;]})
mapping = {&#39;p&#39;:&#39;pour&#39;,&#39;q&#39;:&#39;quoi&#39;,&#39;r&#39;:&#39;roi&#39;}
df[&quot;mot&quot;] = df[&quot;lettre&quot;].map(mapping)</code></pre>
</div>
</div>
<div id="categorical-data-types" class="section level2">
<h2>Categorical data types</h2>
<ul>
<li>Beware of the memory explosion issue when using groupby operations
on categorical data types <a
href="https://github.com/pandas-dev/pandas/issues/30552"
class="uri">https://github.com/pandas-dev/pandas/issues/30552</a></li>
</ul>
<p>Set categorical data type</p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;id&#39;:[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], &#39;x&#39;:range(3)})
list_of_ids = [&quot;b&quot;, &quot;c&quot;, &quot;a&quot;]
df[&#39;id&#39;] = pandas.Categorical(df[&#39;id&#39;], categories=list_of_ids, ordered=True)
df.sort_values(&#39;id&#39;, inplace=True)
df[&quot;id&quot;]
# Out:
# 0    a
# 1    b
# 2    c
# Name: id, dtype: category
# Categories (3, object): [&#39;b&#39; &lt; &#39;c&#39; &lt; &#39;a&#39;]</code></pre>
</div>
<div id="convert-data-frames-to-other-objects-or-types"
class="section level2">
<h2>Convert data frames to other objects or types</h2>
<p>See also the IO section to convert data frames to other files.</p>
<p>Convert 2 columns to a dictionary</p>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:range(0,3), 
                       &#39;b&#39;:[&#39;p&#39;,&#39;q&#39;,&#39;r&#39;], 
                       &#39;c&#39;:[&#39;m&#39;,&#39;n&#39;,&#39;o&#39;]})
df.set_index(&#39;b&#39;).to_dict()[&#39;c&#39;]</code></pre>
<div id="convert-a-column-to-numeric-or-string-and-check"
class="section level3">
<h3>Convert a column to numeric or string and check</h3>
<p>Convert a string to a numeric type using the argument
<code>errors="coerce"</code>:</p>
<pre><code>s = pandas.Series([&quot;1&quot;, &quot;2&quot;, &quot;a&quot;])
pandas.to_numeric(s, errors=&quot;coerce&quot;)</code></pre>
<p><a href="https://stackoverflow.com/a/45568283/2641825">Check if a
column is of numeric or string type</a></p>
<pre><code>pandas.api.types.is_numeric_dtype(s)
pandas.api.types.is_string_dtype(s)</code></pre>
<p>The following would return an error</p>
<pre><code>s.astype(float)
s.astype(int)</code></pre>
<p>And using the <code>df[col].astype()</code> method with
<code>errors="ignore"</code> would not convert at all:</p>
<pre><code>s.astype(float, errors=&quot;ignore&quot;)
pandas.to_numeric(s, errors=&quot;ignore&quot;)</code></pre>
<p>Convert an integer to a string type</p>
<pre><code>s = pandas.Series(range(3))
s.astype(str)</code></pre>
</div>
<div id="convert-one-value-to-a-scalar" class="section level3">
<h3>Convert one value to a scalar</h3>
<p>SO question <a
href="https://stackoverflow.com/questions/47910328/convert-pandas-dataframe-value-to-scalar">Convert
to scalar</a></p>
<ul>
<li><p>iat()</p>
<blockquote>
<p>“Access a single value for a row/column pair by integer position.
Similar to iloc, in that both provide integer-based lookups. Use iat if
you only need to get or set a single value in a DataFrame or
Series.”</p>
</blockquote></li>
<li><p>squeeze()</p>
<blockquote>
<p>“Squeeze 1 dimensional axis objects into scalars. Series or
DataFrames with a single element are squeezed to a scalar. DataFrames
with a single column or a single row are squeezed to a Series. Otherwise
the object is unchanged. This method is most useful when you don’t know
if your object is a Series or DataFrame, but you do know it has just a
single column. In that case you can safely call squeeze to ensure you
have a Series.”</p>
</blockquote></li>
</ul>
</div>
</div>
<div id="compare-data-frames" class="section level2">
<h2>Compare data frames</h2>
<p>Pure equality example from <a
href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.equals.html">pandas.DataFrame.equals</a></p>
<pre><code>import pandas
df = pandas.DataFrame({1: [10], 2: [20]})
exactly_equal = pandas.DataFrame({1: [10], 2: [20]})
df.equals(exactly_equal)
different_column_type = pandas.DataFrame({1.0: [10], 2.0: [20]})
df.equals(different_column_type)
different_data_type = pandas.DataFrame({1: [10.0], 2: [20.0]})
df.equals(different_data_type)</code></pre>
<div id="numpy-assert-all-close" class="section level3">
<h3>Numpy assert all close</h3>
<p>Testing closeness (for example with floating point results computed
in another software)</p>
<pre><code>import numpy as np
np.testing.assert_allclose([1,2,3], [1.001,2,3],rtol=1e-2)
np.testing.assert_allclose([1,2,3], [1.001,2,3],rtol=1e-6)</code></pre>
<p>Other examples</p>
<pre><code>df.equals(df+1e-6)
np.testing.assert_allclose(df,df+1e-7)
np.testing.assert_allclose(df,df+1e-3)</code></pre>
</div>
</div>
<div id="concatenate-and-merge" class="section level2">
<h2>Concatenate and merge</h2>
<ul>
<li><p><a
href="https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html"
class="uri">https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html</a></p>
<blockquote>
<p>“pandas provides various facilities for easily combining together
Series or DataFrame with various kinds of set logic for the indexes and
relational algebra functionality in the case of join / merge-type
operations.”</p>
</blockquote></li>
</ul>
<div id="concatenate-data-frames" class="section level3">
<h3>Concatenate data frames</h3>
<p>Example based on <a
href="https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#concatenating-objects"
class="uri">https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#concatenating-objects</a>
modified</p>
<pre><code>df1 = pandas.DataFrame(
    {
        &quot;A&quot;: range(3),
        &quot;B&quot;: range(3,6)
    }
)

df2 = pandas.DataFrame(
    {
        &quot;A&quot;: range(4),
        &quot;B&quot;: range(4,8),
        &quot;C&quot;: [&quot;w&quot;, &quot;x&quot;, &quot;y&quot;, &quot;z&quot;]
    }
)

df3 = pandas.DataFrame(
    {
        &quot;A&quot;: range(10,13),
        &quot;B&quot;: range(13,16)
    }
)

result = pandas.concat([df1, df2, df3]).reset_index(drop=True)</code></pre>
</div>
<div id="concatenate-series" class="section level3">
<h3>Concatenate series</h3>
<p>Concatenate two series <a
href="https://stackoverflow.com/questions/18062135/combining-two-series-into-a-dataframe-in-pandas">SO</a>
Notice the difference between the default <code>axis=0</code>
concatenate on the index, and <code>axis=1</code> concatenate on the
columns.</p>
<pre><code>import pandas
s1 = pandas.Series([1, 2, 3], index=[&#39;A&#39;, &#39;B&#39;, &#39;c&#39;], name=&#39;s1&#39;)
s2 = pandas.Series([4, 5, 6], index=[&#39;A&#39;, &#39;B&#39;, &#39;D&#39;], name=&#39;s2&#39;)
pandas.concat([s1, s2], axis=0)
pandas.concat([s1, s2], axis=1)</code></pre>
</div>
<div id="merge-or-join" class="section level3">
<h3>Merge or join</h3>
<p>Stackoverflow <a
href="https://stackoverflow.com/questions/53645882/pandas-merging-101/53645883#53645883">Pandas
merging</a></p>
<p>pandas merge right_on do not keep variable name <a
href="https://stackoverflow.com/questions/39985861/pandas-merge-on-columns-with-different-names-and-avoid-duplicates">Stack
Overflow</a></p>
<p>Propose 3 solutions:</p>
<ul>
<li><p>rename the original data frame to merge on varables that have the
same name</p></li>
<li><p>merge and drop the redundant column with a different
name</p></li>
<li><p>set the merge column as an index in the right data frame and use
right_index=True</p></li>
</ul>
</div>
</div>
<div id="columns" class="section level2">
<h2>Columns</h2>
<div id="list-columns" class="section level3">
<h3>List Columns</h3>
<p>List columns as an index object</p>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:range(0,3),&#39;b&#39;:range(3,6)})
df.columns</code></pre>
<p>List columns as a list</p>
<pre><code>df.columns.tolist()</code></pre>
<p>Select only certain columns in a list</p>
<pre><code>df[&#39;bla&#39;] = 0
cols = df.columns.tolist()
[name for name in cols if &#39;a&#39; in name]</code></pre>
</div>
<div id="na-values-in-columns" class="section level3">
<h3>NA values in columns</h3>
<div id="select-rows-where-at-least-one-column-is-na"
class="section level4">
<h4>Select rows where at least one column is NA</h4>
<ul>
<li><p><a href="https://datatofish.com/rows-with-nan-pandas-dataframe/"
class="uri">https://datatofish.com/rows-with-nan-pandas-dataframe/</a></p>
<p>import pandas import numpy as np df = pandas.DataFrame({‘i’ : [‘a’,
‘b’, ‘c’, ‘d’, ‘e’], ‘y’ : [np.nan, ‘2’,‘2’, ‘4’, ‘1’], ‘z’ : [‘2’,‘2’,
‘4’, ‘1’, np.nan], }) df[df.isna().any(axis=1)]</p></li>
</ul>
</div>
<div id="number-and-proportion-of-na-values" class="section level4">
<h4>Number and proportion of NA values</h4>
<p>A function that prints the number and proportion of NA values:</p>
<pre><code>def nrows_available(df, var):
    &quot;&quot;&quot;Number of rows where this variables is not NA&quot;&quot;&quot;
    avail = sum(df[var] == df[var])
    not_avail = sum(df[var] != df[var])
    assert(not_avail + avail == len(df))
    print(f&quot;{var} is available in {avail} rows&quot;,
          f&quot;and NA in the other {not_avail} rows&quot;,
          f&quot;{round(avail/len(df)*100)}% are available.&quot;)
nrows_available(placette, &quot;tpespar1&quot;)
nrows_available(placette, &quot;tpespar2&quot;)</code></pre>
</div>
<div id="remove-empty-columns" class="section level4">
<h4>Remove empty columns</h4>
<p>Remove empty columns where values are all NA</p>
<pre><code>import pandas
import numpy as np
df = pandas.DataFrame({&#39;A&#39; : [&#39;bli&#39;, &#39;bla&#39;, &#39;bla&#39;, &#39;bla&#39;, &#39;bla&#39;],
                       &#39;B&#39; : [np.nan, &#39;2&#39;,&#39;2&#39;, &#39;4&#39;, &#39;1&#39;],
                       &#39;C&#39; : np.nan})
columns_to_keep = [x for x in df.columns if not all(df[x].isna())]
df = df[columns_to_keep].copy()</code></pre>
</div>
</div>
<div id="rename-columns" class="section level3">
<h3>Rename columns</h3>
<p>Rename the ‘a’ column to ‘new’</p>
<pre><code>df.rename(columns={&#39;a&#39;:&#39;new&#39;})</code></pre>
<p>Rename columns to snake case using a regular expression</p>
<pre><code>import re
df.rename(columns=lambda x: re.sub(r&quot; &quot;, &quot;_&quot;, str(x)).lower(), inplace=True)
# Another regexp that replaces all non alphanumeric characters by an
# underscore
df.rename(columns=lambda x: re.sub(r&quot;\W+&quot;, &quot;_&quot;, str(x)).lower(), inplace=True)</code></pre>
<p>Remove parenthesis and dots in column names</p>
<pre><code>df.rename(columns=lambda x: re.sub(r&quot;[()\.]&quot;, &quot;&quot;, x), inplace=True)</code></pre>
<p>Replace the content of the columns, see below:</p>
<pre><code>iris[&quot;species&quot;].replace(&quot;setosa&quot;,&quot;x&quot;)</code></pre>
<div id="rename-and-select-at-the-same-time" class="section level4">
<h4>Rename and select at the same time</h4>
<p>You can use a selector data frame to select and rename at the same
time.</p>
<ul>
<li><p><a
href="https://stackoverflow.com/questions/57417520/selecting-and-renaming-columns-at-the-same-time"
class="uri">https://stackoverflow.com/questions/57417520/selecting-and-renaming-columns-at-the-same-time</a></p>
<p>df.rename(columns=selector_d)[selector_d.values()]</p></li>
</ul>
</div>
<div id="multiple-column-headers" class="section level4">
<h4>Multiple column headers</h4>
<p>Load a csv file which has headers on 2 lines, merge the headers,
convert to lower case, remove the “unnamed_1_” part of the column
name:</p>
<pre><code>csv_file_name = self.data_dir /  &quot;names.csv&quot;
df = pandas.read_csv(csv_file_name, header=[0, 1])
df.columns = [str(&#39;_&#39;.join(col)).lower() for col in df.columns]
df.rename(columns=lambda x: re.sub(r&quot;unnamed_\d+_&quot;, &quot;&quot;, str(x)).lower(), inplace=True)</code></pre>
</div>
<div id="rename-a-series" class="section level4">
<h4>Rename a series</h4>
<p>You can also rename a series with</p>
<pre><code>iris[&quot;species&quot;].rename(&quot;bla&quot;)</code></pre>
</div>
</div>
<div id="reorder-columns" class="section level3">
<h3>Reorder columns</h3>
<p>Place the last column first</p>
<pre><code>  cols = df.columns.to_list()
  cols = [cols[-1] + cols[:-1]
  df = df[cols]</code></pre>
<p>This <a href="https://stackoverflow.com/a/58776941/2641825">SO
Answer</a> provide 6 different ways to reorder columns.</p>
<p>Place the last 3 columns first</p>
<pre><code>  cols = list(df.columns)
  cols = cols[-3:] + cols[:-3]
  df = df[cols]</code></pre>
</div>
<div id="replace-the-content-of-columns" class="section level3">
<h3>Replace the content of columns</h3>
<p>See also string operations in pandas.</p>
<p>Replace Comtrade product code by the FAOSTAT product codes</p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
iris[&quot;species&quot;].replace(&quot;setosa&quot;,&quot;x&quot;)
# Create a dictionary from 2 columns of a data frame
product_dict = product_mapping.set_index(&#39;comtrade_code&#39;).to_dict()[&#39;faostat_code&#39;]
df_comtrade[&quot;product_code&quot;] = df_comtrade[&quot;product_code&quot;].replace(product_dict)</code></pre>
</div>
<div id="variable-type" class="section level3">
<h3>Variable Type</h3>
<p>To change the type of a column use astype:</p>
<pre><code>s = pandas.Series(range(3))
s.to_list()
s.astype(str).to_list()
s.astype(float).to_list()</code></pre>
<p>Note using NA values is not possible with the base integer type, it
requires a special type Int64 as explained in this <a
href="https://stackoverflow.com/a/67270477/2641825">SO answer</a></p>
<div id="find-mixed-data-types" class="section level4">
<h4>Find mixed data types</h4>
<p>When loading data sometimes more than one type are detected per
column with a warning such as this one:</p>
<pre><code>arbre = pandas.read_csv(zf.open(&quot;ARBRE.csv&quot;), sep=&quot;;&quot;)
DtypeWarning: Columns (4,5,9,14,21,36) have mixed types.
Specify dtype option on import or set low_memory=False.</code></pre>
<p>Create sample data with a column that has 2 data types</p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
# Change one row to another type
iris.loc[0,&quot;sepal_length&quot;] = iris.loc[0,&quot;sepal_length&quot;].astype(str)
iris.loc[1,&quot;sepal_length&quot;] = iris.loc[1,&quot;sepal_length&quot;].astype(str)</code></pre>
<p>Find columns that use more than one type</p>
<pre><code>for col in iris.columns:
    unique_types = iris[col].apply(type).unique()
    if len(unique_types) &gt; 1:
        print(col, unique_types)</code></pre>
</div>
</div>
<div id="memory-usage" class="section level3">
<h3>Memory usage</h3>
<p>To display the memory usage of <a
href="https://stackoverflow.com/questions/18089667/how-to-estimate-how-much-memory-a-pandas-dataframe-will-need">each
column in a pandas data frame</a></p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;x&#39;:range(0,3), &#39;y&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})
print(df.memory_usage(deep=True))
print(df.memory_usage(deep=True).sum())
df.info()</code></pre>
<p>Using <code>sys.getsizeof</code>:</p>
<pre><code>import sys
print(sys.getsizeof(df))</code></pre>
<p>Changing a repeated data series to a categorical can help reduce
memory usage</p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
print(iris[&quot;species&quot;].memory_usage(deep=True))
print(iris[&quot;species&quot;].astype(&#39;category&#39;).memory_usage(deep=True))
iris2 = iris.copy()
iris2[&quot;species&quot;] = iris[&quot;species&quot;].astype(&#39;category&#39;)
print(sys.getsizeof(iris2))
print(sys.getsizeof(iris))</code></pre>
</div>
</div>
<div id="copy-data-frame-indices-and-data" class="section level2">
<h2>Copy data frame indices and data</h2>
<p>Use copy() to make a copy of a data frame’s indices and data.</p>
<pre><code>import seaborn
iris1 = seaborn.load_dataset(&quot;iris&quot;)
iris2 = iris1.copy()
iris2[&quot;x&quot;] = 0
print(iris2.head(1))
print(iris1.head(1))
iris2.equals(iris1)</code></pre>
<p>If you don’t make a copy, modifying a new assigned data farme also
modifies the original data frame</p>
<pre><code>iris3 = iris1
iris3[&quot;x&quot;] = 0
print(iris3.head(1))
print(iris1.head(1))
iris3.equals(iris1)</code></pre>
</div>
<div id="datetime-operations" class="section level2">
<h2>Datetime operations</h2>
<p>Create date time columns from a character column</p>
<pre><code>import pandas
pandas.to_datetime(&#39;2020-01-01&#39;, format=&#39;%Y-%m-%d&#39;)
pandas.to_datetime(&#39;2020-01-02&#39;)
pandas.to_datetime(&#39;20200103&#39;)</code></pre>
<p>Extract the year</p>
<pre><code>s = pandas.Series(pandas.date_range(&quot;2000-01-01&quot;, periods=3, freq=&quot;Y&quot;))
print(s)
print(s.dt.year)</code></pre>
<p>Convert integer years to a time series</p>
<pre><code>s = pandas.Series([2020, 2021, 2022])
pandas.to_datetime(s, format=&quot;%Y&quot;)</code></pre>
<div id="convert-to-date-time" class="section level3">
<h3>Convert to date time</h3>
<p>Convert UN Comtrade dates in the format 202201 to a datetime type</p>
<pre><code>df = pandas.DataFrame({&#39;period&#39;:[202201, 202202]})
df[&quot;period2&quot;] = pandas.to_datetime(df[&#39;period&#39;], format=&#39;%Y%m&#39;)
df.info()</code></pre>
</div>
<div id="rolling-sum-and-mean" class="section level3">
<h3>Rolling sum and mean</h3>
<p>Rolling mean over a 5 year window for the whole data frame (provided
that year is the index variable)</p>
<pre><code>df.rolling(window=5).mean()</code></pre>
<p>Plot the difference to a 5 years rolling mean</p>
<pre><code>(df - df.rolling(window=5).mean()).plot.bar()</code></pre>
<p>Example “rolling sum with a window length of 2 observations.”</p>
<pre><code>df = pandas.DataFrame({&#39;B&#39;: [0, 1, 2, np.nan, 4, 5, 6, 7]})
df.rolling(2).sum()</code></pre>
<p>Yearly rolling of a monthly time series:</p>
<pre><code>.transform(lambda x: x.rolling(13, min_periods=1).mean()))</code></pre>
</div>
</div>
<div id="groupby-operations" class="section level2">
<h2>Groupby operations</h2>
<p>Compute the sum of sepal length grouped by species</p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
# Aggregate one value
iris.groupby(&#39;species&#39;)[&quot;sepal_length&quot;].agg(sum).reset_index()
# Aggregate multiple values
iris.groupby(&#39;species&#39;)[[&quot;sepal_length&quot;, &quot;petal_length&quot;]].agg(sum).reset_index()
# Aggregate multiple values and give new names
iris.groupby(&#39;species&#39;).agg(sepal_length_sum = (&#39;sepal_length&#39;, sum),
                            petal_length_sum = (&#39;petal_length&#39;, sum))</code></pre>
<p>Compute the sum but repeated for every original row</p>
<pre><code>iris[&#39;sepal_sum&#39;] = iris.groupby(&#39;species&#39;)[&#39;sepal_length&#39;].transform(&#39;sum&#39;)
iris</code></pre>
<p>This is useful to compute the <a
href="https://stackoverflow.com/questions/23377108/pandas-percentage-of-total-with-groupby">share
of total in each group</a> for example.</p>
<p>Compute the cumulative sum of the sepal length</p>
<pre><code>iris[&#39;cumsum&#39;] = iris.groupby(&#39;species&#39;).sepal_length.cumsum()
ris[&#39;cumsum&#39;].plot()
from matplotlib import pyplot
pyplot.show()</code></pre>
<p>Compute a lag</p>
<pre><code>iris[&#39;cumsum_lag&#39;] = iris.groupby(&#39;species&#39;)[&#39;cumsum&#39;].transform(&#39;shift&#39;, fill_value=0)
iris[[&#39;cumsum&#39;, &#39;cumsum_lag&#39;]].plot()
pyplot.show()</code></pre>
<div id="aggregate-by-decades" class="section level3">
<h3>Aggregate by decades</h3>
<p>Aggregate a trade data frame by decades</p>
<pre><code>bins = range(2000, 2031, 10)
tf_agg[&quot;decade&quot;] = pandas.cut(
    tf_agg[&quot;year&quot;], bins=bins, include_lowest=True, labels=range(2000, 2021, 10)
)
index = [&quot;reporter&quot;, &quot;partner&quot;, &quot;flow&quot;, &quot;product_code_4d&quot;, &quot;decade&quot;]
tf_decade = (
    tf_agg.groupby(index)[[&quot;net_weight&quot;, &quot;trade_value&quot;]]
    .agg(sum)
    .reset_index()
)</code></pre>
</div>
<div id="compute-with-a-lambda-function" class="section level3">
<h3>Compute with a lambda function</h3>
<p>Beyond standard function such as <code>sum</code> and
<code>mean</code>, it’s possible to use a self defined lambda function
as follows</p>
<pre><code>import numpy as np
(iris
 .groupby([&quot;species&quot;])
 .agg(pw_sum = (&quot;petal_width&quot;, sum),
      pw_sum_div_by_10 = (&quot;petal_width&quot;, lambda x: x.sum()/0),
      n = (&quot;petal_width&quot;, len),
      mean1 = (&quot;petal_width&quot;, np.mean))
 .assign(mean2 = lambda x: x.pw_sum / x.n)
)</code></pre>
</div>
<div id="different-aggregation-functions" class="section level3">
<h3>Different aggregation functions</h3>
<p>Example aggregating some variables with a sum and taking the unique
value (first) for other variables (input coefficients). The code below
passes a dictionary of variables and aggregation functions to the
<code>df.groupby().agg()</code> method.</p>
<pre><code>    # Aggregate product codes from the 6 to the 4 digit level
    index = [
        &quot;year&quot;,
        &quot;period&quot;,
        &quot;reporter_code&quot;,
        &quot;reporter&quot;,
        &quot;reporter_iso&quot;,
        &quot;partner_code&quot;,
        &quot;partner&quot;,
        &quot;partner_iso&quot;,
        &quot;product_code_4d&quot;,
        &quot;unit_code&quot;,
        &quot;unit&quot;,
    ]
    agg_dict = {&#39;quantity&#39;: &#39;sum&#39;,
                &#39;net_weight&#39;: &#39;sum&#39;,
                &#39;trade_value&#39;: &#39;sum&#39;,
                &#39;vol_eqrwd_ub&#39;: &#39;sum&#39;,
                &#39;vol_eqrwd_ob&#39;: &#39;sum&#39;,
                &#39;la_fo&#39;: &#39;sum&#39;,
                &#39;conversion_factor_m3_mt&#39;:&#39;first&#39;,
                &#39;bark_factor&#39;: &#39;first&#39;,
                &#39;nai&#39;: &#39;first&#39;}
    ft4d = (
        ft
        .groupby(index)
        .agg(agg_dict)
        .reset_index()
    )</code></pre>
</div>
<div id="unique-values-1" class="section level3">
<h3>Unique values</h3>
<pre><code>unique = lambda x: x.unique()[0] if x.nunique() == 1 else np.nan
agg =  {&#39;primary_eq&#39;:unique,
        &#39;import_quantity&#39;:unique,
        &#39;primary_eq_imp_1&#39;:sum}
df_agg = df.groupby(index)[selected_columns].agg(agg).reset_index()</code></pre>
</div>
<div id="proportion-within-groups" class="section level3">
<h3>Proportion within groups</h3>
<p>Compute proportion within groups:</p>
<pre><code>df = pandas.DataFrame({
    &#39;category&#39;: [&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;, &#39;c&#39;, &#39;c&#39;, &#39;c&#39;],
    &#39;value&#39;: [10, 20, 30, 40, 50, 60, 70]
})
df[&#39;proportion&#39;] = df.groupby(&#39;category&#39;)[&#39;value&#39;].transform(lambda x: x / x.sum())</code></pre>
</div>
<div id="lag-or-shift-a-grouped-variable" class="section level3">
<h3>Lag or shift a grouped variable</h3>
<p>Load the flights dataset and for each month, display the passenger
value in the same month of the previous year. Compare the
<code>passengers</code> and <code>pass_year_minus_one</code> columns by
displaying the tables for January and December.</p>
<pre><code>import seaborn
flights = seaborn.load_dataset(&quot;flights&quot;)
flights[&#39;pass_year_minus_one&#39;] = flights.groupby([&#39;month&#39;]).passengers.shift()
flights.query(&quot;month==&#39;January&#39;&quot;)
flights.query(&quot;month==&#39;December&#39;&quot;)</code></pre>
<p>Compute a lag</p>
<pre><code>iris[&#39;cumsum_lag&#39;] = iris.groupby(&#39;species&#39;)[&#39;cumsum&#39;].transform(&#39;shift&#39;, fill_value=0)
iris[[&#39;cumsum&#39;, &#39;cumsum_lag&#39;]].plot()
pyplot.show()</code></pre>
</div>
<div id="min-or-max-in-group" class="section level3">
<h3>Min or max in group</h3>
<p>Extract the min in each group</p>
<pre><code>df.loc[df.groupby(&#39;A&#39;)[&#39;B val&#39;].idxmin()]</code></pre>
<p>Sort by max in each group</p>
<pre><code>  df.groupby(&#39;reporter&#39;)[&quot;value&quot;].max().sort_values(ascending=False)</code></pre>
</div>
<div id="number-of-unique-combinations" class="section level3">
<h3>Number of unique combinations</h3>
<p>Number of unique combinations of one or 2 columns</p>
<pre><code>df = pandas.DataFrame({&#39;A&#39; : [&#39;bla&#39;, &#39;bla&#39;, &#39;bli&#39;, &#39;bli&#39;, &#39;bli&#39;],
                       &#39;B&#39; : [&#39;1&#39;, &#39;2&#39;, &#39;2&#39;, &#39;4&#39;, &#39;2&#39;]})
df.groupby([&quot;A&quot;]).nunique()
df.groupby([&quot;B&quot;]).nunique()
df.groupby([&quot;A&quot;, &quot;B&quot;]).nunique()</code></pre>
</div>
<div id="slice-get-the-first-elements-of-each-group"
class="section level3">
<h3>Slice, get the first elements of each group</h3>
<ul>
<li><p><a
href="https://stackoverflow.com/questions/30486417/pandas-how-do-i-select-first-row-in-each-group-by-group">How
do I select the first row in each group in groupby</a></p>
<p>import pandas import numpy as np df = pandas.DataFrame({‘A’ : [‘bla’,
‘bla’, ‘bli’, ‘bli’, ‘bli’], ‘B’ : [‘1’, ‘2’,‘2’, ‘4’, ‘1’], ‘C’ :
[np.nan, ‘X’, ‘Y’, ‘Y’, ‘Y’]}) df.sort_values(‘B’).groupby(‘A’).nth(0)
df.sort_values(‘B’).groupby(‘A’).nth(list(range(2)))
df.sort_values(‘B’).groupby(‘A’).head(2)</p></li>
</ul>
</div>
<div id="transform-and-apply" class="section level3">
<h3>Transform and apply</h3>
<p><a href="https://stackoverflow.com/a/47143056/2641825">SO answer
explaining the difference between transform and apply</a></p>
</div>
<div id="concatenate-strings-in-the-same-group" class="section level3">
<h3>Concatenate strings in the same group</h3>
<p>Based on <a
href="https://stackoverflow.com/questions/27298178/concatenate-strings-from-several-rows-using-pandas-groupby/74641478#74641478">SO
answer</a></p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;A&#39; : [&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;c&#39;], 
                       &#39;B&#39; : [&#39;i&#39;, &#39;j&#39;, &#39;k&#39;, &#39;i&#39;, &#39;j&#39;], 
                       &#39;X&#39; : [1, 2, 2, 1, 3]})
df.groupby(&quot;X&quot;, as_index=False)[&quot;A&quot;].agg(&#39; &#39;.join)
df.groupby(&quot;X&quot;, as_index=False)[[&quot;A&quot;, &quot;B&quot;]].agg(&#39; &#39;.join)</code></pre>
</div>
</div>
<div id="index" class="section level2">
<h2>Index</h2>
<p>Index can be converted back to a data frame See also index selection
in the “.loc” section.</p>
<div id="drop-index-levels" class="section level3">
<h3>Drop index levels</h3>
<p>Example from <a
href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html">pandas
DataFrame drop</a></p>
<pre><code>import pandas
midx = pandas.MultiIndex(levels=[[&#39;lama&#39;, &#39;cow&#39;, &#39;falcon&#39;],
                             [&#39;speed&#39;, &#39;weight&#39;, &#39;length&#39;]],
                     codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],
                            [0, 1, 2, 0, 1, 2, 0, 1, 2]])
df = pandas.DataFrame(index=midx, columns=[&#39;big&#39;, &#39;small&#39;],
                  data=[[45, 30], [200, 100], [1.5, 1], [30, 20],
                        [250, 150], [1.5, 0.8], [320, 250],
                        [1, 0.8], [0.3, 0.2]])
df
df.drop(index=&#39;cow&#39;, columns=&#39;small&#39;)
df.drop(index=&#39;length&#39;, level=1)</code></pre>
</div>
<div id="recursive-computation-on-a-index-in-a-loop"
class="section level3">
<h3>Recursive computation on a index in a loop</h3>
<div id="simple-index-case" class="section level4">
<h4>Simple index case</h4>
<p>Compute in a loop based on the value of the previous year t-1. If
there is a single value by year, scalar computation</p>
<pre><code>df = pandas.DataFrame({&#39;x&#39;:range(0,10)})
df.loc[0, &quot;y&quot;] = 2
for t in range(1, len(df)):
    df.loc[t, &quot;y&quot;] = pow(df.loc[t-1, &quot;y&quot;], df.loc[t, &quot;x&quot;]/2)
df</code></pre>
<p>If there are multiple values for each single year vector
computation.</p>
<pre><code>import itertools
import pandas
countries = [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;]
years = range(1990, 2020)
expand_grid = list(itertools.product(countries, years))
df = pandas.DataFrame(expand_grid, columns=(&#39;country&#39;, &#39;year&#39;))
df[&quot;x&quot;] = 1
df[&quot;x&quot;] = df[&quot;x&quot;].cumsum()
df.set_index([&quot;year&quot;], inplace=True)
df.loc[min(years), &quot;y&quot;] = 2
for t in range(min(years)+1, max(years)+1):
    df.loc[t, &quot;y&quot;] = pow(df.loc[t-1, &quot;y&quot;], df.loc[t, &quot;x&quot;]/2)
df</code></pre>
</div>
<div id="multi-index-case" class="section level4">
<h4>Multi index case</h4>
<p>I would like to compute the consumption equation of a partial
equilibrium model.</p>
<pre><code>df = pandas.DataFrame({&#39;x&#39;:range(0,3), 
                       &#39;y&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})

for t in range(gfpmx_data.base_year + 1, years.max()+1):
    # TODO: replace this loop by vectorized operations using only the index on years
    for c in countries:
        # Consumption
        swd.loc[(t,c), &quot;cons2&quot;] = (swd.loc[(t, c), &quot;constant&quot;]
                                   * pow(swd.loc[(t-1, c), &quot;price&quot;],
                                         swd.loc[(t, c), &quot;price_elasticity&quot;])
                                   * pow(swd.loc[(t, c), &quot;gdp&quot;],
                                         swd.loc[(t, c), &quot;gdp_elasticity&quot;])
                                  )
swd[&#39;comp_prop&#39;] = swd.cons2 / swd.cons -1
print(swd[&quot;comp_prop&quot;].abs().max())
swd.query(&quot;year &gt;= 2019&quot;)</code></pre>
</div>
</div>
<div id="unique-values-of-a-multi-index" class="section level3">
<h3>Unique values of a multi index</h3>
<p>Display the unique values of the two columns with a count of
occurrences</p>
<pre><code>import seaborn
penguins = seaborn.load_dataset(&quot;penguins&quot;)
penguins.value_counts([&quot;species&quot;, &quot;island&quot;])
penguins[[&quot;species&quot;, &quot;island&quot;]].value_counts()</code></pre>
<p>Lower level method using <code>unique()</code> on a multi index and
returning a data frame</p>
<pre><code>penguins.set_index([&quot;species&quot;, &quot;island&quot;]).index.unique().to_frame(False)</code></pre>
</div>
<div id="query-index-greater-or-smaller-than" class="section level3">
<h3>Query index greater or smaller than</h3>
<p>See also the query section for other ways to query data frames.</p>
<p><a href="https://stackoverflow.com/a/18103894/2641825">SO
answer</a></p>
<pre><code>df = pandas.DataFrame({&#39;i&#39;:range(0,3), 
                       &#39;j&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;],
                       &#39;x&#39;:range(22,25)})
df = df.set_index([&quot;i&quot;,&quot;j&quot;])
df.loc[(df.index.get_level_values(&#39;i&#39;) &gt; 1)]</code></pre>
<p>Using query instead</p>
<pre><code>df.query(&quot;i&gt;1&quot;)</code></pre>
</div>
</div>
<div id="interpolate" class="section level2">
<h2>Interpolate</h2>
<p><a
href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html">pandas
interpolate</a></p>
<pre><code>import pandas
import numpy as np
s = pandas.Series([0, 2, np.nan, 8, np.nan, np.nan])
s.interpolate(method=&#39;polynomial&#39;, order=2)
s.interpolate(method=&#39;linear&#39;)</code></pre>
<p>Limit interpolation to the inner NAN values</p>
<pre><code>s.interpolate(limit_area=&quot;inside&quot;)</code></pre>
<p><a
href="https://stackoverflow.com/questions/37057187/pandas-interpolate-within-a-groupby">Interpolate
within a groupby</a></p>
<pre><code># Interpolate the whole data frame
df.groupby(&quot;a&quot;).transform(pandas.DataFrame.interpolate)
# Only one column
df.groupby(&quot;a&quot;)[&quot;b&quot;].transform(pandas.Series.interpolate)</code></pre>
</div>
<div id="pyarrow" class="section level2">
<h2>PyArrow</h2>
<ul>
<li><a href="https://arrow.apache.org/overview/">Apache Arrow
overview</a> explains the advantage of using a in memory columnar format
to store data:</li>
</ul>
<blockquote>
<p>“The Apache Arrow format allows computational routines and execution
engines to maximize their efficiency when scanning and iterating large
chunks of data. In particular, the contiguous columnar layout enables
vectorization using the latest SIMD (Single Instruction, Multiple Data)
operations included in modern processors.” “[…] a standardized memory
format facilitates reuse of libraries of algorithms, even across
languages.” “Arrow libraries for C (Glib), MATLAB, Python, R, and Ruby
are built on top of the C++ library.”</p>
</blockquote>
<ul>
<li><p><a
href="https://arrow.apache.org/docs/python/pandas.html">PyArrow
interface with pandas</a></p></li>
<li><p><a href="https://arrow.apache.org/docs/python/csv.html">Read and
write csv files</a></p></li>
</ul>
<div id="dask-data-frame" class="section level3">
<h3>Dask data frame</h3>
<p><a href="https://docs.dask.org/en/latest/dataframe.html"
class="uri">https://docs.dask.org/en/latest/dataframe.html</a></p>
</div>
<div id="vaex" class="section level3">
<h3>Vaex</h3>
<p><a href="https://github.com/vaexio/vaex"
class="uri">https://github.com/vaexio/vaex</a></p>
</div>
</div>
<div id="pandas-io-input-output" class="section level2">
<h2>Pandas IO Input Output</h2>
<p>See the general section on IO input output, many of the subsections
there refer to pandas IO.</p>
</div>
<div id="pivot-reshape-and-transpose" class="section level2">
<h2>Pivot, reshape and transpose</h2>
<div id="from-wide-to-long" class="section level3">
<h3>from wide to long</h3>
<p><a
href="https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#reshaping-by-melt">The
Pandas user guide on reshaping</a> gives several example using
<code>melt</code> (easier to rename the “variable” and “value” columns)
or <code>stack</code> (designed to work together with MultiIndex
objects).</p>
<p>Reshape using <code>melt</code></p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
iris.melt(id_vars=&quot;species&quot;, var_name=&quot;measurement&quot;)</code></pre>
<p>Another example with two index columns</p>
<pre><code>cheese = pandas.DataFrame(
      {
          &quot;first&quot;: [&quot;John&quot;, &quot;Mary&quot;],
          &quot;last&quot;: [&quot;Doe&quot;, &quot;Bo&quot;],
          &quot;height&quot;: [5.5, 6.0],
          &quot;weight&quot;: [130, 150],
      }
)
cheese
cheese.melt(id_vars=[&quot;first&quot;, &quot;last&quot;], var_name=&quot;quantity&quot;)</code></pre>
<p>Another example</p>
<pre><code>grading_matrix = pandas.DataFrame({&quot;dbh&quot;:[&quot;d1&quot;, &quot;d2&quot;, &quot;d3&quot;],
                                   &quot;abies&quot;:[&quot;p&quot;,&quot;q&quot;,&quot;r&quot;],
                                   &quot;picea&quot;:[&quot;m&quot;,&quot;n&quot;,&quot;o&quot;],
                                   &quot;larix&quot;:[&quot;m&quot;,&quot;n&quot;,&quot;o&quot;]})
grading_long = grading_matrix.melt(id_vars=&quot;dbh&quot;, 
                                   var_name=&quot;species&quot;, 
                                   value_name=&quot;grading&quot;)</code></pre>
<p>Reshape using the <code>wide_to_long</code> convenience function</p>
<pre><code>import numpy as np
dft = pandas.DataFrame(
    {
        &quot;A1970&quot;: {0: &quot;a&quot;, 1: &quot;b&quot;, 2: &quot;c&quot;},
        &quot;A1980&quot;: {0: &quot;d&quot;, 1: &quot;e&quot;, 2: &quot;f&quot;},
        &quot;B1970&quot;: {0: 2.5, 1: 1.2, 2: 0.7},
        &quot;B1980&quot;: {0: 3.2, 1: 1.3, 2: 0.1},
        &quot;X&quot;: dict(zip(range(3), np.random.randn(3))),
        &quot;id&quot;:  {0: 0, 1: 1, 2: 2},
    }
)
dft
pandas.wide_to_long(dft, stubnames=[&quot;A&quot;, &quot;B&quot;], i=&quot;id&quot;, j=&quot;year&quot;)</code></pre>
</div>
<div id="from-long-to-wide" class="section level3">
<h3>From long to wide</h3>
<p>Pivot from long to wide format using <code>pivot</code>:</p>
<pre><code>df = pandas.DataFrame({
    &quot;lev1&quot;: [1, 1, 1, 2, 2, 2],
    &quot;lev2&quot;: [1, 1, 2, 1, 1, 2],
    &quot;lev3&quot;: [1, 2, 1, 2, 1, 2],
    &quot;lev4&quot;: [1, 2, 3, 4, 5, 6],
    &quot;values&quot;: [0, 1, 2, 3, 4, 5]})
df_wide = df.pivot(index=&quot;lev1&quot;, columns=[&quot;lev2&quot;, &quot;lev3&quot;], values=&quot;values&quot;)
df_wide

# lev2    1         2
# lev3    1    2    1    2
# lev1
# 1     0.0  1.0  2.0  NaN
# 2     4.0  3.0  NaN  5.0</code></pre>
<p>Rename the (sometimes confusing) axis names</p>
<pre><code>df_wide.rename_axis(columns=[None, None])

#         1         2
#         1    2    1    2
# lev1
# 1     0.0  1.0  2.0  NaN
# 2     4.0  3.0  NaN  5.0</code></pre>
</div>
<div id="transpose-index-and-columns" class="section level3">
<h3>Transpose index and columns</h3>
<ul>
<li><p><a
href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html"
class="uri">https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transpose.html</a></p>
<p>df1 = pandas.DataFrame({‘col1’: [1, 2], ‘col2’: [3, 4]})
df1.transpose()</p></li>
</ul>
</div>
</div>
<div id="replace" class="section level2">
<h2>Replace</h2>
<p><a
href="https://stackoverflow.com/questions/12152716/python-pandas-equivalent-for-replace">Python
pandas equivalent for replace</a></p>
<pre><code>import pandas
s = pandas.Series([&quot;ape&quot;, &quot;monkey&quot;, &quot;seagull&quot;])
s.replace([&quot;ape&quot;, &quot;monkey&quot;], [&quot;lion&quot;, &quot;panda&quot;])
s.replace(&quot;a&quot;, &quot;x&quot;, regex=True)
`s.replace({&quot;ape&quot;: &quot;lion&quot;, &quot;monkey&quot;: &quot;panda&quot;})`
pandas.Series([&quot;bla&quot;, &quot;bla&quot;]).replace(&quot;a&quot;,&quot;i&quot;,regex=True)</code></pre>
<p>Replace by the upper case value</p>
<pre><code>s.str.upper()</code></pre>
<div id="replace-values-where-a-condition-is-false"
class="section level3">
<h3>Replace values where a condition is false</h3>
<p>Replace values where the condition is false see
<code>help(df.where)</code></p>
<blockquote>
<p>“Where <code>cond</code> is True, keep the original value. Where
False, replace with corresponding value from <code>other</code>.”</p>
</blockquote>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:range(0,3), 
                       &#39;b&#39;:[&#39;p&#39;,&#39;q&#39;,&#39;r&#39;], 
                       &#39;c&#39;:[&#39;m&#39;,&#39;n&#39;,&#39;o&#39;]})
df[&quot;b&quot;].where(df[&quot;c&quot;].isin([&quot;n&quot;,&quot;o&quot;]),&quot;no&quot;)
df.where(df[&quot;c&quot;].isin([&quot;n&quot;,&quot;o&quot;]),&quot;no&quot;)</code></pre>
</div>
<div id="fill-na-values" class="section level3">
<h3>Fill Na values</h3>
<p>Replace NA values by another value</p>
<pre><code>import pandas
import numpy as np
df = pandas.DataFrame([[np.nan, 2, np.nan, 0],
                  [3, 4, np.nan, 1],
                  [np.nan, np.nan, np.nan, 5],
                  [np.nan, 3, np.nan, 4]],
                 columns=list(&quot;ABCD&quot;))
# Replace all NaN elements with 0s.
df.fillna(0)
# Replace by 0 and column 2 and by 1 in column B
df.fillna({&quot;A&quot;:0, &quot;B&quot;:1}, inplace=True)
df</code></pre>
</div>
</div>
<div id="select-with-loc-iloc-query-isin-and-xs" class="section level2">
<h2>Select with loc, iloc, query, isin and xs</h2>
<p>There are many ways to select data in pandas (squarebraquets, loc,
iloc, query, isin). In a first stage, during data preparation it’s
better to keep data out of the index. But in a second stage, when you
are doing modelling, multi indexes become useful. And especially slicers
to computes on part of the dataset - only some years, only some
products, only some countries . For this, tools such as df.xs or <a
href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.IndexSlice.html"
class="uri">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.IndexSlice.html</a>
are needed.</p>
<ul>
<li>blog <a
href="https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/">Select
pandas data frame rows and columns using iloc and loc</a></li>
</ul>
<div id="loc" class="section level3">
<h3>loc</h3>
<p><code>.loc</code> is primarily label based, but may also be used with
a boolean array.</p>
<p>I copied the examples below from the pandas <strong>loc</strong>
documentation at: <a
href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html">pandas.DataFrame.loc</a></p>
<p>Create an example data frame</p>
<pre><code>import pandas
df = pandas.DataFrame([[1, 2], [4, 5], [7, 8]],
                      index=[&#39;cobra&#39;, &#39;viper&#39;, &#39;sidewinder&#39;],
                      columns=[&#39;max_speed&#39;, &#39;shield&#39;])</code></pre>
<p>List of index labels</p>
<pre><code>In :  df.loc[[&#39;viper&#39;, &#39;sidewinder&#39;]]
Out:
                    max_speed  shield
        viper               4       5
        sidewinder          7       8</code></pre>
<p>Selecting a cell with 2 lists returns a data frame</p>
<pre><code>df.loc[[&quot;viper&quot;], [&quot;shield&quot;]]</code></pre>
<p>Selecting cell with tuples (for multi indexes) or strings returns its
value</p>
<pre><code>df.loc[(&quot;viper&quot;), (&quot;shield&quot;)]
df.loc[&quot;viper&quot;, &quot;shield&quot;]</code></pre>
<p>Note: in the case of a multi index, use tuples for index selection,
see section below on multi index selection with loc.</p>
<p>Conditional that returns a boolean Series</p>
<pre><code>In :  df.loc[df[&#39;shield&#39;] &gt; 6]
Out:
                     max_speed  shield
         sidewinder          7       8</code></pre>
<p>Slice with labels for row and labels for columns.</p>
<pre><code>In :  df.loc[&#39;cobra&#39;:&#39;viper&#39;, &#39;max_speed&#39;:&#39;shield&#39;]
Out:
               max_speed  shield
        cobra          1       2
        viper          4       5</code></pre>
<p>Set value for all items matching the list of labels</p>
<pre><code>In : df.loc[[&#39;viper&#39;, &#39;sidewinder&#39;], [&#39;shield&#39;]] = 50

In : df
Out:
                    max_speed  shield
        cobra               1       2
        viper               4      50
        sidewinder          7      50</code></pre>
<p>Another example using integers for the index</p>
<pre><code>df2 = pandas.DataFrame([[1, 2], [4, 5], [7, 8]],
                      index=[7, 8, 9],
                      columns=[&#39;max_speed&#39;, &#39;shield&#39;])</code></pre>
<p>Slice with integer labels for rows. Note that <strong>both the start
and stop of the slice</strong> are included. Python slices behave
differently.</p>
<pre><code>In :  df2.loc[8:9]
Out:
      max_speed  shield
   8          4       5
   9          7       8</code></pre>
<div id="index.isin" class="section level4">
<h4>index.isin()</h4>
<p>Using the same example as above, select rows that are not in
[‘cobra’,‘viper’]. Based on a <a
href="https://stackoverflow.com/a/29140194/2641825">SO answer use isin
on the index</a>:</p>
<pre><code>In : df.index.isin([&#39;cobra&#39;,&#39;viper&#39;])
Out: array([ True,  True, False])

In : df.loc[~df.index.isin([&#39;cobra&#39;,&#39;viper&#39;])]
Out: 
            max_speed  shield
sidewinder          7       8</code></pre>
<p>Or assign the selector to reuse it:</p>
<pre><code>selector = df.index.isin([&#39;cobra&#39;,&#39;viper&#39;])
df.loc[selector]
df.loc[~selector]</code></pre>
</div>
<div id="index-conditions" class="section level4">
<h4>index conditions</h4>
<p>With an index corresponding to years, select all years below or equal
to 2050</p>
<pre><code>df.loc[df.index &lt;= 2050]</code></pre>
</div>
<div id="multiple-conditions" class="section level4">
<h4>Multiple conditions</h4>
<pre><code>import pandas
df = pandas.DataFrame([[1, 2], [4, 5], [7, 8]],
                      index=[&#39;cobra&#39;, &#39;viper&#39;, &#39;sidewinder&#39;],
                      columns=[&#39;max_speed&#39;, &#39;shield&#39;])
df.loc[(df[&quot;max_speed&quot;] &gt; 1) &amp; (df[&quot;shield&quot;] &lt; 7)]
df.query(&quot;max_speed &gt; 1 &amp; shield &lt; 7&quot;)</code></pre>
</div>
<div id="multi-index-selection-with-loc" class="section level4">
<h4>Multi-index selection with loc</h4>
<p>Create a panel data set with a multi index in years and countries</p>
<pre><code>import pandas
import numpy as np
df = pandas.DataFrame(
    {&quot;country&quot;: [&#39;Algeria&#39;, &#39;Angola&#39;, &#39;Benin&#39;, &#39;Botswana&#39;, &#39;Burkina Faso&#39;] * 2,
     &quot;year&quot;: np.repeat(np.array([2020,2021]), 5),
     &quot;value&quot;:  np.random.randint(0,1e3,10)
     })
df = df.set_index([&quot;year&quot;, &quot;country&quot;])</code></pre>
<p>Use the multi index to select data for 2020 only</p>
<pre><code>idx = pandas.IndexSlice
df.loc[idx[2020, :]]</code></pre>
<p>Use the multi index to select data for Algeria only, in all years</p>
<pre><code>df.loc[idx[:, &quot;Algeria&quot;], :]</code></pre>
<p>Note: it’s better to write <code>df.loc[idx[2020, :], :]</code> than
<code>df.loc[(2020,)]</code>. The later is in fact just equivalent to
<code>df.loc[(2020,)]</code>. Note that df.loc[(,“Algeria”)] would
return a syntax error</p>
<p>See also the course material <a
href="https://python.quantecon.org/pandas_panel.html">Pandas for panel
data</a>.</p>
<p>Sample data copied from <code>help(df.loc)</code>:</p>
<pre><code>tuples = [
   (&#39;cobra&#39;, &#39;mark i&#39;), (&#39;cobra&#39;, &#39;mark ii&#39;),
   (&#39;sidewinder&#39;, &#39;mark i&#39;), (&#39;sidewinder&#39;, &#39;mark ii&#39;),
   (&#39;viper&#39;, &#39;mark ii&#39;), (&#39;viper&#39;, &#39;mark iii&#39;)
]
index = pandas.MultiIndex.from_tuples(tuples)
values = [[12, 2], [0, 4], [10, 20],
        [1, 4], [7, 1], [16, 36]]
df = pandas.DataFrame(values, columns=[&#39;max_speed&#39;, &#39;shield&#39;], index=index)</code></pre>
<p>Single label. Note this returns a DataFrame with a single index.</p>
<pre><code>df.loc[&#39;cobra&#39;]</code></pre>
<p>Single index tuple. Note this returns a Series.</p>
<pre><code>df.loc[(&#39;cobra&#39;, &#39;mark ii&#39;)]
df.loc[(:,&#39;mark ii&#39;)]</code></pre>
<p>Single tuple. Note using <code>[[]]</code> returns a DataFrame.</p>
<pre><code>df.loc[[(&#39;cobra&#39;, &#39;mark ii&#39;)]]</code></pre>
<p>Single label for row and column. Similar to passing in a tuple, this
returns a Series.</p>
<pre><code>df.loc[&#39;cobra&#39;, &#39;mark i&#39;]</code></pre>
<p>Slice from index tuple to single label</p>
<pre><code>df.loc[(&#39;cobra&#39;, &#39;mark i&#39;):&#39;viper&#39;]</code></pre>
<p>Slice from index tuple to index tuple</p>
<pre><code>df.loc[(&#39;cobra&#39;, &#39;mark i&#39;):(&#39;viper&#39;, &#39;mark ii&#39;)]</code></pre>
<p>Invert a selection on the second index</p>
<pre><code>df.loc[~df.index.isin([&quot;mark i&quot;], level=1)]</code></pre>
<div id="df.index.get_level_values" class="section level5">
<h5>df.index.get_level_values</h5>
<p>Get index level values to use conditional checks on those values. For
example select years smaller than 2021:</p>
<pre><code>selector = df.index.get_level_values(&quot;year&quot;) &lt; 2021
df.loc[selector]</code></pre>
</div>
<div id="multi-index-slicers-to-select-the-second-index-element"
class="section level5">
<h5>Multi-index slicers to select the second index element</h5>
<p><a
href="https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#using-slicers">Using
slicers</a></p>
<blockquote>
<p>“You can use pandas.IndexSlice to facilitate a more natural syntax
using <code>:</code>, rather than using <code>slice(None)</code>.”</p>
</blockquote>
<p>Other example from <a
href="https://stackoverflow.com/questions/56340906/ilocing-one-level-of-a-multiindex">a
SO question</a></p>
<pre><code>import pandas
df = pandas.DataFrame(index = pandas.MultiIndex.from_product([range(2010,2020),
                      [&#39;mike&#39;, &#39;matt&#39;, &#39;dave&#39;, &#39;frank&#39;, &#39;larry&#39;], ]))
df[&#39;x&#39;]=0
df.index.names=[&#39;year&#39;, &#39;people&#39;]
df.loc[2010]
df.loc[(2010,&quot;mike&quot;)]</code></pre>
<p>These two <code>df.loc[2010]</code>,
<code>df.loc[(2010,"mike")]</code> work, but</p>
<pre><code>df.loc[&quot;mike&quot;]</code></pre>
<p>Returns a <code>KeyError: 'mike'</code>. To select on the second
index level only, you need a multi index slicer.</p>
<pre><code>idx = pandas.IndexSlice
df.loc[idx[:, &quot;mike&quot;],:]</code></pre>
<p>You can also use <code>df.xs</code></p>
<pre><code>df.xs(&quot;mike&quot;, level=1)
df.xs(&quot;mike&quot;, level=&quot;people&quot;)</code></pre>
<p><a href="https://stackoverflow.com/a/50414126/2641825">Using loc on
just the second index in multi index</a> Other example using the same
data frame as the previous section.</p>
<pre><code>idx = pandas.IndexSlice
df.loc[idx[:, &quot;mark i&quot;],:]
df.xs(&quot;mark i&quot;, level=1)</code></pre>
</div>
</div>
</div>
<div id="iloc" class="section level3">
<h3>iloc</h3>
<p><a
href="https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-integer">.iloc</a>
is primarily integer position based (from 0 to length -1 of the axis),
but may also be used with a boolean array.</p>
<p>Create a sample data frame:</p>
<pre><code>In : example = [{&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3, &#39;d&#39;: 4},
                {&#39;a&#39;: 100, &#39;b&#39;: 200, &#39;c&#39;: 300, &#39;d&#39;: 400},
                {&#39;a&#39;: 1000, &#39;b&#39;: 2000, &#39;c&#39;: 3000, &#39;d&#39;: 4000 }]
      df = pandas.DataFrame(example)

In : df
Out: 
            a     b     c     d
      0     1     2     3     4
      1   100   200   300   400
      2  1000  2000  3000  4000</code></pre>
<p>Index with a slice object. Note that it doesn’t include the upper
bound.</p>
<pre><code>In :  df.iloc[0:2]
Out: 
          a    b    c    d
     0    1    2    3    4
     1  100  200  300  400</code></pre>
<p>With lists of integers.</p>
<pre><code>In : df.iloc[[0, 2], [1, 3]]
Out: 
            b     d
      0     2     4
      2  2000  4000</code></pre>
<p>With slice objects.</p>
<pre><code>In : df.iloc[1:3, 0:3]
Out: 
            a     b     c
      1   100   200   300
      2  1000  2000  3000</code></pre>
<p>With a boolean array whose length matches the columns.</p>
<pre><code>In : df.iloc[:, [True, False, True, False]]
Out: 
            a     c
      0     1     3
      1   100   300
      2  1000  3000</code></pre>
</div>
<div id="query" class="section level3">
<h3>Query</h3>
<p>Query the columns of a Data Frame with a boolean expression.</p>
<pre><code>df = pandas.DataFrame({&#39;A&#39;: range(1, 6),
                       &#39;B&#39;: range(10, 0, -2),
                       &#39;C&#39;: range(10, 5, -1)})
df.query(&quot;A &gt; B&quot;)

A  B  C
5  2  6</code></pre>
<p>Two queries</p>
<pre><code>df.query(&quot;A &lt; B and B &lt; C&quot;)
df.query(&quot;A &lt; B or B &lt; C&quot;)</code></pre>
<p>Query using a variable</p>
<pre><code>limit = 3
df.query(&quot;A &gt; @limit&quot;)

A  B  C
4  4  7
5  2  6</code></pre>
<p>Query for a variable in a list</p>
<pre><code>df.query(&quot;A in [3,6]&quot;)</code></pre>
<p>Query for a variable not in a list</p>
<pre><code>df.query(&quot;A not in [3,6]&quot;)</code></pre>
<div id="str.contains-and-str.startswith" class="section level4">
<h4>str.contains and str.startswith</h4>
<p>str.contains and str.startswith do not work with the default numexpre
engine, you need to set <code>engine="python"</code> as explained in <a
href="https://stackoverflow.com/a/51375487/2641825">this answer</a>.</p>
<p>Example use on a table of product codes, query products description
that contain “oak” but not “cloak” and query sawnwood products starting
with “4407”:</p>
<pre><code>comtrade.products.hs.query(&quot;product_description.str.contains(&#39;oak&#39;) and not product_description.str.contains(&#39;cloak&#39;)&quot;, engine=&quot;python&quot;)
comtrade.products.hs.query(&quot;product_code.str.startswith(&#39;4407&#39;)&quot;, engine=&quot;python&quot;)</code></pre>
</div>
</div>
<div id="isin" class="section level3">
<h3>isin</h3>
<p><a
href="https://stackoverflow.com/questions/12096252/use-a-list-of-values-to-select-rows-from-a-pandas-dataframe">Use
alist of values to select rows</a></p>
<pre><code>df = pandas.DataFrame({&#39;A&#39;: [5,6,3,4], &#39;B&#39;: [1,2,3,5]})
df[df[&#39;A&#39;].isin([3, 6])]
df.loc[df[&#39;A&#39;].isin([3, 6])]
df.query(&quot;A in [3,6]&quot;)</code></pre>
</div>
<div id="square-brackets" class="section level3">
<h3>Square brackets</h3>
<p>Select the second column with square brackets</p>
<pre><code>df[df.columns[1]]</code></pre>
</div>
<div id="xs-cross-sections" class="section level3">
<h3>xs cross sections</h3>
<p>The <code>key</code> and <code>level</code> arguments specify which
part of the multilevel index should be used. Create a sample data frame,
copied from <code>help(df.xs)</code>:</p>
<pre><code>d = {&#39;num_legs&#39;: [4, 4, 2, 2],
     &#39;num_wings&#39;: [0, 0, 2, 2],
     &#39;class&#39;: [&#39;mammal&#39;, &#39;mammal&#39;, &#39;mammal&#39;, &#39;bird&#39;],
     &#39;animal&#39;: [&#39;cat&#39;, &#39;dog&#39;, &#39;bat&#39;, &#39;penguin&#39;],
     &#39;locomotion&#39;: [&#39;walks&#39;, &#39;walks&#39;, &#39;flies&#39;, &#39;walks&#39;]}
df = pandas.DataFrame(data=d)
df = df.set_index([&#39;class&#39;, &#39;animal&#39;, &#39;locomotion&#39;])
print(df)</code></pre>
<p>Select with a key following the order in which levels appear in the
index:</p>
<pre><code>df.xs(&#39;mammal&#39;)
df.xs((&#39;mammal&#39;, &#39;dog&#39;))</code></pre>
<p>Select with a key and specify the levels:</p>
<pre><code>df.xs(key=&#39;cat&#39;, level=1)
df.xs(key=(&#39;bird&#39;, &#39;walks&#39;),
      level=[0, &#39;locomotion&#39;])</code></pre>
<p>Pandas <a
href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html">DataFrame.xs</a>
“cannot be used to set values.”</p>
</div>
<div id="determine-whether-a-column-contains-a-particular-value"
class="section level3">
<h3>Determine whether a column contains a particular value</h3>
<p><a
href="https://stackoverflow.com/questions/21319929/how-to-determine-whether-a-pandas-column-contains-a-particular-value">How
to determine whether a pandas column contains a particular
varlue</a></p>
<blockquote>
<p>In of a Series checks whether the value is in the index:</p>
</blockquote>
<pre><code>In : s = pd.Series(list(&#39;abc&#39;))
In : 1 in s
Out: True
In : &#39;a&#39; in s
Out: False</code></pre>
<blockquote>
<p>One option is to see if it’s in unique values:</p>
</blockquote>
<pre><code>In : &#39;a&#39; in s.unique()
Out: True</code></pre>
</div>
<div id="check-if-df-is-empty" class="section level3">
<h3>Check if df is empty</h3>
<p><a
href="https://stackoverflow.com/questions/19828822/how-to-check-whether-a-pandas-dataframe-is-empty">SO
question</a> recomends using the boolean value <code>df.empty</code> to
test whether a data frame is empty.</p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
selector = iris[&quot;species&quot;] == &quot;non_existant&quot;
df = iris[selector]
df.empty</code></pre>
</div>
</div>
<div id="sort-or-arrange-values" class="section level2">
<h2>Sort or arrange values</h2>
<p>Sort iris by descending order of species and ascending order of petal
width</p>
<pre><code>iris.sort_values(by=[&quot;species&quot;, &quot;petal_width&quot;], ascending=[False,True])</code></pre>
</div>
<div id="string-operations-in-pandas" class="section level2">
<h2>String operations in pandas</h2>
<p>See also string operations in python in another section.</p>
<p>String operations in pandas use vectorized string methods of the
class StringMethods(pandas.core.base.NoNewAttributesMixin).</p>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})
help(df.a.str)</code></pre>
<p>Concatenate all values in a character vector:</p>
<pre><code>df[&#39;a&#39;].str.cat()</code></pre>
<p>Extract the first 2 or last 2 characters</p>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:[&#39;bla&#39;,&#39;bli&#39;,&#39;quoi?&#39;]})
df[&quot;a&quot;].str[:2]
df[&quot;a&quot;].str[-2:]</code></pre>
<div id="search-and-replace" class="section level3">
<h3>Search and replace</h3>
<p>Search one element or another in a character vector:</p>
<pre><code>df = pandas.DataFrame({&#39;a&#39;:[&#39;bla&#39;,&#39;ble&#39;,&#39;bli2&#39;]})
df[df[&#39;a&#39;].str.contains(&#39;a|i&#39;)]</code></pre>
<p>Replace elements in a character vector:</p>
<pre><code>df[&#39;a&#39;].replace(&#39;a|i&#39;,&#39;b&#39;,regex=True)</code></pre>
<p>Keep only numbers</p>
<pre><code>df[&quot;a&quot;].replace(&#39;[a-zA-Z]&#39;, &#39;&#39;, regex=True)</code></pre>
</div>
<div id="separate-a-columns-in-two-based-on-a-split-pattern"
class="section level3">
<h3>Separate a columns in two based on a split pattern</h3>
<p>The “too many values to unpack” error can also be returned by the
<code>str.split</code> method of pandas data frames.</p>
<p>For example splitting a character vector on the “<code>,</code>”
pattern:</p>
<pre><code>import pandas
df = pandas.DataFrame({&quot;x&quot;: [&quot;a&quot;, &quot;a, b&quot;, &quot;a,b,c&quot;]})
df.x.str.split(&quot;,&quot;)

# 0          [a]
# 1      [a,  b]
# 2    [a, b, c]

df.x.str.split(&quot;,&quot;, n=1)

# 0         [a]
# 1     [a,  b]
# 2    [a, b,c]

df.x.str.split(&quot;,&quot;, expand=True)

#    0     1     2
# 0  a  None  None
# 1  a     b  None
# 2  a     b     c

df.x.str.split(&quot;,&quot;, n=1, expand=True)

#    0     1
# 0  a  None
# 1  a     b
# 2  a   b,c</code></pre>
<p>The following version works only if each row has exactly 2 splits. It
<strong>fails</strong> with the <strong>error</strong> “too many values
to unpack (expected 2)” in this example:</p>
<pre><code>df[&quot;y&quot;], df[&quot;z&quot;] = df.x.str.split(&quot;,&quot;, n=1)</code></pre>
<p>The last version with both <code>n=1</code> and
<code>expand=True</code> is the one to use for multiple vector
assignment. It is equivalent to <a
href="https://tidyr.tidyverse.org/reference/separate.html">tidyr::separate</a>
in R.</p>
<pre><code>df[[&quot;y&quot;, &quot;z&quot;]] = df.x.str.split(&quot;,&quot;, n=1, expand=True)
df

#        x  y     z
# 0      a  a  None
# 1   a, b  a     b
# 2  a,b,c  a   b,c</code></pre>
<p>According to the <a
href="https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html">documentation
of pandas.Series.str.split</a> If n &gt; 0 and</p>
<blockquote>
<p>“If for a certain row the number of found splits &lt; n, append None
for padding up to n if expand=True.”</p>
</blockquote>
</div>
<div id="extract-columns-based-on-a-pattern" class="section level3">
<h3>Extract columns based on a pattern</h3>
<p>Place product patterns in a capture group for extraction</p>
<pre><code>df = pandas.DataFrame({&quot;x&quot;: [&quot;am&quot;, &quot;an&quot;, &quot;o&quot;, &quot;bm&quot;, &quot;bn&quot;, &quot;cm&quot;]})
product_pattern = &quot;a|b|c&quot;
df[[&quot;product&quot;, &quot;element&quot;]] = df.x.str.extract(f&quot;({product_pattern})?(.*)&quot;)
df</code></pre>
</div>
</div>
<div id="difference-between-2-data-frames" class="section level2">
<h2>Difference between 2 data frames</h2>
<ul>
<li><a
href="https://stackoverflow.com/questions/48647534/python-pandas-find-difference-between-two-data-frames">Find
difference between two data frames</a></li>
<li><a
href="https://stackoverflow.com/questions/36891977/pandas-diff-of-two-dataframes/36893773">Diff
of 2 data frames</a></li>
</ul>
<p>Two methods Using <code>merge</code>:</p>
<pre><code>merged = df1.merge(df2, indicator=True, how=&#39;outer&#39;)
merged[merged[&#39;_merge&#39;] == &#39;right_only&#39;]</code></pre>
<p>Using <code>drop_duplicates</code></p>
<pre><code>newdf=pd.concat[df1,df2].drop_duplicates(keep=False)</code></pre>
</div>
<div id="duplicated-values" class="section level2">
<h2>Duplicated values</h2>
<p>Warn in case the variable x is duplicated</p>
<pre><code>import pandas
df = pandas.DataFrame({&quot;x&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;], &quot;y&quot;: range(4)})
dup_x = df[&quot;x&quot;].duplicated(keep=False)
if any(dup_x):
    msg = &quot;x values are not unique. &quot;
    msg += &quot;The following duplicates are present:\n&quot;
    msg += f&quot;{df.loc[dup_x]}&quot;
    raise ValueError(msg)</code></pre>
<p>Drop duplicates</p>
<pre><code>df[&quot;x&quot;].drop_duplicates()
df[&quot;x&quot;].drop_duplicates(keep=False)
df[&quot;x&quot;].drop_duplicates(keep=&quot;last&quot;)</code></pre>
</div>
<div id="where-and-mask" class="section level2">
<h2>Where and mask</h2>
<p><code>where</code> replaces values that do not fit the condition and
<code>mask</code> replaces values that fit the condition.</p>
<pre><code>s = pandas.Series(range(5))
s.where(s &gt; 1, 10)
s.mask(s &gt; 1, 10)</code></pre>
<p>On a data frame</p>
<pre><code>import pandas
import numpy as np
df1 = pandas.DataFrame({&#39;x&#39;:[0,np.nan, np.nan], 
                        &#39;y&#39;:[&#39;a&#39;,np.nan,&#39;c&#39;]})
df2 = pandas.DataFrame({&#39;x&#39;:[10, 11, 12], 
                        &#39;y&#39;:[&#39;x&#39;,&#39;y&#39;, np.nan]})
df1.mask(df1.isna(), df2)
df1.where(df1.isna(), df2)</code></pre>
</div>
</div>
<div id="paths" class="section level1">
<h1>Paths</h1>
<div id="copy-or-move-files" class="section level2">
<h2>Copy or move files</h2>
<p>Write to a text file using a <a
href="https://book.pythontips.com/en/latest/context_managers.html">context
manager</a>, then copy the file somewhere else.</p>
<pre><code>with open(&quot;/tmp/bli.md&quot;, &quot;w&quot;) as f:
    f.write(&#39;Hola!&#39;)</code></pre>
<p>Copy a file</p>
<pre><code>import shutil
shutil.copy(&quot;/tmp/bli.md&quot;, &quot;/tmp/bla.md&quot;)</code></pre>
<p>Move a file</p>
<pre><code>shutil.move(&quot;/tmp/bli.md&quot;, &quot;/tmp/bla.md&quot;)</code></pre>
</div>
<div id="delete-files-or-directories" class="section level2">
<h2>Delete files or directories</h2>
<p>Create a file and a path object for example purposes</p>
<pre><code>import pathlib
with open(&quot;/tmp/bli.md&quot;, &quot;w&quot;) as f:
    f.write(&#39;Hola!&#39;)
bli_path = pathlib.Path(&quot;/tmp/bli.md&quot;)</code></pre>
<p>Delete a file if it exists</p>
<pre><code>if bli_path.exists():
    bli_path.unlink()</code></pre>
<p>Create a directory and path object for example purposes</p>
<pre><code>import pathblib</code></pre>
<p>Delete a directory if it exists</p>
<p>See also:</p>
<ul>
<li><a
href="https://stackoverflow.com/questions/6996603/how-can-i-delete-a-file-or-folder-in-python"
class="uri">https://stackoverflow.com/questions/6996603/how-can-i-delete-a-file-or-folder-in-python</a></li>
</ul>
</div>
<div id="pathlib" class="section level2">
<h2>Pathlib</h2>
<p>Pathlib is an object oriented path API for python as explained in <a
href="https://www.python.org/dev/peps/pep-0428/#why-an-object-oriented-api">PEP
428</a></p>
<p>Instead of</p>
<pre><code>import os
os.path.join(&#39;~&#39;,&#39;downloads&#39;)</code></pre>
<p>You can use:</p>
<pre><code>from pathlib import Path
Path(&#39;~&#39;) / &#39;downloads&#39;</code></pre>
<p>Data located in the home folder</p>
<pre><code> data_dir = Path.home() / &quot;repos/data/&quot;</code></pre>
<div id="check-if-a-directory-is-empty" class="section level3">
<h3>Check if a directory is empty</h3>
<p>Check if a directory is empty using pathlib</p>
<pre><code>import pathlib
p1 = pathlib.Path(&quot;/tmp/&quot;)
p2 = pathlib.Path(&quot;/tmp/thisisempty/&quot;)
p2.mkdir()
any(p1.iterdir()) # returns True
any(p2.iterdir()) # returns False</code></pre>
</div>
<div id="dir-name-or-parent-directory" class="section level3">
<h3>Dir name or parent directory</h3>
<p><a href="https://stackoverflow.com/a/35490226/2641825">SO
question</a> that illustrate different levels of parents</p>
<pre><code>import os
import pathlib
p = pathlib.Path(&#39;/path/to/my/file&#39;)
p.parents[0]
p.parents[1]
p.parent</code></pre>
<blockquote>
<p>“Note that os.path.dirname and pathlib treat paths with a trailing
slash differently. The pathlib parent of some/path/ is some: While
os.path.dirname on some/path/ returns some/path”:</p>
</blockquote>
<pre><code>pathlib.Path(&#39;some/path/&#39;).parent
os.path.dirname(&#39;some/path/&#39;)</code></pre>
</div>
<div id="home" class="section level3">
<h3>Home</h3>
<p>Cross platform way to refer to the home directory</p>
<pre><code>from pathlib import Path
Path.home()</code></pre>
</div>
<div id="list-all-files-in-a-directory" class="section level3">
<h3>List all files in a directory</h3>
<p>If <code>p</code> is a pathlib object you can list file names
corresponding to a file pattern as such:</p>
<pre><code>[x.name for x in p.glob(&#39;**/*.csv&#39;)]</code></pre>
<p>You can also use the simpler <code>iterdir()</code> method to list
all files in the directory</p>
<pre><code>from pathlib import Path
dir_path = Path(&#39;/tmp&#39;)
for file_path in dir_path.iterdir():
    print(file_path)</code></pre>
</div>
</div>
<div id="python-path" class="section level2">
<h2>Python Path</h2>
<p>Temporarily add to the python path (<a
href="https://stackoverflow.com/questions/3402168/permanently-add-a-directory-to-pythonpath">SO
question</a>) in order to import scripts</p>
<pre><code>import sys
sys.path.append(&#39;/path/to/dir&#39;)
# You might want to prepend if you want to overwrite a system package
sys.path.insert(0, &quot;/home/rougipa/eu_cbm/eu_cbm_hat&quot;)
# If it&#39;s a pathlib object, you want to convert it to string first
sys.path.insert(0, str(path_lib_object))</code></pre>
<p>To permanently add a package under development to the python path,
add the following to your <code>.bashrc</code> or
<code>.bash_profile</code>:</p>
<pre><code>export PYTHONPATH=&quot;$HOME/repos/project_name/&quot;:$PYTHONPATH</code></pre>
</div>
<div id="temporary-directories-and-files" class="section level2">
<h2>Temporary directories and files</h2>
<p>Docs.python.org <a
href="https://docs.python.org/3/library/tempfile.html#examples">tempfile
examples</a> using a context manager</p>
<pre><code>import tempfile
# create a temporary directory using the context manager
with tempfile.TemporaryDirectory() as tmpdirname:
    print(&#39;created temporary directory&#39;, tmpdirname)
# directory and contents have been removed</code></pre>
<p>Using <code>pathlib</code> to facilitate path manipulation on top of
<code>tempfile</code> makes it possible to create new paths using the
<code>/</code> path operator of pathlib:</p>
<pre><code>import tempfile
from pathlib import Path
with tempfile.TemporaryDirectory() as tmpdirname:
    temp_dir = Path(tmpdirname)
    print(temp_dir, temp_dir.exists())
    file_name = temp_dir / &quot;test.txt&quot;
    file_name.write_text(&quot;bla bla bla&quot;)
    print(file_name, &quot;contains&quot;, file_name.open().read())</code></pre>
<p>Outside the context manager, files have been destroyed</p>
<pre><code>print(temp_dir, temp_dir.exists())
# /tmp/tmp81iox6s2 False
print(file_name, file_name.exists())
# /tmp/tmp81iox6s2/test.txt False</code></pre>
</div>
</div>
<div id="plot" class="section level1">
<h1>Plot</h1>
<p><a href="https://pythonplot.com/">Python plotting for exploratory
analysis</a> is a great gallery of plot examples, each example is
written in 5 different plotting libraries: pandas, plotnine, plotly,
altair and R ggplot2. There is also one seaborn example.</p>
<div id="matplotlib" class="section level2">
<h2>Matplotlib</h2>
<p>All matplotlib examples require the following imports:</p>
<pre><code>from matplotlib import pyplot as plt
plt.style.use(&#39;seaborn-whitegrid&#39;)
import numpy as np</code></pre>
<p>Simple line plot changing the figure size and the axes limit with
pyplot</p>
<pre><code>plt.rcParams[&#39;figure.figsize&#39;] = [10, 10]
fig = plt.figure()
ax = plt.axes()
x = np.linspace(-1.5, 1.5, 1000)
ax.plot(x, 1-3*x)
ax.set_xlim(-6, 6)
ax.set_ylim(-6, 6)</code></pre>
<p>Scatter plot, using a colour variable and the ‘jet’ colour map.</p>
<pre><code>Y = np.array([1,-1,-1, 1])
X = np.array([
        [-1, -1],
        [ 1, -1],
        [-1,  1],
        [ 1,  1]])
fig = plt.figure()
ax = plt.axes()
ax.scatter(X[:,0], X[:,1],c=Y, cmap=&#39;jet&#39;)</code></pre>
<p>Use another <a
href="https://matplotlib.org/examples/color/colormaps_reference.html">colour
map</a></p>
<pre><code>ax.scatter(X[:,0], X[:,1],c=Y, cmap=&#39;Spectral&#39;)</code></pre>
<p>Plot the probability density function of the <a
href="https://en.wikipedia.org/wiki/Normal_distribution">normal
distribution</a>.</p>
<p><span class="math display">\[f(x)=\frac{1}{\sigma{\sqrt {2\pi
}}}e^{-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma
}}\right)^{2}}\]</span></p>
<p>With various sigma and mu values displayed in the legend.</p>
<pre><code>fig = plt.figure()
ax = plt.axes()
x = np.linspace(-5, 5, 1000)
def pdensitynormal(x,sigma_squared,mu):
    sigma = np.sqrt(sigma_squared)
    return 1/(sigma*np.sqrt(2*np.math.pi))*np.exp(-1/2*((x-mu)/sigma)**2)
ax.plot(x, pdensitynormal(x,0.2,0), label=&quot;$\sigma^2=0.2, \mu=0$&quot;)
ax.plot(x, pdensitynormal(x,1,0), label=&quot;$\sigma^2=1, \mu=0$&quot;)
ax.plot(x, pdensitynormal(x,5,0), label=&quot;$\sigma^2=5, \mu=0$&quot;)
ax.plot(x, pdensitynormal(x,0.5,-2), label=&quot;$\sigma^2=0.5, \mu=-2$&quot;)
ax.legend(loc=&quot;upper right&quot;)
plt.show()</code></pre>
<p>3D line, contour plot and scatter plot</p>
<pre><code>from mpl_toolkits import mplot3d # Required for 3d plots
fig = plt.figure()
ax = plt.axes(projection=&#39;3d&#39;)
# Data for a three-dimensional line
xline = np.linspace(-10, 10, 1000)
yline = np.linspace(-10, 10, 1000)
# Just a line
zline = xline**2 + yline**2
ax.plot3D(xline, yline, zline, &#39;gray&#39;)
# A mesh grid
X, Y = np.meshgrid(xline, yline)
Z = X**2 + Y**2
ax.contour3D(X, Y, Z, 50, cmap=&#39;binary&#39;)
# Scatter points
ax.scatter(1,2,3)</code></pre>
<p>See how the <code>np.meshgridi</code> objects interact with each
other. Note this nested loop is not the optimal way to compute. Better
to use X<strong>2 + Y</strong>2 directly as above.</p>
<pre><code>for i in range(Z.shape[0]):
    for j in range(Z.shape[1]):
        vector = np.array([X[i,j],Y[i,j]])
            Z[i,j] = np.linalg.norm(vector)**2
fig = plt.figure()
ax = plt.axes(projection=&#39;3d&#39;)
ax.contour3D(X, Y, Z, 50, cmap=&#39;binary&#39;)</code></pre>
<div id="axes-object" class="section level3">
<h3>Axes object</h3>
<p>Create an axes object</p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;x&#39;:range(0,30), &#39;y&#39;:range(110,140)})
plot = df.plot(x=&quot;x&quot;, y=&quot;y&quot;, kind=&quot;scatter&quot;)
help(plot)</code></pre>
<p>Create another axes object for a faceted plot</p>
<p>It has the following methods</p>
<pre><code>print([m for m in dir(plot) if not m.startswith(&quot;_&quot;)])

[&#39;ArtistList&#39;, &#39;acorr&#39;, &#39;add_artist&#39;, &#39;add_callback&#39;, &#39;add_child_axes&#39;, 
&#39;add_collection&#39;, &#39;add_container&#39;, &#39;add_image&#39;, &#39;add_line&#39;, &#39;add_patch&#39;, 
&#39;add_table&#39;, &#39;angle_spectrum&#39;, &#39;annotate&#39;, &#39;apply_aspect&#39;, &#39;arrow&#39;, 
&#39;artists&#39;, &#39;autoscale&#39;, &#39;autoscale_view&#39;, &#39;axes&#39;, &#39;axhline&#39;, &#39;axhspan&#39;, 
&#39;axis&#39;, &#39;axison&#39;, &#39;axline&#39;, &#39;axvline&#39;, &#39;axvspan&#39;, &#39;bar&#39;, &#39;bar_label&#39;, 
&#39;barbs&#39;, &#39;barh&#39;, &#39;bbox&#39;, &#39;boxplot&#39;, &#39;broken_barh&#39;, &#39;bxp&#39;, &#39;callbacks&#39;, 
&#39;can_pan&#39;, &#39;can_zoom&#39;, &#39;child_axes&#39;, &#39;cla&#39;, &#39;clabel&#39;, &#39;clear&#39;, &#39;clipbox&#39;, 
&#39;cohere&#39;, &#39;collections&#39;, &#39;containers&#39;, &#39;contains&#39;, &#39;contains_point&#39;, 
&#39;contour&#39;, &#39;contourf&#39;, &#39;convert_xunits&#39;, &#39;convert_yunits&#39;, &#39;csd&#39;, 
&#39;dataLim&#39;, &#39;drag_pan&#39;, &#39;draw&#39;, &#39;draw_artist&#39;, &#39;end_pan&#39;, &#39;errorbar&#39;, 
&#39;eventplot&#39;, &#39;figure&#39;, &#39;fill&#39;, &#39;fill_between&#39;, &#39;fill_betweenx&#39;, &#39;findobj&#39;, 
&#39;fmt_xdata&#39;, &#39;fmt_ydata&#39;, &#39;format_coord&#39;, &#39;format_cursor_data&#39;, 
&#39;format_xdata&#39;, &#39;format_ydata&#39;, &#39;get_adjustable&#39;, &#39;get_agg_filter&#39;, 
&#39;get_alpha&#39;, &#39;get_anchor&#39;, &#39;get_animated&#39;, &#39;get_aspect&#39;, 
&#39;get_autoscale_on&#39;, &#39;get_autoscalex_on&#39;, &#39;get_autoscaley_on&#39;, 
&#39;get_axes_locator&#39;, &#39;get_axisbelow&#39;, &#39;get_box_aspect&#39;, &#39;get_children&#39;, 
&#39;get_clip_box&#39;, &#39;get_clip_on&#39;, &#39;get_clip_path&#39;, &#39;get_cursor_data&#39;, 
&#39;get_data_ratio&#39;, &#39;get_default_bbox_extra_artists&#39;, &#39;get_facecolor&#39;, 
&#39;get_fc&#39;, &#39;get_figure&#39;, &#39;get_frame_on&#39;, &#39;get_gid&#39;, &#39;get_gridspec&#39;, 
&#39;get_images&#39;, &#39;get_in_layout&#39;, &#39;get_label&#39;, &#39;get_legend&#39;, 
&#39;get_legend_handles_labels&#39;, &#39;get_lines&#39;, &#39;get_mouseover&#39;, &#39;get_navigate&#39;, 
&#39;get_navigate_mode&#39;, &#39;get_path_effects&#39;, &#39;get_picker&#39;, &#39;get_position&#39;, 
&#39;get_rasterization_zorder&#39;, &#39;get_rasterized&#39;, &#39;get_renderer_cache&#39;, 
&#39;get_shared_x_axes&#39;, &#39;get_shared_y_axes&#39;, &#39;get_sketch_params&#39;, &#39;get_snap&#39;, 
&#39;get_subplotspec&#39;, &#39;get_tightbbox&#39;, &#39;get_title&#39;, &#39;get_transform&#39;, 
&#39;get_transformed_clip_path_and_affine&#39;, &#39;get_url&#39;, &#39;get_visible&#39;, 
&#39;get_window_extent&#39;, &#39;get_xaxis&#39;, &#39;get_xaxis_text1_transform&#39;, 
&#39;get_xaxis_text2_transform&#39;, &#39;get_xaxis_transform&#39;, &#39;get_xbound&#39;, 
&#39;get_xgridlines&#39;, &#39;get_xlabel&#39;, &#39;get_xlim&#39;, &#39;get_xmajorticklabels&#39;, 
&#39;get_xminorticklabels&#39;, &#39;get_xscale&#39;, &#39;get_xticklabels&#39;, &#39;get_xticklines&#39;, 
&#39;get_xticks&#39;, &#39;get_yaxis&#39;, &#39;get_yaxis_text1_transform&#39;, 
&#39;get_yaxis_text2_transform&#39;, &#39;get_yaxis_transform&#39;, &#39;get_ybound&#39;, 
&#39;get_ygridlines&#39;, &#39;get_ylabel&#39;, &#39;get_ylim&#39;, &#39;get_ymajorticklabels&#39;, 
&#39;get_yminorticklabels&#39;, &#39;get_yscale&#39;, &#39;get_yticklabels&#39;, &#39;get_yticklines&#39;, 
&#39;get_yticks&#39;, &#39;get_zorder&#39;, &#39;grid&#39;, &#39;has_data&#39;, &#39;have_units&#39;, &#39;hexbin&#39;, 
&#39;hist&#39;, &#39;hist2d&#39;, &#39;hlines&#39;, &#39;ignore_existing_data_limits&#39;, &#39;images&#39;, 
&#39;imshow&#39;, &#39;in_axes&#39;, &#39;indicate_inset&#39;, &#39;indicate_inset_zoom&#39;, &#39;inset_axes&#39;, 
&#39;invert_xaxis&#39;, &#39;invert_yaxis&#39;, &#39;is_transform_set&#39;, &#39;label_outer&#39;, 
&#39;legend&#39;, &#39;legend_&#39;, &#39;lines&#39;, &#39;locator_params&#39;, &#39;loglog&#39;, 
&#39;magnitude_spectrum&#39;, &#39;margins&#39;, &#39;matshow&#39;, &#39;minorticks_off&#39;, 
&#39;minorticks_on&#39;, &#39;mouseover&#39;, &#39;name&#39;, &#39;patch&#39;, &#39;patches&#39;, &#39;pchanged&#39;, 
&#39;pcolor&#39;, &#39;pcolorfast&#39;, &#39;pcolormesh&#39;, &#39;phase_spectrum&#39;, &#39;pick&#39;, &#39;pickable&#39;, 
&#39;pie&#39;, &#39;plot&#39;, &#39;plot_date&#39;, &#39;properties&#39;, &#39;psd&#39;, &#39;quiver&#39;, &#39;quiverkey&#39;, 
&#39;redraw_in_frame&#39;, &#39;relim&#39;, &#39;remove&#39;, &#39;remove_callback&#39;, &#39;reset_position&#39;, 
&#39;scatter&#39;, &#39;secondary_xaxis&#39;, &#39;secondary_yaxis&#39;, &#39;semilogx&#39;, &#39;semilogy&#39;, 
&#39;set&#39;, &#39;set_adjustable&#39;, &#39;set_agg_filter&#39;, &#39;set_alpha&#39;, &#39;set_anchor&#39;, 
&#39;set_animated&#39;, &#39;set_aspect&#39;, &#39;set_autoscale_on&#39;, &#39;set_autoscalex_on&#39;, 
&#39;set_autoscaley_on&#39;, &#39;set_axes_locator&#39;, &#39;set_axis_off&#39;, &#39;set_axis_on&#39;, 
&#39;set_axisbelow&#39;, &#39;set_box_aspect&#39;, &#39;set_clip_box&#39;, &#39;set_clip_on&#39;, 
&#39;set_clip_path&#39;, &#39;set_facecolor&#39;, &#39;set_fc&#39;, &#39;set_figure&#39;, &#39;set_frame_on&#39;, 
&#39;set_gid&#39;, &#39;set_in_layout&#39;, &#39;set_label&#39;, &#39;set_mouseover&#39;, &#39;set_navigate&#39;, 
&#39;set_navigate_mode&#39;, &#39;set_path_effects&#39;, &#39;set_picker&#39;, &#39;set_position&#39;, 
&#39;set_prop_cycle&#39;, &#39;set_rasterization_zorder&#39;, &#39;set_rasterized&#39;, 
&#39;set_sketch_params&#39;, &#39;set_snap&#39;, &#39;set_subplotspec&#39;, &#39;set_title&#39;, 
&#39;set_transform&#39;, &#39;set_url&#39;, &#39;set_visible&#39;, &#39;set_xbound&#39;, &#39;set_xlabel&#39;, 
&#39;set_xlim&#39;, &#39;set_xmargin&#39;, &#39;set_xscale&#39;, &#39;set_xticklabels&#39;, &#39;set_xticks&#39;, 
&#39;set_ybound&#39;, &#39;set_ylabel&#39;, &#39;set_ylim&#39;, &#39;set_ymargin&#39;, &#39;set_yscale&#39;, 
&#39;set_yticklabels&#39;, &#39;set_yticks&#39;, &#39;set_zorder&#39;, &#39;sharex&#39;, &#39;sharey&#39;, 
&#39;specgram&#39;, &#39;spines&#39;, &#39;spy&#39;, &#39;stackplot&#39;, &#39;stairs&#39;, &#39;stale&#39;, 
&#39;stale_callback&#39;, &#39;start_pan&#39;, &#39;stem&#39;, &#39;step&#39;, &#39;sticky_edges&#39;, 
&#39;streamplot&#39;, &#39;table&#39;, &#39;tables&#39;, &#39;text&#39;, &#39;texts&#39;, &#39;tick_params&#39;, 
&#39;ticklabel_format&#39;, &#39;title&#39;, &#39;titleOffsetTrans&#39;, &#39;transAxes&#39;, &#39;transData&#39;, 
&#39;transLimits&#39;, &#39;transScale&#39;, &#39;tricontour&#39;, &#39;tricontourf&#39;, &#39;tripcolor&#39;, 
&#39;triplot&#39;, &#39;twinx&#39;, &#39;twiny&#39;, &#39;update&#39;, &#39;update_datalim&#39;, &#39;update_from&#39;, 
&#39;use_sticky_edges&#39;, &#39;viewLim&#39;, &#39;violin&#39;, &#39;violinplot&#39;, &#39;vlines&#39;, &#39;xaxis&#39;, 
&#39;xaxis_date&#39;, &#39;xaxis_inverted&#39;, &#39;xcorr&#39;, &#39;yaxis&#39;, &#39;yaxis_date&#39;, 
&#39;yaxis_inverted&#39;, &#39;zorder&#39;]</code></pre>
</div>
<div id="figure-object" class="section level3">
<h3>Figure object</h3>
<p>Create a figure object</p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;x&#39;:range(0,30), &#39;y&#39;:range(110,140)})
plot = df.plot(x=&quot;x&quot;, y=&quot;y&quot;, kind=&quot;scatter&quot;)
fig = plot.get_figure()
help(fig)</code></pre>
<p>A figure object is the “The top level container for all the plot
elements.” It has the following methods:</p>
<pre><code>print([m for m in dir(fig) if not m.startswith(&quot;_&quot;)])

[&#39;add_artist&#39;, &#39;add_axes&#39;, &#39;add_axobserver&#39;, &#39;add_callback&#39;, 
&#39;add_gridspec&#39;, &#39;add_subfigure&#39;, &#39;add_subplot&#39;, &#39;align_labels&#39;, 
&#39;align_xlabels&#39;, &#39;align_ylabels&#39;, &#39;artists&#39;, &#39;autofmt_xdate&#39;, &#39;axes&#39;, 
&#39;bbox&#39;, &#39;bbox_inches&#39;, &#39;callbacks&#39;, &#39;canvas&#39;, &#39;clear&#39;, &#39;clf&#39;, &#39;clipbox&#39;, 
&#39;colorbar&#39;, &#39;contains&#39;, &#39;convert_xunits&#39;, &#39;convert_yunits&#39;, &#39;delaxes&#39;, 
&#39;dpi&#39;, &#39;dpi_scale_trans&#39;, &#39;draw&#39;, &#39;draw_artist&#39;, &#39;draw_without_rendering&#39;, 
&#39;execute_constrained_layout&#39;, &#39;figbbox&#39;, &#39;figimage&#39;, &#39;figure&#39;, &#39;findobj&#39;, 
&#39;format_cursor_data&#39;, &#39;frameon&#39;, &#39;gca&#39;, &#39;get_agg_filter&#39;, &#39;get_alpha&#39;, 
&#39;get_animated&#39;, &#39;get_axes&#39;, &#39;get_children&#39;, &#39;get_clip_box&#39;, &#39;get_clip_on&#39;, 
&#39;get_clip_path&#39;, &#39;get_constrained_layout&#39;, &#39;get_constrained_layout_pads&#39;, 
&#39;get_cursor_data&#39;, &#39;get_default_bbox_extra_artists&#39;, &#39;get_dpi&#39;, 
&#39;get_edgecolor&#39;, &#39;get_facecolor&#39;, &#39;get_figheight&#39;, &#39;get_figure&#39;, 
&#39;get_figwidth&#39;, &#39;get_frameon&#39;, &#39;get_gid&#39;, &#39;get_in_layout&#39;, &#39;get_label&#39;, 
&#39;get_layout_engine&#39;, &#39;get_linewidth&#39;, &#39;get_mouseover&#39;, &#39;get_path_effects&#39;, 
&#39;get_picker&#39;, &#39;get_rasterized&#39;, &#39;get_size_inches&#39;, &#39;get_sketch_params&#39;, 
&#39;get_snap&#39;, &#39;get_tight_layout&#39;, &#39;get_tightbbox&#39;, &#39;get_transform&#39;, 
&#39;get_transformed_clip_path_and_affine&#39;, &#39;get_url&#39;, &#39;get_visible&#39;, 
&#39;get_window_extent&#39;, &#39;get_zorder&#39;, &#39;ginput&#39;, &#39;have_units&#39;, &#39;images&#39;, 
&#39;is_transform_set&#39;, &#39;legend&#39;, &#39;legends&#39;, &#39;lines&#39;, &#39;mouseover&#39;, &#39;number&#39;, 
&#39;patch&#39;, &#39;patches&#39;, &#39;pchanged&#39;, &#39;pick&#39;, &#39;pickable&#39;, &#39;properties&#39;, &#39;remove&#39;, 
&#39;remove_callback&#39;, &#39;savefig&#39;, &#39;sca&#39;, &#39;set&#39;, &#39;set_agg_filter&#39;, &#39;set_alpha&#39;, 
&#39;set_animated&#39;, &#39;set_canvas&#39;, &#39;set_clip_box&#39;, &#39;set_clip_on&#39;, 
&#39;set_clip_path&#39;, &#39;set_constrained_layout&#39;, &#39;set_constrained_layout_pads&#39;, 
&#39;set_dpi&#39;, &#39;set_edgecolor&#39;, &#39;set_facecolor&#39;, &#39;set_figheight&#39;, &#39;set_figure&#39;, 
&#39;set_figwidth&#39;, &#39;set_frameon&#39;, &#39;set_gid&#39;, &#39;set_in_layout&#39;, &#39;set_label&#39;, 
&#39;set_layout_engine&#39;, &#39;set_linewidth&#39;, &#39;set_mouseover&#39;, &#39;set_path_effects&#39;, 
&#39;set_picker&#39;, &#39;set_rasterized&#39;, &#39;set_size_inches&#39;, &#39;set_sketch_params&#39;, 
&#39;set_snap&#39;, &#39;set_tight_layout&#39;, &#39;set_transform&#39;, &#39;set_url&#39;, &#39;set_visible&#39;, 
&#39;set_zorder&#39;, &#39;show&#39;, &#39;stale&#39;, &#39;stale_callback&#39;, &#39;sticky_edges&#39;, &#39;subfigs&#39;, 
&#39;subfigures&#39;, &#39;subplot_mosaic&#39;, &#39;subplotpars&#39;, &#39;subplots&#39;, 
&#39;subplots_adjust&#39;, &#39;suppressComposite&#39;, &#39;suptitle&#39;, &#39;supxlabel&#39;, 
&#39;supylabel&#39;, &#39;text&#39;, &#39;texts&#39;, &#39;tight_layout&#39;, &#39;transFigure&#39;, 
&#39;transSubfigure&#39;, &#39;update&#39;, &#39;update_from&#39;, &#39;waitforbuttonpress&#39;, &#39;zorder&#39;]</code></pre>
</div>
<div id="xy-comparison-scatter-plot" class="section level3">
<h3>XY comparison scatter plot</h3>
<p>When x and y are supposed to be the same value but are not
necessarily equal. Compare the x and y values on a scatter plot to a y=x
line.</p>
<pre><code>def comp_plot(df, x_var, y_var, title):
    &quot;&quot;&quot;Plot comparison for the given data frame&quot;&quot;&quot;
    # Scatter plot
    plt.scatter(df[x_var], df[y_var])
    # 1:1 line
    line = np.linspace(df[x_var].min(), df[x_var].max(), 100)
    plt.plot(line, line, &#39;r--&#39;)
    plt.xlabel(f&#39;{x_var} additional text&#39;)
    plt.ylabel(f&#39;{y_var} additional text&#39;)
    plt.title(title)
    return plt</code></pre>
<p>Note on suggestions compared between Bard and Chat GPT-4</p>
<pre><code>    # Create the 1:1 line suggested by bard
    line_x = np.linspace(x.min(), x.max(), 100)
    line_y = line_x
    plt.plot(line_x, line_y, &#39;r--&#39;)
    # 1:1 line suggested by GPT4 (wrong in some way)
    plt.plot([min(x), max(x)], [min(y), max(y)], &#39;r&#39;)</code></pre>
</div>
<div id="save-figures-to-pdf-png-or-svg-files" class="section level3">
<h3>Save figures to pdf, png or svg files</h3>
<p>This works with pandas plots and seaborn plots as well.</p>
<p>With the pyplot object, only works immediately after building the
plot.</p>
<pre><code>plt.savefig(&quot;/tmp/bli.pdf&quot;)
plt.savefig(&quot;/tmp/bli.png&quot;)
plt.savefig(&quot;file_name.svg&quot;, bbox_inches=&#39;tight&#39;)</code></pre>
<p>Save a plot object to a pdf file</p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;x&#39;:range(0,30), &#39;y&#39;:range(110,140)})
plot = df.plot(x=&quot;x&quot;, y=&quot;y&quot;, kind=&quot;scatter&quot;)
fig = plot.get_figure()
fig.savefig(&#39;/tmp/output.pdf&#39;, format=&#39;pdf&#39;)</code></pre>
<p>Save a grid plot object to a pdf file</p>
<pre><code>fmri = seaborn.load_dataset(&quot;fmri&quot;)
g = seaborn.relplot(
    data=fmri, x=&quot;timepoint&quot;, y=&quot;signal&quot;, col=&quot;region&quot;,
    hue=&quot;event&quot;, style=&quot;event&quot;, kind=&quot;line&quot;,
    facet_kws={&#39;sharey&#39;: False, &#39;sharex&#39;: False}
)
g.savefig(&quot;/tmp/fmri.pdf&quot;)</code></pre>
</div>
</div>
<div id="pandas-plots-are-matplotlib-axessubplot-objects"
class="section level2">
<h2>Pandas plots are matplotlib AxesSubplot objects</h2>
<div id="arguments-of-the-df.plot-function" class="section level3">
<h3>Arguments of the df.plot() function</h3>
<p>Example values for the df.plot() function:</p>
<ul>
<li><p><code>figsize=(3,3)</code> change the figure size. <a
href="https://stackoverflow.com/a/51174822/2641825">SO answer</a> links
to the documentation that explains that</p>
<pre><code>&gt; &quot;plt.figure(figsize=(10,5)) doesn&#39;t work because df.plot() creates its
&gt; own matplotlib.axes.Axes object, the size of which cannot be changed
&gt; after the object has been created. &quot;</code></pre></li>
<li><p><code>title='bla bla'</code> add a plot title</p></li>
<li><p><code>colormap</code> change colours</p></li>
</ul>
</div>
<div id="show-pandas-plots-in-ipython" class="section level3">
<h3>Show pandas plots in ipython</h3>
<p>Create some data and change the xticks labels</p>
<pre><code>import pandas
import matplotlib.pyplot as plt
df = pandas.DataFrame({&#39;x&#39;:range(0,30), &#39;y&#39;:range(10,40)})
df.set_index(&#39;x&#39;, inplace=True)
plot = df.plot(title=&#39;Two ranges&#39;)
type(plot)
# help(plot)
plot.set_xticks(range(0,31,10), minor=False)
plt.show()</code></pre>
</div>
<div id="colour-palette-in-pandas-plots" class="section level3">
<h3>Colour palette in pandas plots</h3>
<p>Simple palette as a dictionary</p>
<pre><code>palette = {&#39;ssp2&#39;: &#39;orange&#39;,
           &#39;fair&#39;: &#39;green&#39;, 
           &#39;historical_period&#39;: &#39;black&#39;}
df.plot(title = &quot;Harvest Scenarios&quot;, ylabel=&quot;Million m3&quot;, color=palette)</code></pre>
<p>Note: the argument for seaborn would be palette=palette.</p>
<p>Using a list of colours with matplotlib <a
href="https://matplotlib.org/stable/api/_as_gen/matplotlib.colors.ListedColormap.html">ListedColormap</a>
(see also example in that documentation page): Reusing the data frame
from the previous section</p>
<pre><code>from matplotlib.colors import ListedColormap
df[&quot;z&quot;] = 39 
df[&quot;a&quot;] = 10
df.plot(colormap=ListedColormap([&quot;red&quot;,&quot;green&quot;,&quot;orange&quot;]), figsize=(3,3))
plt.show()
plt.savefig(&quot;/tmp/plotpalette.png&quot;)</code></pre>
<p>Using a seaborn palette with the <code>as_cmap=True</code>
argument:</p>
<pre><code>palette = seaborn.color_palette(&quot;rocket_r&quot;, as_cmap=True)
df.plot(colormap=palette, figsize=(3,3))
# plt.show()
plt.savefig(&quot;/tmp/plotpalette2.png&quot;)</code></pre>
</div>
<div id="histogram" class="section level3">
<h3>Histogram</h3>
<p>Histogram</p>
<pre><code>iris[&quot;petal_width&quot;].hist(bins=20)</code></pre>
<p>Options for title, labels, colours</p>
<pre><code>import pandas
import matplotlib.pyplot as plt
series = pandas.Series([1, 2, 2, 3, 3, 3, 4, 4, 4, 4])
series.hist(grid=False, bins=20, rwidth=0.9, color=&#39;#607c8e&#39;)
plt.title(&#39;Title&#39;)
plt.xlabel(&#39;Counts&#39;)
plt.ylabel(&#39;Frequency&#39;)
plt.grid(axis=&#39;y&#39;, alpha=0.75)
plt.show()</code></pre>
<p>Histogram with a log scale</p>
</div>
<div id="pandas-plots-side-by-side" class="section level3">
<h3>Pandas plots side by side</h3>
<p>Using the same df as above show 2 plost side by side based on this <a
href="https://stackoverflow.com/a/68008119/2641825">SO answer</a></p>
<pre><code>fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,6))
df.plot(title=&#39;Two ranges&#39;, ax=ax1)
df.plot(title=&#39;Two ranges&#39;, ax=ax2)
plt.show()</code></pre>
</div>
</div>
<div id="plotly" class="section level2">
<h2>Plotly</h2>
<p>The advantage of plotly is that it provides dynamic visualisation
inside web pages, such as the possibility to zoom in a graph. It’s the
open source component of a commercial project called Dash
entreprise.</p>
<p>For example <a
href="https://colab.research.google.com/github/bytehub-ai/blog-examples/blob/master/temperature_forecast_example.ipynb#scrollTo=7yJZA1CZSSx4">this
notebook</a> on machine learning used to enhance the localisation of
weather forecasts. Seen on this blog post <a
href="https://medium.com/bytehub-ai/what-does-machine-learning-have-to-do-with-weather-94f3ac625ad3">What
does machine learning have to do with weather</a>.</p>
<div id="bubble-chart" class="section level3">
<h3>Bubble chart</h3>
<ul>
<li><p><a href="https://plotly.com/python/bubble-charts/"
class="uri">https://plotly.com/python/bubble-charts/</a> example:</p>
<p>import plotly.express as px df = px.data.gapminder() fig =
px.scatter(df.query(“year==2007”), x=“gdpPercap”, y=“lifeExp”,
size=“pop”, color=“continent”, hover_name=“country”, log_x=True,
size_max=60) fig.show()</p></li>
</ul>
</div>
<div id="facet-chart" class="section level3">
<h3>Facet chart</h3>
<p>Facet chart where the y facet label where removed and replaced with a
common annotation. (There was an issue with the annotation dissapearing
when going full screen in a streamlit app).</p>
<pre><code>y_var = f&quot;{flow} {element}&quot;
fig = plotly.express.line(
    # shorten the plot facet titles
    df.rename(columns={&quot;product_name&quot;: &quot;p&quot;,
                       flow: y_var}),
    x=&quot;period&quot;,
    y=y_var,
    color=&quot;partner&quot;,
    facet_row=&quot;p&quot;,
    line_group=&quot;partner&quot;,
)
# Remove y facet labels
for axis in fig.layout:
    if type(fig.layout[axis]) == plotly.graph_objects.layout.YAxis:
        fig.layout[axis].title.text = &#39;&#39;
# Update y label, by adding to the existing annotation
fig.layout.annotations += (
    dict(
        x=0,
        y=0.5,
        showarrow=False,
        text=f&quot;{flow} {element}&quot;,
        textangle=-90,
        # xanchor=&#39;left&#39;,
        # yanchor=&quot;middle&quot;,
        xref=&quot;paper&quot;,
        yref=&quot;paper&quot;
    ), # Keep this comma, this needs to be a tuple
)</code></pre>
</div>
<div id="xy-comparison-scatter-plot-1" class="section level3">
<h3>XY comparison scatter plot</h3>
<p>When x and y are supposed to be the same value but are not
necessarily equal. Compare the x and y values on a scatter plot to a 1:1
line.</p>
<pre><code>import plotly

def comp_plotly(df, x_var, y_var, title):
    &quot;&quot;&quot;Plot comparison for the given data frame&quot;&quot;&quot;
    fig = plotly.graph_objects.Figure()
    fig.add_trace(go.Scatter(x=df[x_var], y=df[y_var], mode=&#39;markers&#39;, name=&#39;Data&#39;))
    fig.add_trace(go.Scatter(x=[min(x), max(x)], y=[min(x), max(x)], mode=&#39;lines&#39;, name=&#39;1:1 Line&#39;))
    fig.update_layout(
        title=&#39;Scatter plot with 1:1 Line&#39;,
        xaxis_title=x_var,
        yaxis_title=y_var
    )
    # Add the reporter, partner, and year to the tooltip
    fig.update_traces(
        hoverinfo=&#39;text&#39;,
        hovertext=list(zip(df[&#39;reporter&#39;], df[&#39;partner&#39;], df[&#39;year&#39;]))
    )
    return fig

this_primary_product = &quot;rape_or_colza_seed&quot;
selector = comp_2[&quot;primary_product&quot;] == this_primary_product
comp_plotly(comp_2.loc[selector],
            x_var = &#39;primary_crop_eq_re_allocated_2nd_level_imported&#39;,
            y_var = &#39;primary_eq_imp_alloc_1&#39;,
            title = f&quot;Step 2 primary crop import {this_primary_product}&quot;)</code></pre>
</div>
</div>
<div id="plotnine" class="section level2">
<h2>Plotnine</h2>
<p>Grammar of graphics for python <a
href="https://github.com/has2k1/plotnine"
class="uri">https://github.com/has2k1/plotnine</a></p>
<div id="figure-size" class="section level3">
<h3>Figure size</h3>
<p>Change the <a
href="https://plotnine.readthedocs.io/en/stable/generated/plotnine.options.figure_size.html">plotnine
figure size</a></p>
<pre><code>import plotnine
plotnine.options.figure_size = (12, 8)</code></pre>
</div>
<div id="facet-grid" class="section level3">
<h3>Facet grid</h3>
<p>Create a facet grid plot</p>
<pre><code>from plotnine import ggplot, aes, geom_line, facet_grid, labs</code></pre>
</div>
</div>
<div id="seaborn" class="section level2">
<h2>Seaborn</h2>
<p>All Seaborn examples below require the following imports and
datasets:</p>
<pre><code>import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
tips = seaborn.load_dataset(&quot;tips&quot;) 
fmri = seaborn.load_dataset(&quot;fmri&quot;)
from matplotlib import pyplot as plt</code></pre>
<p>Resources</p>
<ul>
<li><a href="https://seaborn.pydata.org/examples/index.html">Seaborn
gallery</a></li>
</ul>
<div id="axes" class="section level3">
<h3>Axes</h3>
<div id="invert-axis" class="section level4">
<h4>Invert axis</h4>
<p>Of a single figure</p>
<pre><code>ax.invert_yaxis()</code></pre>
<p>Of a grid figure</p>
<pre><code>g = seaborn.relplot(x=&#39;crop&#39;, y=&#39;ranking&#39;, col=&#39;intensity&#39;,
                      hue=&#39;conservation_target&#39;, data=df)
for ax in g.axes[0]:
    ax.invert_yaxis()</code></pre>
</div>
<div id="labels-and-titles" class="section level4">
<h4>labels and titles</h4>
<p>Use p.set() to set a y label and a title</p>
<pre><code>p = seaborn.scatterplot(&#39;petal_length&#39;,&#39;petal_width&#39;,&#39;species&#39;,data=iris)
p.set(xlabel = &quot;Petal Length&quot;, ylabel = &quot;Petal Width&quot;, title = &quot;Flower sizes&quot;)
plt.show()</code></pre>
<p>Use <code>set_title</code> to add a title:</p>
<pre><code>(seaborn
 .scatterplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips)
 .set_title(&#39;Progression of tips along the bill amount&#39;)
)</code></pre>
</div>
<div id="labels-on-grid-plots" class="section level4">
<h4>Labels on grid plots</h4>
<p>Set a common title for grid plots</p>
<pre><code>g = seaborn.FacetGrid(tips, col=&quot;time&quot;, row=&quot;smoker&quot;)
g = g.map(plt.hist, &quot;total_bill&quot;)
# Supplementary title
g.fig.suptitle(&#39;I don&#39;t smoke and I don&#39;t tip.&#39;)</code></pre>
<p>Add axis labels for grid plots</p>
<pre><code> g.fig.supxlabel(&quot;time in years&quot;)
 g.fig.supylabel(&quot;weight in kg&quot;)</code></pre>
<p>In case the title is overwritten on the subplots, you might need to
use <a
href="https://stackoverflow.com/a/28650623/2641825">fig.subplot_adjust()</a>
as such:</p>
<pre><code>g.fig.subplots_adjust(top=.95)</code></pre>
</div>
<div id="axes-limit" class="section level4">
<h4>Axes limit</h4>
<p>Set limits on the one axis in a Seaborn plot:</p>
<pre><code>p = seaborn.scatterplot(&#39;petal_length&#39;,&#39;petal_width&#39;,&#39;species&#39;,data=iris)
p.set(ylim=(-2,None))</code></pre>
<p>In Seaborn facet grid. <a
href="https://stackoverflow.com/a/25213614/2641825">How to set xlim and
ylim in seaborn facet grid</a></p>
<pre><code>g = seaborn.FacetGrid(tips, col=&quot;time&quot;, row=&quot;smoker&quot;)
g = g.map(plt.hist, &quot;total_bill&quot;)
g.set(ylim=(0, None)) </code></pre>
</div>
<div id="year-to-date-time-objects" class="section level4">
<h4>Year to date time objects</h4>
<p>Years are sometimes displayed with commas, convert them to date time
objects to avoid this:</p>
<pre><code>pandas.to_datetime(comp[&quot;year&quot;], format=&quot;%Y&quot;)</code></pre>
</div>
</div>
<div id="bar-plot" class="section level3">
<h3>Bar plot</h3>
<p>Bar plot</p>
<pre><code>import matplotlib.pyplot as plt
import seaborn
iris = seaborn.load_dataset(&quot;iris&quot;)
iris_agg = iris.groupby(&quot;species&quot;).agg(sum)
iris_agg_long = iris_agg.melt(ignore_index=False).reset_index()
seaborn.barplot(data=iris_agg_long, x=&quot;variable&quot;, y=&quot;value&quot;, hue=&quot;species&quot;)</code></pre>
<p>Rotate index labels</p>
<pre><code>plt.xticks(rotation=70)
plt.tight_layout()
plt.show()</code></pre>
</div>
<div id="palettes-and-styles" class="section level3">
<h3>Palettes and styles</h3>
<div id="colour-palette" class="section level4">
<h4>Colour palette</h4>
<p>See various examples in the plots in the seaborn section. The palette
can be defined from pre existing palettes</p>
<pre><code>palette = seaborn.color_palette(&quot;rocket_r&quot;)</code></pre>
<p>Without argument this function displays the default palette</p>
<pre><code>seaborn.color_palette()</code></pre>
<p>It can translate a list of colour codes into a palette</p>
<pre><code>seaborn.color_palette([&quot;r&quot;,&quot;g&quot;,&quot;b&quot;])
seaborn.color_palette([&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;, &quot;orange&quot;])</code></pre>
<p>This function is used internally by the palette argument of plotting
functions:</p>
<pre><code>p1 = sns.relplot(x=&quot;Growth&quot;, y=&quot;Value&quot;, hue=&quot;Risk&quot;, col=&quot;Mcap&quot;, data=mx, s=200, palette=[&#39;r&#39;, &#39;g&#39;, &#39;y&#39;])</code></pre>
<p>Another example using a dictionary for the palette</p>
<pre><code>palette = {&quot;fair&quot;:&quot;green&quot;, &quot;ssp2&quot;:&quot;orange&quot;, &quot;historical&quot;:&quot;black&quot;}
p = seaborn.lineplot(x=&quot;year&quot;, y=&quot;gdp_t&quot;, hue=&quot;scenario&quot;, data=df_gdp_eu, palette=palette)</code></pre>
<p>Seaborn tutorial on choosing colour palettes <a
href="https://seaborn.pydata.org/tutorial/color_palettes.html"
class="uri">https://seaborn.pydata.org/tutorial/color_palettes.html</a></p>
<p>According to <a href="https://stackoverflow.com/a/46174007/2641825"
class="uri">https://stackoverflow.com/a/46174007/2641825</a> you can
also use a dictionary to associate hue values to a palette element.</p>
<pre><code>selected_products = [&quot;wood_fuel&quot;, 
                     &quot;sawlogs_and_veneer_logs&quot;,
                     &quot;pulpwood_round_and_split_all_species_production&quot;,
                     &quot;other_industrial_roundwood&quot;]
palette = dict(zip(selected_products, [&quot;red&quot;, &quot;brown&quot;, &quot;blue&quot;, &quot;grey&quot;]))</code></pre>
<p>Generate darker and lighter green and orange colours</p>
<pre><code>lighter_green = seaborn.dark_palette(&#39;green&#39;, n_colors=5)[0]
darker_green = seaborn.dark_palette(&#39;green&#39;, n_colors=5, reverse=True)[0]
lighter_orange = seaborn.dark_palette(&#39;orange&#39;, n_colors=5)[0]
darker_orange = seaborn.dark_palette(&#39;orange&#39;, n_colors=5, reverse=True)[0]</code></pre>
<div id="colour-names" class="section level5">
<h5>Colour names</h5>
<ul>
<li><p><a href="https://seaborn.pydata.org/tutorial/color_palettes.html"
class="uri">https://seaborn.pydata.org/tutorial/color_palettes.html</a></p>
<blockquote>
<p>“. It’s also possible to pass a list of colors specified any way that
matplotlib accepts (an RGB tuple, a hex code, or a name in the X11
table).</p>
</blockquote>
<ul>
<li>Named colors in Matplotlib as in the X11 table <a
href="https://stackoverflow.com/questions/22408237/named-colors-in-matplotlib"
class="uri">https://stackoverflow.com/questions/22408237/named-colors-in-matplotlib</a></li>
</ul></li>
</ul>
<pre class="python"><code>import matplotlib.pyplot as plt
from matplotlib import colors as mcolors
colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)</code></pre>
<pre><code>    SO answer has a plot of this dict of colors with names.</code></pre>
</div>
<div id="colour-blindness" class="section level5">
<h5>Colour blindness</h5>
<ul>
<li>Simulate colour blindness <a
href="https://www.color-blindness.com/coblis-color-blindness-simulator/"
class="uri">https://www.color-blindness.com/coblis-color-blindness-simulator/</a></li>
</ul>
</div>
</div>
<div id="linestyle-dict-doesnt-work" class="section level4">
<h4>Linestyle dict (doesn’t work)</h4>
<p>Example of specifying line styles doesn’t work</p>
<pre><code>linestyle_dict = {&#39;Industrial roundwood&#39;: &#39;solid&#39;, &#39;Fuelwood&#39;: &#39;dotted&#39;}
g = sns.relplot(data=df.loc[selector], x=&#39;year&#39;, y=&#39;demand&#39;, col=&#39;country&#39;,
                hue=&#39;combo_name&#39;, style=&quot;faostat_name&quot;, kind=&#39;line&#39;,
                col_wrap=col_wrap, palette=palette_combo,
                facet_kws={&#39;sharey&#39;: False, &#39;sharex&#39;: False},
                dashes=linestyle_dict)</code></pre>
<p>See also <a
href="https://stackoverflow.com/questions/65549047/how-to-apply-a-linestyle-to-a-specific-line-in-seaborn-lineplot"
class="uri">https://stackoverflow.com/questions/65549047/how-to-apply-a-linestyle-to-a-specific-line-in-seaborn-lineplot</a></p>
</div>
</div>
<div id="facet-grid-plots" class="section level3">
<h3>Facet grid plots</h3>
<p>Use Figure-level interface for drawing plots onto a FacetGrid:</p>
<ul>
<li><p>catplot for drawing categorical plots</p></li>
<li><p>relplot for drawing relational plots</p>
<ul>
<li>kind=“scatter” (the default) for scatter plots</li>
<li>kind=“line” for line plots</li>
</ul></li>
</ul>
<p>The figure level interfaces return FacetGrid objects which can be
reused to add subsequent layers.</p>
<p>Seaborn version 0.12.1 introduced an object interfacet which can also
be used to make facet plots.</p>
<div id="facet-title-and-size" class="section level4">
<h4>Facet title and size</h4>
<p>Change row and column labels to display only the content (not
“<code>label=</code>”) and change the size to 30.</p>
<pre><code>import seaborn
seaborn.set_theme(style=&quot;darkgrid&quot;)
df = seaborn.load_dataset(&quot;penguins&quot;)
g = seaborn.displot(
    df, x=&quot;flipper_length_mm&quot;, col=&quot;species&quot;, row=&quot;sex&quot;,
    binwidth=3, height=3, facet_kws=dict(margin_titles=True),
)
g.fig.subplots_adjust(top=.9, bottom=0.1, right=0.9)
g.set_titles(row_template=&quot;{row_name}&quot;, col_template=&quot;{col_name}&quot;, size=30)</code></pre>
<p>See also the figure size section.</p>
</div>
<div id="grid-bar-plot" class="section level4">
<h4>Grid Bar plot</h4>
<p>Draw a facet bar plot <a
href="https://stackoverflow.com/a/62225095/2641825">from SO</a> for each
combination of size and smoker/non smoker</p>
<pre><code>import seaborn as sns
import matplotlib.pyplot as plt
sns.set()
tips=sns.load_dataset(&quot;tips&quot;)
g = sns.FacetGrid(tips, col = &#39;size&#39;,  row = &#39;smoker&#39;, hue = &#39;day&#39;)
g = (g.map(sns.barplot, &#39;time&#39;, &#39;total_bill&#39;, ci = None).add_legend())
plt.show()</code></pre>
</div>
<div id="grid-histogram" class="section level4">
<h4>Grid histogram</h4>
<p><a href="https://seaborn.pydata.org/examples/faceted_histogram.html"
class="uri">https://seaborn.pydata.org/examples/faceted_histogram.html</a></p>
<pre><code>import seaborn
seaborn.set_theme(style=&quot;darkgrid&quot;)
df = seaborn.load_dataset(&quot;penguins&quot;)
seaborn.displot(
    df, x=&quot;flipper_length_mm&quot;, col=&quot;species&quot;, row=&quot;sex&quot;,
    binwidth=3, height=3, facet_kws=dict(margin_titles=True),
)</code></pre>
</div>
<div id="grid-line-plot" class="section level4">
<h4>Grid line plot</h4>
<div id="relplot" class="section level5">
<h5>relplot</h5>
<p>help(searborn.relplot)</p>
<pre><code>&gt; &quot;This function provides access to several different axes-level functions
&gt; that show the relationship between two variables with semantic mappings
&gt; of subsets. The ``kind`` parameter selects the underlying axes-level
&gt; function to use:
&gt;     - :func:`scatterplot` with ``kind=&quot;scatter&quot;``; the default
&gt;     - :func:`lineplot` with ``kind=&quot;line&quot;``
&gt; Extra keyword arguments are passed to the underlying function, so you should
&gt; refer to the documentation for each to see kind-specific options.&quot;</code></pre>
<p>Example:</p>
<ul>
<li><p>plot signal through time and facet along the region</p></li>
<li><p>use different axes size. This requires passing a dictionary to
FacetGrid.</p></li>
<li><p>Add a y label</p></li>
<li><p>adjust the left margin so that the y label doesn’t overwrite the
axis</p></li>
<li><p>Set the Y limit to zero</p>
<p>g = seaborn.relplot( data=fmri, x=“timepoint”, y=“signal”,
col=“region”, hue=“event”, style=“event”, kind=“line”, col_wrap=1,
height=3, facet_kws={‘sharey’: False, ‘sharex’: False} )
g.fig.supylabel(“Adaptive Engagement of Cognitive Control”)
g.fig.subplots_adjust(left=0.28, top=0.9) g.fig.suptitle(“Example”)
g.set_ylabels(“Y label”) g.set(ylim=(0, None)) plt.show()</p></li>
</ul>
<p>Older example from <a
href="https://seaborn.pydata.org/examples/faceted_lineplot.html"
class="uri">https://seaborn.pydata.org/examples/faceted_lineplot.html</a></p>
<pre><code>import seaborn as sns
sns.set_theme(style=&quot;ticks&quot;)

dots = sns.load_dataset(&quot;dots&quot;)

# Define the palette as a list to specify exact values
palette = sns.color_palette(&quot;rocket_r&quot;)

# Plot the lines on two facets
g = sns.relplot(
    data=dots,
    x=&quot;time&quot;, y=&quot;firing_rate&quot;,
    hue=&quot;coherence&quot;, size=&quot;choice&quot;, col=&quot;align&quot;,
    kind=&quot;line&quot;, size_order=[&quot;T1&quot;, &quot;T2&quot;], palette=palette,
    height=5, aspect=.75, facet_kws=dict(sharex=False),
)
g.fig.suptitle(&quot;Dots example&quot;)
# Add a title and adjust the position so the title doesn&#39;t overwrite facets
g.set_ylabels(&quot;Y label&quot;)
plt.subplots_adjust(top=0.9)</code></pre>
</div>
<div id="object-interface" class="section level5">
<h5>Object interface</h5>
<p>Facet line plot example</p>
<pre><code>import seaborn
import seaborn.objects as so
healthexp = seaborn.load_dataset(&quot;healthexp&quot;)
(
    so.Plot(healthexp, x=&quot;Year&quot;, y=&quot;Life_Expectancy&quot;)
    .facet(&quot;Country&quot;, wrap=3)
    .add(so.Line(alpha=.3), group=&quot;Country&quot;, col=None)
    .add(so.Line(linewidth=3))
)</code></pre>
<p>Example from my data</p>
<pre><code>import seaborn.objects as so
(
    so.Plot(df, x=&quot;age&quot;, y=&quot;volume&quot;)
    .facet(&quot;forest_type&quot;, wrap=6)
    .add(so.Line(alpha=.3), group=&quot;forest_type&quot;, col=None)
    .add(so.Line(linewidth=3))
)</code></pre>
</div>
</div>
<div id="grid-scatter-plot" class="section level4">
<h4>Grid scatter plot</h4>
<p>Draw a scatter plot for each iris species, using the recommended
<code>relplot()</code> function:</p>
<pre><code>g = seaborn.relplot(x=&#39;petal_length&#39;, y=&#39;petal_width&#39;, col=&#39;species&#39;, hue=&#39;species&#39;, data=iris)
plt.show()</code></pre>
<p>help(seaborn.relplot) explains that it returns a FacetGrid
object:</p>
<pre><code>&gt; &quot; After plotting, the :class:`FacetGrid` with the plot is returned and can be
&gt; used directly to tweak supporting plot details or add other layers.&quot;</code></pre>
<p>Old way: using FacetGrid directly requires changing the species to a
categorical variable in order to have a different colour for each
species.</p>
<pre><code>g = seaborn.FacetGrid(iris, col=&quot;species&quot;, height=6)
iris[&#39;species&#39;] = iris[&#39;species&#39;].astype(&#39;category&#39;)
# Use map_dataframe to name the arguments
g.map_dataframe(seaborn.scatterplot,x=&#39;petal_length&#39;,y=&#39;petal_width&#39;,hue=&#39;species&#39;)
plt.show()

# Old way without named argument
g.map(seaborn.scatterplot,&#39;petal_length&#39;,&#39;petal_width&#39;,&#39;species&#39;)
plt.show()</code></pre>
<p>Notice that if you don’t change the color to a categorical variable,
it will not vary across the species. I reported <a
href="https://github.com/mwaskom/seaborn/issues/2028">this issue</a>
which led me to update the searborn documentation in this <a
href="https://github.com/mwaskom/seaborn/pull/2030/commits/88a45dddeb6ac4c88ab49da195e7a05843ad4aaf">merge
request</a>.</p>
<blockquote>
<p>“When using seaborn functions that infer semantic mappings from a
dataset, care must be taken to synchronize those mappings across facets.
In other words some mechanism needs to ensure that the same mapping is
used in each facet. This can be achieved for example by passing pallete
dictionnaries or by defining categorical types in your dataframe. In
most cases, it will be better to use a figure-level function
(e.g. :func:<code>relplot</code> or :func:<code>catplot</code>) than to
use :class:<code>FacetGrid</code> directly.”</p>
</blockquote>
<div id="grid-scatter-plot-with-xy-line" class="section level5">
<h5>Grid scatter plot with x=y line</h5>
<p>A grid scatter plot with an x=y line for comparison purposes</p>
<pre><code>g = seaborn.relplot(data=df,
                x=&quot;x_var&quot;,
                y=&quot;y=var&quot;,
                col=&quot;year&quot;,
                hue=&quot;partner&quot;,
                kind=&quot;scatter&quot;,
               )
g.fig.subplots_adjust(top=0.9)
# Add x=y line
for ax in g.axes.flat:
    ax.plot(ax.get_xlim(), ax.get_ylim(), ls=&quot;--&quot;, c=&quot;.3&quot;, scalex=False, scaley=False)</code></pre>
</div>
</div>
<div id="grid-text" class="section level4">
<h4>Grid Text</h4>
<p>From [SO answer][<a
href="https://stackoverflow.com/a/59775753/2641825"
class="uri">https://stackoverflow.com/a/59775753/2641825</a>)</p>
<pre><code>import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
data = [[&#39;APOLLOHOSP&#39;, 8, 6, &#39;High&#39;, &#39;small&#39;],
        [&#39;ANUP&#39;, 8, 7, &#39;High&#39;, &#39;small&#39;],
        [&#39;SIS&#39;, 4, 6, &#39;High&#39;, &#39;mid&#39;],
        [&#39;HAWKINCOOK&#39;, 5, 2, &#39;Low&#39;, &#39;mid&#39;],
        [&#39;NEULANDLAB&#39;, 6, 4, &#39;Low&#39;, &#39;large&#39;],
        [&#39;ORIENTELEC&#39;, 7, 9, &#39;Low&#39;, &#39;mid&#39;],
        [&#39;AXISBANK&#39;, 2, 3, &#39;Medium&#39;, &#39;mid&#39;],
        [&#39;DMART&#39;, 4, 1, &#39;Medium&#39;, &#39;large&#39;],
        [&#39;ARVIND&#39;, 2, 10, &#39;Medium&#39;, &#39;small&#39;],
        [&#39;TCI&#39;, 1, 7, &#39;High&#39;, &#39;mid&#39;],
        [&#39;MIDHANI&#39;, 5, 5, &#39;Low&#39;, &#39;large&#39;],
        [&#39;RITES&#39;, 6, 4, &#39;Medium&#39;, &#39;mid&#39;],
        [&#39;COROMANDEL&#39;, 9, 9, &#39;High&#39;, &#39;small&#39;],
        [&#39;SBIN&#39;, 10, 3, &#39;Medium&#39;, &#39;large&#39;]]
mx = pd.DataFrame(data=data, columns=[&quot;code&quot;, &quot;Growth&quot;, &quot;Value&quot;, &quot;Risk&quot;, &quot;Mcap&quot;])
plotnum = {&#39;small&#39;: 0, &#39;mid&#39;: 1, &#39;large&#39;: 2}
p1 = sns.relplot(x=&quot;Growth&quot;, y=&quot;Value&quot;, hue=&quot;Risk&quot;, col=&quot;Mcap&quot;, data=mx, s=200, palette=[&#39;r&#39;, &#39;g&#39;, &#39;y&#39;])

for ax in p1.axes[0]:
    ax.set_xlim(0.0, max(mx[&quot;Growth&quot;]) + 1.9)
for row in mx.itertuples():
    print(row)
    ax = p1.axes[0, plotnum[row.Mcap]]
    ax.text(row.Growth + 0.5, row.Value, row.code, horizontalalignment=&#39;left&#39;)
plt.show()</code></pre>
</div>
<div id="grid-axes" class="section level4">
<h4>Grid axes</h4>
<p>Use scientific notation on the axes of a <code>g</code> FacetGrid
object:</p>
<pre><code>for axes in g.axes.flat:
    axes.ticklabel_format(axis=&#39;both&#39;, style=&#39;scientific&#39;, scilimits=(0, 0))</code></pre>
<p>Do not use scientific notation on the axes</p>
<pre><code>plt.ticklabel_format(style=&#39;plain&#39;, axis=&#39;y&#39;)</code></pre>
<p>Use the scientific notation on the y axis labels, at every tick.
Without putting a <code>1e7</code> at the top that might be overwritten
by a facet label.</p>
<pre class="python"><code>g = seaborn.relplot(
    data=rp_global.reset_index(), x=&quot;step&quot;, y=&quot;primary_eq&quot;, col=&quot;primary_product&quot;,
    hue=&quot;year&quot;, kind=&quot;line&quot;,
    col_wrap=3, height=3,
    facet_kws={&#39;sharey&#39;: False, &#39;sharex&#39;: False}
)

def y_fmt(x, pos):
    &quot;&quot;&quot;function to format the y axis&quot;&quot;&quot;
    return f&quot;{x:.0e}&quot;


from matplotlib.ticker import FuncFormatter
#g.set(yticklabels=[])
for ax in g.axes.flat:
    ax.yaxis.set_major_formatter(FuncFormatter(y_fmt))</code></pre>
</div>
</div>
<div id="figure-size-1" class="section level3">
<h3>Figure size</h3>
<p>Resize a scatter plot</p>
<pre><code>p = seaborn.scatterplot(&#39;petal_length&#39;,&#39;petal_width&#39;,&#39;species&#39;,data=iris)
p.figure.set_figwidth(15)</code></pre>
<div id="larger-grid-plots" class="section level4">
<h4>Larger grid plots</h4>
<p><code>set_figwidth</code> and <code>set_figheight</code> work well to
resize a grid object in its entirety.</p>
<pre><code>g = seaborn.FacetGrid(tips, col=&quot;time&quot;, row=&quot;smoker&quot;)
g = g.map(plt.hist, &quot;total_bill&quot;)
g.fig.set_figwidth(10)
g.fig.set_figheight(10) </code></pre>
<p>Try also</p>
<pre><code>g.fig.set_size_inches(15,15)</code></pre>
<p>Mentioned as a comment under <a
href="https://stackoverflow.com/a/56970556/2641825">this answer</a></p>
<p>To change the height and aspect ration of individual grid cells, you
can use the <code>height</code> and <code>aspect</code> arguments of the
FacetGrid call as such:</p>
<pre><code>import seaborn 
import matplotlib.pyplot as plt
seaborn.set()
iris = seaborn.load_dataset(&quot;iris&quot;)
# Change height and aspect ratio
g = seaborn.FacetGrid(iris, col=&quot;species&quot;, height=8, aspect=0.3)
iris[&#39;species&#39;] = iris[&#39;species&#39;].astype(&#39;category&#39;)
g.map(seaborn.scatterplot,&#39;petal_length&#39;,&#39;petal_width&#39;,&#39;species&#39;)
plt.show()</code></pre>
<p><code>help(seaborn.FacetGrid)</code></p>
<blockquote>
<p><code>aspect * height</code> gives the width of each facet in
inches.</p>
</blockquote>
</div>
</div>
<div id="legend" class="section level3">
<h3>Legend</h3>
<p>Move a legend below a grid plot</p>
<pre><code>g.fig.subplots_adjust(left=0.28, top=0.9) # resize the plot
g.legend.set_bbox_to_anchor((0.5, 0.15))</code></pre>
<p>Another way to move the legend and make it flat</p>
<pre><code>seaborn.move_legend(g, &quot;upper center&quot;, bbox_to_anchor=(0.5, 0.1), ncol=4)</code></pre>
</div>
<div id="line-plot" class="section level3">
<h3>Line plot</h3>
<p>Create a line plot with a title and axis labels.</p>
<pre class="python"><code>import numpy as np
df = pandas.DataFrame({&#39;value&#39;:np.random.random(100), 
                       &#39;year&#39;:range(1901,2001)})
p = seaborn.lineplot(x=&quot;year&quot;, y=&quot;value&quot;, data=df)
p.set(ylabel = &quot;Random variation&quot;, title = &quot;Title here&quot;)
plt.show()</code></pre>
<div id="line-styles" class="section level4">
<h4>Line styles</h4>
<p>Example generated by <a
href="https://arxiv.org/abs/2303.08774">GPT4</a> with a series of prompt
related to a time series plot I was refining.</p>
<pre><code>import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.lines import Line2D

# Set a random seed for reproducibility
np.random.seed(42)

# Create a synthetic dataset with a random walk
years = np.arange(2000, 2031)
categories = [&#39;x&#39;, &#39;y&#39;]
data = []

for category in categories:
    random_walk = np.random.randn(len(years)).cumsum()
    data.extend(zip(years, [category] * len(years), random_walk))

df = pd.DataFrame(data, columns=[&#39;year&#39;, &#39;category&#39;, &#39;value&#39;])

# Create a custom linestyle and color dictionary for each category (x, y)
style_dict = {&#39;x&#39;: (&#39;-&#39;, &#39;black&#39;), &#39;y&#39;: (&#39;--&#39;, &#39;black&#39;)}

# Plot the lineplot
ax = sns.lineplot(
    x=&quot;year&quot;,
    y=&quot;value&quot;,
    hue=&quot;category&quot;,
    style=&quot;category&quot;,
    data=df
)

# Apply custom linestyle and color for each category (x, y)
for line, category in zip(ax.lines, df[&quot;category&quot;].unique()):
    linestyle, color = style_dict[category]
    line.set_linestyle(linestyle)
    line.set_color(color)

# Set the ylabel and title
ax.set(ylabel=&quot;Value&quot;, title=&quot;Random Walk by Category&quot;)

# Modify the legend colors to black
legend = ax.legend()
for handle in legend.legendHandles:
    handle.set_color(&#39;black&#39;)

plt.show()</code></pre>
</div>
</div>
<div id="marker-and-text" class="section level3">
<h3>Marker and text</h3>
<p>Add a market and text to a plot, works both with simple plots and
faceted plots.</p>
<pre><code>plt.plot(2030, -420, marker=&#39;*&#39;, markersize=10, color=&#39;red&#39;)
plt.text(2030+1, -420, &quot;Target -420&quot;, fontsize=10)</code></pre>
</div>
<div id="pair-plot" class="section level3">
<h3>Pair plot</h3>
<p><a
href="https://seaborn.pydata.org/generated/seaborn.pairplot.html#">seaborn.pairplot</a></p>
<blockquote>
<p>“Plot pairwise relationships in a dataset.”</p>
</blockquote>
</div>
<div id="scatter-plot" class="section level3">
<h3>Scatter Plot</h3>
<p>Create a scatter plot</p>
<pre><code>import seaborn
import matplotlib.pyplot as plt
tips = seaborn.load_dataset(&quot;tips&quot;)
seaborn.scatterplot(x=&quot;total_bill&quot;, y=&quot;tip&quot;, data=tips)
plt.show()</code></pre>
<p>Group by another variable and show the groups with different
colors:</p>
<pre><code>seaborn(x=&quot;total_bill&quot;, y=&quot;tip&quot;, hue=&quot;time&quot;, data=tips)</code></pre>
</div>
<div id="scatter-plot-1" class="section level3">
<h3>Scatter plot</h3>
<p>Create a scatter plot with a title and axis labels</p>
<pre><code>p = seaborn.scatterplot(&#39;petal_length&#39;,&#39;petal_width&#39;,&#39;species&#39;,data=iris)
p.set(xlabel = &quot;Petal Length&quot;, ylabel = &quot;Petal Width&quot;, title = &quot;Flower sizes&quot;)
plt.show()</code></pre>
</div>
<div id="sample-data" class="section level3">
<h3>Sample data</h3>
<p>Show all Seaborn sample datasets</p>
<pre><code>for dataset in seaborn.get_dataset_names():
    print(dataset)
    print(seaborn.load_dataset(dataset).head())</code></pre>
</div>
</div>
<div id="squarify-treemaps" class="section level2">
<h2>Squarify treemaps</h2>
<p>Plot a <a href="https://www.python-graph-gallery.com/treemap/">tree
map from the python graph gallery</a></p>
<pre><code>import matplotlib.pyplot as plt
import squarify    # pip install squarify (algorithm for treemap)
import pandas
df = pandas.DataFrame({&#39;nb_people&#39;:[8,3,4,2], &#39;group&#39;:[&quot;group A&quot;, &quot;group B&quot;, &quot;group C&quot;, &quot;group D&quot;] })
squarify.plot(sizes=df[&#39;nb_people&#39;], label=df[&#39;group&#39;], alpha=.8 )
plt.axis(&#39;off&#39;)
plt.show()</code></pre>
</div>
<div id="vega-altair" class="section level2">
<h2>Vega Altair</h2>
<ul>
<li><p>Altair <a href="https://altair-viz.github.io/"
class="uri">https://altair-viz.github.io/</a></p>
<blockquote>
<p>“Vega-Altair is a declarative visualization library for Python. Its
simple, friendly and consistent API, built on top of the powerful
Vega-Lite grammar, empowers you to spend less time writing code and more
time exploring your data.”</p>
</blockquote>
<ul>
<li>Seen in the <a
href="https://jjallaire.github.io/visualization-curriculum/"
class="uri">https://jjallaire.github.io/visualization-curriculum/</a></li>
</ul></li>
<li><p>Vega Lite</p>
<ul>
<li><p>Vega lite gallery <a
href="https://vega.github.io/vega-lite-v1/examples/"
class="uri">https://vega.github.io/vega-lite-v1/examples/</a></p></li>
<li><p>Vega lite documentation on <a
href="https://vega.github.io/vega-lite/docs/tooltip.html">tooltips</a></p>
<p>from vega import VegaLite import pandas df =
pandas.read_json(‘cars.json’) VegaLite({ “data”: {“url”:
“data/cars.json”}, “mark”: {“type”: “point”, “tooltip”: true},
“encoding”: { “x”: {“field”: “Horsepower”,“type”: “quantitative”}, “y”:
{“field”: “Miles_per_Gallon”,“type”: “quantitative”} } }, df)</p></li>
</ul></li>
<li><p>The tool tip feature is nice in an interactive notebook.</p>
<ul>
<li><p>Ipython vega for Jupyter notebooks <a
href="https://github.com/vega/ipyvega"
class="uri">https://github.com/vega/ipyvega</a></p></li>
<li><p>Vega gallery <a href="https://vega.github.io/vega/examples/"
class="uri">https://vega.github.io/vega/examples/</a></p></li>
</ul></li>
</ul>
</div>
</div>
<div id="print" class="section level1">
<h1>Print</h1>
<p><a href="https://stackoverflow.com/a/21786287/2641825">How to print
coloured text at the terminal?</a></p>
<blockquote>
<p>“Print a string that starts a color/style, then the string, and then
end the color/style change with ‘1b[0m’.”</p>
</blockquote>
<p>For example</p>
<pre><code>print(1000 * (&quot;\x1b[1;32;44m&quot; + &quot;Winter&quot; + &quot;\x1b[0m&quot; + &quot;, &quot; +
              &quot;\x1b[1;32;42m&quot; + &quot;Spring&quot; + &quot;\x1b[0m&quot; + &quot;, &quot; +
              &quot;\x1b[1;35;41m&quot; + &quot;Summer&quot; + &quot;\x1b[0m&quot; + &quot;, &quot; +
              &quot;\x1b[1;35;45m&quot; + &quot;Autumn&quot; + &quot;\x1b[0m&quot; + &quot;, &quot;))</code></pre>
</div>
<div id="profiling-and-measuring-time" class="section level1">
<h1>Profiling and measuring time</h1>
<div id="profiling" class="section level2">
<h2>Profiling</h2>
<p>Run a scrip with the profiler, from within ipython</p>
<pre><code>%run -i -p run_zz.py</code></pre>
<p>Memory profiling <a
href="https://stackoverflow.com/a/15682871/2641825"
class="uri">https://stackoverflow.com/a/15682871/2641825</a></p>
</div>
<div id="time-it" class="section level2">
<h2>Time it</h2>
<p><a
href="https://stackoverflow.com/questions/2866380/how-can-i-time-a-code-segment-for-testing-performance-with-pythons-timeit">How
can I time a code segment for testing performance with Pythons
timeit?</a></p>
<p>Time a function:</p>
<pre><code>import timeit
import time
def wait():
    time.sleep(1)
timeit.timeit(wait, number=3)</code></pre>
<blockquote>
<p>“If you are profiling your code and can use IPython, it has the magic
function <code>%timeit</code>. <code>%%timeit</code> operates on
cells.”</p>
</blockquote>
<pre><code>%timeit wait()</code></pre>
<p><a href="https://stackoverflow.com/a/15707125/2641825">Time a code
block</a>:</p>
<pre><code>import timeit
start_time = timeit.default_timer()
# code you want to evaluate
elapsed = timeit.default_timer() - start_time</code></pre>
</div>
</div>
<div id="r-and-python" class="section level1">
<h1>R and python</h1>
<p>See also the <a href="R.html">R page</a> for more details on R.</p>
<p>Reddit <a
href="https://old.reddit.com/r/datascience/comments/67p72w/python_vs_r/">python
vs R</a></p>
<blockquote>
<p>“R is for analysis. Python is for production. If you want to do
analysis only, use R. If you want to do production only, use Python. If
you want to do analysis then production, use Python for both. If you
aren’t planning to do production then it’s not worth doing, (unless
you’re an academic). Conclusion: Use python.”</p>
</blockquote>
<div id="history" class="section level2">
<h2>History</h2>
<p>The central objects in R are vectors, matrices and data frames, that
is why I mostly compare R to the python packages numpy and pandas. R was
created almost 20 years before numpy and more than 40 years before
pandas.</p>
<p><a
href="https://en.wikipedia.org/wiki/R_(programming_language)">R_(programming_language)</a></p>
<blockquote>
<p>“R is an implementation of the S programming language combined with
lexical scoping semantics, inspired by Scheme. S was created by John
Chambers in 1976 while at Bell Labs. A commercial version of S was
offered as S-PLUS starting in 1988.”</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/NumPy#History">NumPy
history</a></p>
<blockquote>
<p>“In 1995 the special interest group (SIG) matrix-sig was founded with
the aim of defining an array computing package; among its members was
Python designer and maintainer Guido van Rossum, who extended Python’s
syntax (in particular the indexing syntax) to make array computing
easier. […] An implementation of a matrix package was completed by Jim
Fulton, then generalized by Jim Hugunin and called Numeric. […] new
package called Numarray was written as a more flexible replacement for
Numeric. Like Numeric, it too is now deprecated. […] In early 2005,
NumPy developer Travis Oliphant wanted to unify the community around a
single array package and ported Numarray’s features to Numeric,
releasing the result as NumPy 1.0 in 2006.”</p>
</blockquote>
<p><a
href="https://en.wikipedia.org/wiki/Pandas_(software)#History">Pandas_(software)</a></p>
<blockquote>
<p>“Developer Wes McKinney started working on pandas in 2008 while at
AQR Capital Management out of the need for a high performance, flexible
tool to perform quantitative analysis on financial data. Before leaving
AQR he was able to convince management to allow him to open source the
library.”</p>
</blockquote>
<p><a
href="https://jrvcomputing.wordpress.com/2016/11/14/migrating-from-r-to-python/">Migrating
from R to python</a></p>
<blockquote>
<p>“Python is a full fledge programming language but it is missing
statistical and plotting libraries. Vectors are an after thought in
python most functionality can be reproduced using operator overloading,
but some functionality looks clumsy.”</p>
</blockquote>
</div>
<div id="numpy-and-r" class="section level2">
<h2>Numpy and R</h2>
<p>R session showing a division by zero returning an infinite value.</p>
<pre><code>&gt; 1/0
[1] Inf</code></pre>
<p>Python session showing a division by zero error for normal integer
division and the same operation on a numpy array returning an infinite
value with a warning.</p>
<pre><code>In [1]: 1/0
---------------------------------------------------------------------------
ZeroDivisionError                         Traceback (most recent call last)
&lt;ipython-input-1-9e1622b385b6&gt; in &lt;module&gt;
----&gt; 1 1/0

ZeroDivisionError: division by zero

In [2]: import numpy as np

In [3]: np.array([1]) / 0
/home/paul/.local/bin/ipython:1: RuntimeWarning: divide by zero encountered in true_divide
  #!/usr/bin/python3
Out[3]: array([inf])</code></pre>
</div>
<div id="pandas-comparison-with-r" class="section level2">
<h2>Pandas comparison with R</h2>
<p>R data frame to be used for examples:</p>
<pre><code>df = data.frame(x = 1:3, y = c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;), stringsAsFactors = FALSE)</code></pre>
<p>Pandas data frame to be used for examples:</p>
<pre><code>import pandas
df = pandas.DataFrame({&#39;x&#39; : [1,2,3], &#39;y&#39; : [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]})</code></pre>
<table>
<colgroup>
<col width="25%" />
<col width="27%" />
<col width="47%" />
</colgroup>
<thead>
<tr class="header">
<th>Base R</th>
<th>python or pandas</th>
<th>SO questions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>df[df$y %in% c('a','b'),]</code></td>
<td><code>df[df['y'].isin(['a','b'])]</code></td>
<td><a
href="https://stackoverflow.com/questions/12096252/use-a-list-of-values-to-select-rows-from-a-pandas-dataframe">list
of values to select a row</a></td>
</tr>
<tr class="even">
<td><code>dput(df)</code></td>
<td><code>df.to_dict(orient="list")</code></td>
<td><a
href="https://stackoverflow.com/questions/47450931/print-pandas-data-frame-for-reproducible-example-equivalent-to-dput-in-r">Print
pandas data frame for reproducible example</a></td>
</tr>
<tr class="odd">
<td><code>expand.grid(df$x,df$y)</code></td>
<td><code>itertools.product</code></td>
<td>see section below</td>
</tr>
<tr class="even">
<td><code>ifelse</code></td>
<td><code>df.where()</code></td>
<td>[ifelse in pandas]</td>
</tr>
<tr class="odd">
<td><code>gsub</code></td>
<td><code>df.x.replace(regex=True)</code></td>
<td><a
href="https://stackoverflow.com/questions/21834293/equivalent-of-gsub-for-pandas-series-dataframe/56547104?noredirect=1#comment99677847_56547104">gsub
in pandas</a></td>
</tr>
<tr class="even">
<td></td>
<td>or df.x.str.replace()</td>
<td></td>
</tr>
<tr class="odd">
<td><code>length(df)</code> and <code>dim(df)</code></td>
<td><code>df.shape</code></td>
<td><a
href="https://stackoverflow.com/questions/15943769/how-do-i-get-the-row-count-of-a-pandas-dataframe">row
count of a data frame</a></td>
</tr>
<tr class="even">
<td><code>rbind</code></td>
<td><code>pandas.concat</code></td>
<td><a
href="https://stackoverflow.com/questions/14988480/pandas-version-of-rbind">Pandas
version of rbind</a></td>
</tr>
<tr class="odd">
<td><code>rep(1,3)</code></td>
<td><code>[1]*3</code></td>
<td></td>
</tr>
<tr class="even">
<td><code>seq(1:5)</code></td>
<td><code>np.array(range(0,5))</code></td>
<td><a href="https://stackoverflow.com/a/60753578/2641825">numpy
function to generate sequences</a></td>
</tr>
<tr class="odd">
<td><code>summary</code></td>
<td><code>describe</code></td>
<td></td>
</tr>
<tr class="even">
<td><code>str</code></td>
<td><code>df.info()</code></td>
<td><a
href="https://stackoverflow.com/questions/27637281/what-are-python-pandas-equivalents-for-r-functions-like-str-summary-and-he">pandas
equivalents for R functions like str summary and head</a></td>
</tr>
</tbody>
</table>
<p><a
href="https://stackoverflow.com/questions/43391591/if-else-function-in-pandas-dataframe">ifelse
in pandas</a></p>
<p>The mapping of tidyverse to pandas is:</p>
<table>
<colgroup>
<col width="24%" />
<col width="47%" />
<col width="28%" />
</colgroup>
<thead>
<tr class="header">
<th>tidyverse</th>
<th>pandas</th>
<th>Help or SO questions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>arrange</td>
<td>df.sort_values(by=“y”, ascending=False)</td>
<td></td>
</tr>
<tr class="even">
<td>df %&gt;% select(-a,-b)</td>
<td>df.drop(columns=[‘x’, ‘y’])</td>
<td></td>
</tr>
<tr class="odd">
<td>select(a)</td>
<td>df.loc[:,“x”] # Strict, var has to be present</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>df.filter(items=[‘x’]) # Not strict</td>
<td></td>
</tr>
<tr class="odd">
<td>select(contains(“a”))</td>
<td>df.filter(regex=‘x’)</td>
<td></td>
</tr>
<tr class="even">
<td>filter</td>
<td>df.query(“y==‘b’”)</td>
<td></td>
</tr>
<tr class="odd">
<td>group_by</td>
<td>groupby</td>
<td></td>
</tr>
<tr class="even">
<td>lag</td>
<td><a
href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html">shift</a></td>
<td><a
href="https://stackoverflow.com/questions/23664877/pandas-equivalent-of-oracle-lead-lag-function">pandas
lag function</a></td>
</tr>
<tr class="odd">
<td>mutate</td>
<td>df.assign(e = lambda x: x[“a”] * 3)</td>
<td><a
href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html">assign</a></td>
</tr>
<tr class="even">
<td>pivot_longer</td>
<td><a
href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html">melt</a>
or <a
href="https://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html">wide_to_long</a></td>
<td></td>
</tr>
<tr class="odd">
<td>pivot_wider</td>
<td><a
href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html">pivot</a></td>
<td></td>
</tr>
<tr class="even">
<td>rename</td>
<td>df.rename(columns={‘a’:‘new’})</td>
<td></td>
</tr>
<tr class="odd">
<td>separate</td>
<td>df[[‘b’,‘c’]] = df.a.str.split(‘,’,1,expand=True)</td>
<td><a href="https://stackoverflow.com/a/57823566">pandas separate</a>
str section</td>
</tr>
<tr class="even">
<td>separate</td>
<td>df[[‘b’,‘c’]] = df.a.str.split(‘,’,expand=True)</td>
<td></td>
</tr>
<tr class="odd">
<td>summarize</td>
<td>agg</td>
<td></td>
</tr>
<tr class="even">
<td>unite</td>
<td>df[“z”] = df.y + df.y</td>
<td><a
href="https://stackoverflow.com/questions/19377969/combine-two-columns-of-text-in-pandas-dataframe">pandas
unite</a></td>
</tr>
<tr class="odd">
<td>unnest</td>
<td><a
href="https://pandas.pydata.org/pandas-docs/version/0.25/reference/api/pandas.DataFrame.explode.html">explode</a></td>
<td><a href="https://stackoverflow.com/a/53218939/2641825">unnest in
pandas</a></td>
</tr>
</tbody>
</table>
<p>Methods to use inside the .groupby().agg() method:</p>
<ul>
<li><code>sum</code></li>
<li><code>count</code></li>
<li><code>mean</code></li>
<li><code>', '.join</code> <a
href="https://stackoverflow.com/questions/17841149/pandas-groupby-how-to-get-a-union-of-strings">to
get a union of strings</a></li>
</ul>
<div id="expand-grid-in-pandas" class="section level3">
<h3>Expand grid in pandas</h3>
<p>This <a href="https://stackoverflow.com/a/60371544/2641825">SO
answer</a> provides an implementation of expand grid using
itertools:</p>
<pre><code>import itertools
import pandas
countries = [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;]
years = range(1990, 2020)
expand_grid = list(itertools.product(countries, years))
df = pandas.DataFrame(expand_grid, columns=(&#39;country&#39;, &#39;year&#39;))</code></pre>
<p>Another <a href="https://stackoverflow.com/a/64449660/2641825">SO
answer on the same topic</a></p>
</div>
<div id="blogs-and-quotes-on-pandas-and-r" class="section level3">
<h3>Blogs and quotes on Pandas and R</h3>
<ul>
<li><a
href="https://www.kdnuggets.com/2017/02/moving-r-python-libraries.html">Moving
from R to python</a></li>
</ul>
<blockquote>
<p>“One thing that is a blessing and a curse in R is that the machine
learning algorithms are generally segmented by package. […] it can be a
pain for day-to-day use where you might be switching between algorithms.
[…] scikit-learn provides a common set of ML algorithms all under the
same API.</p>
</blockquote>
<blockquote>
<p>“one thing that R still does better than Python is plotting. Hands
down, R is better in just about every facet. Even so, Python plotting
has matured though it’s a fractured community.”</p>
</blockquote>
<ul>
<li><p>pandas.pydata.org <a
href="https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html">Comparison
with R</a></p></li>
<li><p><a
href="https://stmorse.github.io/journal/tidyverse-style-pandas.html">Tydiverse
style pandas</a></p></li>
</ul>
<blockquote>
<p>“Tidyverse allows a mix of quoted and unquoted references to variable
names. In my (in)experience, the convenience this brings is accompanied
by equal consternation. It seems to me a lot of the problems solved by
tidyeval would not exist if all variables were quoted all the time, as
in pandas, but there are likely deeper truths I’m missing here…”</p>
</blockquote>
<p>Help of the R function unite from the tidyr package:</p>
<blockquote>
<p>“col: The name of the new column, as a string or symbol. This
argument is passed by expression and supports quasiquotation (you can
unquote strings and symbols). The name is captured from the expression
with ‘rlang::ensym()’ (note that <strong>this kind of interface where
symbols do not represent actual objects is now discouraged</strong> in
the tidyverse; we support it here for backward compatibility).”</p>
</blockquote>
<p>The use of symbols which do not represent actual objects was was
frustrating at first when using pandas, because we hat to use df[“x”] to
assign vectors to new column names whereas we could use df.x to display
them.</p>
</div>
</div>
<div id="xarray-pandas-and-r" class="section level2">
<h2>Xarray, pandas and R</h2>
<p>The <a
href="https://docs.xarray.dev/en/stable/user-guide/pandas.html">xarray
user guide page on pandas</a> cites Hadley Whickham’s paper on tidy
data:</p>
<blockquote>
<p>“Tabular data is easiest to work with when it meets the criteria for
tidy data”.</p>
</blockquote>
</div>
<div id="personal-reflection" class="section level2">
<h2>Personal reflection</h2>
<p>R is great for statistical analysis and plotting. You can also use it
to elaborate a pipeline to load data, prepare it and analyse it. But
when things start to get complicated, such as loading json data from
APIs, or dealing with http requests issues, or understanding lazy
evaluation, or the consequences of non standard evaluation, moving down
the rabbit whole can get really complicated with R. The rabbit hole
slide is smoother with python. I have the feeling that I keep a certain
level of understanding at all steps. It’s just a matter of taste
anyway.</p>
<p>The Python language can be more verbose on some aspects, but it
allows for greater programmability, it is also more predictable because
non standard evaluation doesn’t create scoping problems and it enables
to dive deeper into input/output issues such as URL request headers for
example. R remains very good for data exploration, statistical analysis
and plotting because non standard evaluation makes it possible to call
variables without quotes and to pass formulas to plotting and estimation
functions.</p>
<p>I see R more like the bash command line. It’s great for scripts, but
you wouldn’t want to write large applications in bash.</p>
<p>Non standard evaluation doesn’t exist in python. - An email thread
discussing <a
href="https://www.mail-archive.com/python-ideas@python.org/msg15694.html">the
idea of non standard evaluation in python</a>. - A <a
href="https://third-bit.com/2018/11/16/non-standard-evaluation/">comparison
of a python implementation and an R implementation using non standard
evaluation</a>.</p>
</div>
</div>
<div id="security" class="section level1">
<h1>Security</h1>
<ul>
<li><p><a
href="https://pytorch.org/blog/compromised-nightly-dependency/">Compromised
PyTorch-nightly dependency chain between December 25th and December
30th, 2022.</a></p>
<blockquote>
<p>“PyTorch-nightly Linux packages installed via pip during that time
installed a dependency, torchtriton, which was compromised on the Python
Package Index (PyPI) code repository and ran a malicious binary. This is
what is known as a supply chain attack and directly affects dependencies
for packages that are hosted on public package indices.”</p>
</blockquote></li>
<li><p>Anaconda was not affected <a
href="https://www.anaconda.com/blog/anaconda-unaffected-by-pytorch-security-incident"
class="uri">https://www.anaconda.com/blog/anaconda-unaffected-by-pytorch-security-incident</a> </p>
<blockquote>
<p>“Conda users installing packages from Anaconda’s “main” channel are
not impacted. This is because Anaconda’s official channels (the
location where all our packages are stored) only contain packages built
from stable upstream releases, while the affected PyTorch releases
were nightly, development builds.</p>
</blockquote>
<blockquote>
<p>“Update: we have confirmed with the conda-forge maintainers thattheir
PyTorch packages are also built from stable upstream releases andare
similarly not impacted.”</p>
</blockquote></li>
</ul>
</div>
<div id="string" class="section level1">
<h1>String</h1>
<p>See also string operations in pandas character vectors.</p>
<p><a
href="https://stackoverflow.com/questions/25675943/how-can-i-concatenate-str-and-int-objects">SO
answer</a> providing various ways to concatenate python strings.</p>
<div id="f-string" class="section level2">
<h2>F string</h2>
<div id="number-formatting-in-f-strings" class="section level3">
<h3>Number formatting in f strings</h3>
<p><a href="https://stackoverflow.com/a/10742904/2641825">How to print
number with commas as thousands separators?</a></p>
<p>Thousand mark</p>
<pre><code>f&quot;{1e6:,}&quot;</code></pre>
<p>Round to 2 decimal places</p>
<pre><code>f&quot;{0.129456789:.2f}&quot;</code></pre>
<p>See also string operations in pandas with df[“x”].str methods.</p>
</div>
</div>
<div id="regex-substitution" class="section level2">
<h2>Regex substitution</h2>
<p><a href="https://docs.python.org/3/library/re.html">Documentation of
the re package</a>.</p>
<p>Replace one or another character by a space</p>
<pre><code>import re
re.sub(&quot;l|k&quot;, &quot; &quot;, &quot;mlkj&quot;)</code></pre>
<p>Replace one or more consecutive non alphanumeric characters by an
underscore.</p>
<pre><code>re.sub(r&#39;\W+&#39;, &#39;_&#39;, &#39;bla: bla**(bla)&#39;)</code></pre>
<p>Insert a suffix in a file name before the extension <a
href="https://stackoverflow.com/a/2763772/2641825">SO anwser</a></p>
<pre><code>import re
re.sub(r&#39;(?:_a)?(\.[^\.]*)$&#39; , r&#39;_suff\1&#39;,&quot;long.file.name.jpg&quot;)</code></pre>
</div>
<div id="regex-search-regular-expressions" class="section level2">
<h2>Regex search Regular Expressions</h2>
<p>Search for patterns</p>
<pre><code>import re
re.findall(r&#39;\bf[a-z]*&#39;, &#39;which foot or hand fell fastest&#39;)
[&#39;foot&#39;, &#39;fell&#39;, &#39;fastest&#39;]

re.findall(r&#39;(\w+)=(\d+)&#39;, &#39;set width=20 and height=10&#39;)
[(&#39;width&#39;, &#39;20&#39;), (&#39;height&#39;, &#39;10&#39;)]</code></pre>
<p>Search for ab in baba:</p>
<pre><code>re.search(&quot;ab&quot;, &quot;baba&quot;)</code></pre>
<p>Search for the numeric after “value_”</p>
<pre><code>re.findall(&quot;value_(\d+)&quot;, &quot;value_2022&quot;)</code></pre>
<p>Search for the group values occurrence of the numeric after
“value_”</p>
<pre><code>re.search(&quot;(value)_(\d+)&quot;, &quot;value_2022&quot;).group(0)
re.search(&quot;(value)_(\d+)&quot;, &quot;value_2022&quot;).group(1)
re.search(&quot;(value)_(\d+)&quot;, &quot;value_2022&quot;).group(2)</code></pre>
<p>Search charcters that are not value</p>
<pre><code>l = [&quot;value123&quot;, &quot;a&quot;, &quot;b&quot;]
[x for x in l if not re.search(&quot;value&quot;, x)]</code></pre>
</div>
<div id="join" class="section level2">
<h2>Join</h2>
<p>Join strings from a list to print them nicely</p>
<pre><code>l = [&quot;cons&quot;, &quot;imp&quot;, &quot;exp&quot;, &quot;prod&quot;]
print(l)
print(&quot;, &quot;.join(l))</code></pre>
</div>
<div id="split" class="section level2">
<h2>Split</h2>
<p><a href="https://stackoverflow.com/a/172454/2641825">Split lines in a
string</a></p>
<pre><code>input = &quot;&quot;&quot;bla
bla
bla&quot;&quot;&quot;
for line in input.splitlines():
    print(line, &quot;\n&quot;)</code></pre>
</div>
</div>
<div id="statistics" class="section level1">
<h1>Statistics</h1>
<div id="linear-programming-solvers" class="section level2">
<h2>Linear programming solvers</h2>
<p>Real Python <a
href="https://realpython.com/linear-programming-python/#what-is-linear-programming">What
is linear programing</a></p>
<blockquote>
<p>Several free Python libraries are specialized to interact with linear
or mixed-integer linear programming solvers:</p>
</blockquote>
<p><a
href="https://docs.scipy.org/doc/scipy/reference/optimize.html">SciPy
Optimization and Root Finding</a></p>
<p><a href="https://www.coin-or.org/PuLP/solvers.html">PuLP</a></p>
<p><a
href="https://pyomo.readthedocs.io/en/stable/solving_pyomo_models.html#supported-solvers">Pyomo</a></p>
<p><a
href="https://cvxopt.org/userguide/coneprog.html#optional-solvers">CVXOPT</a></p>
</div>
<div id="scaling" class="section level2">
<h2>Scaling</h2>
<p><a
href="http://benalexkeen.com/feature-scaling-with-scikit-learn/">Feature
scaling with scikit learn</a></p>
<ul>
<li>StandardScaler</li>
<li>MinMaxScaler</li>
<li>RobustScaler</li>
<li>Normalizer</li>
</ul>
</div>
</div>
<div id="style-and-linter" class="section level1">
<h1>Style and linter</h1>
<div id="aa-code-style" class="section level2">
<h2>AA Code style</h2>
<ul>
<li><p><a href="https://docs.python.org/3/glossary.html#term-EAFP">EAFP
Easier to ask for forgiveness than permission</a></p>
<blockquote>
<p>“This common Python coding style assumes the existence of valid keys
or attributes and catches exceptions if the assumption proves false.
This clean and fast style is characterized by the presence of many try
and except statements. The technique contrasts with the LBYL style
common to many other languages such as C.</p>
</blockquote></li>
<li><p><a href="https://docs.python.org/3/glossary.html#term-LBYL">LBYL
Look before you leap</a></p>
<blockquote>
<p>“This coding style explicitly tests for pre-conditions before making
calls or lookups. This style contrasts with the EAFP approach and is
characterized by the presence of many if statements. In a multi-threaded
environment, the LBYL approach can risk introducing a race condition
between “the looking” and “the leaping”. For example, the code, if key
in mapping: return mapping[key] can fail if another thread removes key
from mapping after the test, but before the lookup. This issue can be
solved with locks or by using the EAFP approach.</p>
</blockquote></li>
</ul>
</div>
<div id="black" class="section level2">
<h2>Black</h2>
<p><a href="https://github.com/psf/black">Black</a> is “the
uncompromising Python code formater”</p>
<p>See the pre commit section below to install and run
<code>black</code> as a pre commit hook with
<code>pre-commit</code>.</p>
<p>In vim, you can run black on the current file with:</p>
<pre><code>:!black %</code></pre>
<ul>
<li><p><a
href="https://black.readthedocs.io/en/stable/guides/introducing_black_to_your_project.html">Ignore
a revision in git blame after moving to black</a></p>
<blockquote>
<p>“A long-standing argument against moving to automated code formatters
like Black is that the migration will clutter up the output of git
blame. This was a valid argument, but since Git version 2.23, Git
natively supports ignoring revisions in blame with the –ignore-rev
option.”</p>
</blockquote>
<blockquote>
<p>“You can even configure git to automatically ignore revisions listed
in a file on every call to git blame.”</p>
</blockquote>
<pre><code>  git config blame.ignoreRevsFile .git-blame-ignore-revs</code></pre></li>
</ul>
</div>
<div id="flake-8" class="section level2">
<h2>Flake 8</h2>
<p>Flake 8 looks at more than just formatting.</p>
<p><a
href="https://pypi.org/project/flake8/1.6.1/#warning-error-codes">List
of FLake8 warnings and error codes</a></p>
</div>
<div id="pep-python-enhancement-proposals" class="section level2">
<h2>PEP Python Enhancement Proposals</h2>
<p><a
href="https://legacy.python.org/dev/peps/pep-0008/#version-bookkeeping">PEP
8 Style Guide for Python Code</a></p>
<blockquote>
<p>“A style guide is about consistency. Consistency with this style
guide is important. Consistency within a project is more important.
Consistency within one module or function is the most important.”</p>
</blockquote>
<blockquote>
<p>“However, <strong>know when to be inconsistent</strong> – sometimes
style guide recommendations just aren’t applicable. When in doubt, use
your best judgment. Look at other examples and decide what looks best.
And don’t hesitate to ask!”</p>
</blockquote>
<blockquote>
<p>“In particular: do not break backwards compatibility just to comply
with this PEP!”</p>
</blockquote>
</div>
<div id="pre-commit-hooks" class="section level2">
<h2>Pre commit hooks</h2>
<p>Blog:</p>
<ul>
<li><a
href="https://ljvmiranda921.github.io/notebook/2018/06/21/precommits-using-black-and-flake8/">pre
commits using black and flake8</a></li>
</ul>
<div id="install-pre-commit-hooks" class="section level3">
<h3>Install pre commit hooks</h3>
<p>Install <code>pre-commit</code></p>
<pre><code>pip install pre-commit</code></pre>
<p>Set up <code>pre-commit</code> in a repository</p>
<pre><code>cd path_to_repository
# Add the &quot;pre-commit&quot; python module to a requirements file
vim requirements.txt 
# Create a configuration file
vim .pre-commit-config.yaml </code></pre>
<p>Configuration options such as</p>
<pre><code>repos:
-   repo: https://github.com/ambv/black
    rev: 21.6b0
    hooks:
    - id: black
      language_version: python3.7
-   repo: https://gitlab.com/pycqa/flake8
    rev: 3.7.9
    hooks:
    - id: flake8</code></pre>
<p>Update <a
href="https://pre-commit.com/#using-the-latest-version-for-a-repository">hook
repositories to the latest version</a></p>
<pre><code>pre-commit autoupdate</code></pre>
<p>Install git hooks in your .git/ directory.</p>
<pre><code>pre-commit install</code></pre>
</div>
<div id="temporarily-deactivate-a-pre-commit-hook"
class="section level3">
<h3>Temporarily deactivate a pre commit hook</h3>
<p>To deactivate a pre commit hook temporarily <a
href="https://stackoverflow.com/questions/7230820/skip-git-commit-hooks"
class="uri">https://stackoverflow.com/questions/7230820/skip-git-commit-hooks</a></p>
<pre><code>git commit --no-verify -m &quot;commit message&quot;</code></pre>
</div>
<div id="usage-in-continuous-integration" class="section level3">
<h3>Usage in Continuous integration</h3>
<p><a
href="https://pre-commit.com/#usage-in-continuous-integration">Usage in
Continuous integration</a> has a gitlab example:</p>
<pre class="python"><code>    my_job:
      variables:
        PRE_COMMIT_HOME: ${CI_PROJECT_DIR}/.cache/pre-commit
      cache:
        paths:
          - ${PRE_COMMIT_HOME}</code></pre>
</div>
<div id="un-install-pre-commit-hooks" class="section level3">
<h3>Un install pre-commit hooks</h3>
<p>Uninstall</p>
<pre><code>pre-commit uninstall</code></pre>
</div>
</div>
<div id="pylint" class="section level2">
<h2>Pylint</h2>
<p>Edit the configuration file</p>
<pre><code>vim ~/.pylintrc</code></pre>
<p>You can also make a project specific configuration file at the root
of a git repository.</p>
<p>List of good names that shouldn’t give a “short name” warning</p>
<pre><code>[pylint]
good-names=df</code></pre>
<p>Generate a configuration file</p>
<pre><code>pylint --generate-rcfile</code></pre>
<p>Blog</p>
<ul>
<li>Reddit <a
href="https://www.reddit.com/r/Python/comments/82hgzm/any_advantages_of_flake8_over_pylint/">Any
advantages of Flake8 over PyLint</a> some answers suggest keeping
both.</li>
</ul>
<div id="class-with-dynamic-attributes" class="section level3">
<h3>Class with dynamic attributes</h3>
<p>E1101: ‘Instance of .. has no .. member’ for class with dynamic
attributes</p>
<p>To ignore this error, I entered this in a .pylintrc file at the root
of the project’s git repository</p>
<pre><code>[TYPECHECK]
generated-members=other,indround,fuel,sawn,panel,pulp,paper</code></pre>
</div>
<div id="ignore-unused-import-warning" class="section level3">
<h3>Ignore unused import warning</h3>
<p>Use case:</p>
<pre><code>  # Make agg_trade_eu_row available here for backward compatibility
  # so that the following import statement continues to work:
  # &gt;&gt;&gt; from biotrade.faostat.aggregate import agg_trade_eu_row
  from biotrade.common.aggregate import agg_trade_eu_row # noqa # pylint: disable=unused-import</code></pre>
<p><a href="https://stackoverflow.com/a/36741413/2641825">SO
answer</a></p>
<pre><code>import &lt;module&gt; # noqa # pylint: disable=unused-import</code></pre>
</div>
<div id="dangerous-default-argument" class="section level3">
<h3>Dangerous default argument</h3>
<ul>
<li>[SO answer][<a
href="https://stackoverflow.com/questions/101268/hidden-features-of-python#113198"
class="uri">https://stackoverflow.com/questions/101268/hidden-features-of-python#113198</a>)</li>
<li><a href="https://github.com/PyCQA/pylint/issues/3642">pylint
issues</a></li>
</ul>
<blockquote>
<p>I understand the dangerous of using a mutable default value and I
suggest switching the warning message for something like “Dangerous
mutable default value as argument”. However, this is dangerous for all
sorts of scenarios? (I know that pylint isn’t supposed to check the
functionality of my code, just trying to clarify this anti-pattern)</p>
</blockquote>
<pre><code>&gt;&gt;&gt; def find(_filter={&#39;_id&#39;: 0}):
...     print({**find.__defaults__[0], **_filter})
...
&gt;&gt;&gt; find()
{&#39;_id&#39;: 0}
&gt;&gt;&gt; find({&#39;a&#39;: 1})
{&#39;_id&#39;: 0, &#39;a&#39;: 1}
&gt;&gt;&gt; find()
{&#39;_id&#39;: 0}
&gt;&gt;&gt; find({&#39;a&#39;: 1, &#39;b&#39;: 2})
{&#39;_id&#39;: 0, &#39;a&#39;: 1, &#39;b&#39;: 2}</code></pre>
<blockquote>
<p>One might argue that the following should be used and I tend to
agree:</p>
</blockquote>
<pre><code>&gt;&gt;&gt; def find(_filter=None):
...     if _filter is None:
...             _filter = {&#39;_id&#39;: 0}
...     else:
...             _filter[&#39;_id&#39;] = 0
...     print(_filter)
...
&gt;&gt;&gt; find()
{&#39;_id&#39;: 0}
&gt;&gt;&gt; find({&#39;a&#39;: 1})
{&#39;a&#39;: 1, &#39;_id&#39;: 0}
&gt;&gt;&gt; find()
{&#39;_id&#39;: 0}
&gt;&gt;&gt; find({&#39;a&#39;: 1, &#39;b&#39;: 2})
{&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;_id&#39;: 0}</code></pre>
</div>
<div id="using-with-for-resource-allocation" class="section level3">
<h3>Using with for resource allocation</h3>
<p>Pylint message</p>
<blockquote>
<p>Consider using ‘with’ for resource-allocating operations</p>
</blockquote>
<p>Explained in a <a
href="https://stackoverflow.com/a/67419279/2641825">SO answer</a></p>
<blockquote>
<p>suppose you are opening a file:</p>
</blockquote>
<pre><code>file_handle = open(&quot;some_file.txt&quot;, &quot;r&quot;)
...
...
file_handle.close()</code></pre>
<blockquote>
<p>You need to close that file manually after required task is done. If
it’s not closed, then resource (memory/buffer in this case) is wasted.
If you use <code>with</code> in the above example:</p>
</blockquote>
<pre><code>with open(&quot;some_file.txt&quot;, &quot;r&quot;) as file_handle:
    ...
    ...</code></pre>
<blockquote>
<p>there is no need to close that file. Resource de-allocation
automatically happens when you use with.</p>
</blockquote>
</div>
</div>
</div>
<div id="system-information" class="section level1">
<h1>System information</h1>
<p>Platform type</p>
<pre><code>import sys
sys.platform</code></pre>
<p>or</p>
<pre><code>import os
os.name</code></pre>
<p>Sys and os return different results ‘linux’ or ‘posix’.</p>
<p>More details are given by</p>
<pre><code>os.uname()</code></pre>
<div id="environment-variables" class="section level2">
<h2>Environment variables</h2>
<div id="get-or-set" class="section level3">
<h3>Get or set</h3>
<p>Get an environment variable</p>
<pre><code>import os
os.environ[&quot;XYZ&quot;]</code></pre>
<p>Set an environment variable</p>
<pre><code>os.environ[&quot;XYZ&quot;]  = &quot;/tmp&quot;</code></pre>
</div>
<div id="python-path-1" class="section level3">
<h3>Python path</h3>
<p>For example in bash, the python path can be updated as follows:</p>
<pre><code>export PYTHONPATH=&quot;$HOME/repos/biotrade/&quot;:$PYTHONPATH</code></pre>
<p>This tells python where the biotrade package is located.</p>
<p>From python, use <code>sys.path</code> to prepend to the python
path.</p>
<pre><code>import sys
sys.path.insert(0, &quot;/home/rougipa/eu_cbm/eu_cbm_hat&quot;)</code></pre>
<p>See also the section on Path/python path to change the python path
and import a script from Jupyter notebook.</p>
</div>
</div>
<div id="gil-global-interpreter-lock" class="section level2">
<h2>GIL Global Interpreter Lock</h2>
<ul>
<li><p><a
href="https://docs.python.org/3/glossary.html#term-global-interpreter-lock"
class="uri">https://docs.python.org/3/glossary.html#term-global-interpreter-lock</a></p>
<blockquote>
<p>“The mechanism used by the CPython interpreter to assure that only
one thread executes Python bytecode at a time. This simplifies the
CPython implementation by making the object model (including critical
built-in types such as dict) implicitly safe against concurrent access.
Locking the entire interpreter makes it easier for the interpreter to be
multi-threaded, at the expense of much of the parallelism afforded by
multi-processor machines.</p>
</blockquote>
<blockquote>
<p>However, some extension modules, either standard or third-party, are
designed so as to release the GIL when doing computationally intensive
tasks such as compression or hashing. Also, the GIL is always released
when doing I/O.”</p>
</blockquote></li>
<li><p><a
href="https://numba.pydata.org/numba-doc/latest/user/jit.html#nogil"
class="uri">https://numba.pydata.org/numba-doc/latest/user/jit.html#nogil</a></p>
<blockquote>
<p>“Whenever Numba optimizes Python code to native code that only works
on native types and variables (rather than Python objects), it is not
necessary anymore to hold Python’s global interpreter lock (GIL). Numba
will release the GIL when entering such a compiled function if you
passed nogil=True.”</p>
</blockquote></li>
</ul>
</div>
<div id="memory" class="section level2">
<h2>Memory</h2>
<div id="memory-usage-of-a-python-object" class="section level3">
<h3>Memory usage of a python object</h3>
<p>To display the memory usage of a python object</p>
<pre><code>import sys
a = 1
print(sys.getsizeof(a))</code></pre>
<p>See also the section on memory usage of pandas data frames under
columns / memory usage.</p>
</div>
<div id="out-of-memory-error" class="section level3">
<h3>Out of memory error</h3>
<p>Sometimes when a python process runs out of memory, it can get killed
by the Linux Kernel. In that case the error message is short “killed”
and there is no python trace back printed. You can check that it is
indeed a memory error by calling</p>
<pre><code>sudo dmesg</code></pre>
<p>Here is a typical message:</p>
<pre><code>[85962.510533] Out of memory: Kill process 16035 (ipython3) score 320 or sacrifice child
[85962.510554] Killed process 16035 (ipython3) total-vm:7081812kB, anon-rss:4536336kB, file-rss:0kB, shmem-rss:8kB
[85962.687468] oom_reaper: reaped process 16035 (ipython3), now anon-rss:0kB, file-rss:0kB, shmem-rss:8kB</code></pre>
<p>Various related Stack Overflow questions <a
href="https://stackoverflow.com/questions/19189522/what-does-killed-mean-when-a-processing-of-a-huge-csv-with-python-which-sudde">what
does “kill” mean</a>, <a
href="https://stackoverflow.com/questions/47408608/how-can-i-find-the-reason-that-python-script-is-killed">How
can I find the reason that python script is killed?</a>, <a
href="https://stackoverflow.com/questions/1811173/why-does-my-python-script-randomly-get-killed">Why
does python script randomly gets killed?</a>.</p>
</div>
</div>
<div id="python-version" class="section level2">
<h2>Python version</h2>
<p>See also the status of python versions:</p>
<ul>
<li><a href="https://devguide.python.org/versions/"
class="uri">https://devguide.python.org/versions/</a></li>
</ul>
</div>
<div id="where-are-python-module-stored" class="section level2">
<h2>Where are python module stored</h2>
<p>Show the location of an imported module:</p>
<pre><code>import module_name
print(module_name.__file__)</code></pre>
<p>For example on a system you might have built-in modules stored in one
directory, user installed modules in another place and development
modules yet in another place:</p>
<pre><code>import os
os.__file__
# &#39;/usr/lib/python3.9/os.py&#39;

import pandas
pandas.__file__
# &#39;/home/paul/.local/lib/python3.9/site-packages/pandas/__init__.py&#39;

import biotrade
biotrade.__file__
# &#39;/home/paul/repos/forobs/biotrade/biotrade/__init__.py&#39;</code></pre>
<p>Show all modules installed in a system:</p>
<pre><code>help(&quot;modules&quot;)</code></pre>
</div>
</div>
<div id="test-driven-development" class="section level1">
<h1>Test driven development</h1>
<p>A good post about TDD <a
href="https://medium.com/@Cyrdup/unit-testing-youre-doing-it-wrong-407a07692989">Unit
testing your doing it wrong</a></p>
<blockquote>
<p>“TDD is actually about every form of tests. For example, I often
write performance tests as part of my TDD routine; end-to-end tests as
well. Furthermore, this is about behaviours, not implementation: you
write a new test when you need to fulfil a requirement. You do not write
a test when you need to code a new class or a new method. Subtle, but
important nuance. For example, you should not write a new test just
because you refactored the code. If you have to, it means you were not
really doing TDD.” […] “Good tests must test a behavior in isolation to
other tests. Calling them unit, system or integration has no relevance
to this. Kent Beck says this much better than I would ever do. ’‘’From
this perspective, the integration/unit test frontier is a frontier of
design, not of tools or frameworks or how long tests run or how many
lines of code we wrote get executed while running the test.’’’ Kent
Beck”</p>
</blockquote>
<div id="assertions" class="section level2">
<h2>Assertions</h2>
<ul>
<li><a href="https://blog.regehr.org/archives/1091">Use of
Assertions</a></li>
</ul>
</div>
<div id="unit-tests" class="section level2">
<h2>Unit tests</h2>
<p>See</p>
<ul>
<li><p><a
href="https://github.com/okken/markdown.py/blob/master/test_markdown_unittest.py">python
markdown unit tests</a></p></li>
<li><p><a
href="https://stackoverflow.com/questions/2085953/unit-testing-with-singletons">Unit
testing with singleton</a></p></li>
</ul>
</div>
<div id="pytest" class="section level2">
<h2>pytest</h2>
<p>Numpy moved from nose to pytest as explained in their <a
href="https://docs.scipy.org/doc/numpy/reference/testing.html">testing
guidelines</a>:</p>
<blockquote>
<p>“Until the 1.15 release, NumPy used the nose testing framework, it
now uses the pytest framework. The older framework is still maintained
in order to support downstream projects that use the old numpy
framework, but all tests for NumPy should use pytest.”</p>
</blockquote>
<p>Save this function in a file names test_numpy.py</p>
<pre><code>def test_numpy_closeness():
    assert [1,2] == [1,2]
    assert (np.array([1,2]) == np.array([1,2])).all()
    np.testing.assert_allclose(np.array([1,2]),np.array([1,3]))</code></pre>
<p>Save the file to test_nn.py</p>
<pre><code>import neural_nets as nn
import numpy as np

def test_rectified_linear_unit():
    x = np.array([[1,0],
                  [-1,-3]])
    expected = np.array([[1,0],
                         [0,0]])
    provided = nn.rectified_linear_unit(x)
    assert np.allclose(expected, provided), &quot;test failed&quot;</code></pre>
<p>Execute the test suite from bash with py.test as follows:</p>
<pre><code>cd ~/rp/course_machine_learning/projects/project_2_3_mnist/part2-nn
py.test</code></pre>
<div id="test-pandas-data-frame" class="section level3">
<h3>Test pandas data frame</h3>
<p>Methods to test data frame and series equality</p>
<pre><code>from pandas.testing import assert_frame_equal
from pandas.testing import assert_series_equal
import seaborn 
iris = seaborn.load_dataset(&quot;iris&quot;)
assert_frame_equal(iris, iris)
iris[&quot;species2&quot;] = iris[&quot;species&quot;]
assert_series_equal(iris[&quot;species&quot;], iris[&quot;species2&quot;])
# Ignore names
assert_series_equal(iris[&quot;species&quot;], iris[&quot;species2&quot;], check_names=False)</code></pre>
<p>Sometimes you want tolerance</p>
<pre><code>df = pandas.DataFrame({&quot;a&quot;:[1.0,2,3],
                       &quot;b&quot;:[1.0001,2,3]})
assert_series_equal(df[&quot;a&quot;], df[&quot;b&quot;], check_names=False)
assert_series_equal(df[&quot;a&quot;], df[&quot;b&quot;], rtol=1e-2, check_names=False)</code></pre>
</div>
<div id="aa-run" class="section level3">
<h3>AA run</h3>
<ul>
<li><p>Run and enter debug mode <a
href="https://stackoverflow.com/a/48739098/2641825"
class="uri">https://stackoverflow.com/a/48739098/2641825</a> suggests
starting an ipython shell within the package directory and then running
<code>!pytest --pdb</code> to enter inside the function that is causing
a test to fail. Objects in that function can then be inspected at the <a
href="https://docs.python.org/3/library/pdb.html">python debugger</a>
prompt.</p>
<p>!pytest –pdb</p></li>
<li><p>Run unittest with pytest <a
href="https://docs.pytest.org/en/7.1.x/how-to/unittest.html">How to use
unittest-based tests with pytest</a></p>
<p>pytest file_test.py</p></li>
</ul>
</div>
<div id="expected-exceptions" class="section level3">
<h3>Expected exceptions</h3>
<p>pytest <a
href="https://docs.pytest.org/en/6.2.x/assert.html">assert</a></p>
<blockquote>
<p>“In order to write assertions about raised exceptions, you can use
pytest.raises() as a context manager like this:”</p>
</blockquote>
<pre><code>import pytest
def test_zero_division():
    with pytest.raises(ZeroDivisionError):
        1 / 0</code></pre>
<blockquote>
<p>“and if you need to have access to the actual exception info you may
use:”</p>
</blockquote>
<pre><code>def test_recursion_depth():
    with pytest.raises(RuntimeError) as excinfo:

        def f():
            f()

        f()
    assert &quot;maximum recursion&quot; in str(excinfo.value)</code></pre>
<blockquote>
<p>“excinfo is an ExceptionInfo instance, which is a wrapper around the
actual exception raised. The main attributes of interest are .type,
.value and .traceback.”</p>
</blockquote>
</div>
<div id="fixtures" class="section level3">
<h3>Fixtures</h3>
<pre><code>import pytest
import xarray
from cobwood.gfpmx_equations import (
    consumption,
    consumption_pulp,
    consumption_indround,
)

@pytest.fixture
def secondary_product_dataset():
    &quot;&quot;&quot;Create a sample dataset for testing&quot;&quot;&quot;
    ds = xarray.Dataset({
        &quot;cons_constant&quot;: xarray.DataArray([2, 3, 4], dims=[&quot;c&quot;]),
        &quot;price&quot;: xarray.DataArray([[1, 2], [3, 4], [5, 6]], dims=[&quot;c&quot;, &quot;t&quot;]),
        &quot;gdp&quot;: xarray.DataArray([[100, 200], [300, 400], [500, 600]], dims=[&quot;c&quot;, &quot;t&quot;]),
        &quot;prod&quot;: xarray.DataArray([[100, 200], [300, 400], [500, 600]], dims=[&quot;c&quot;, &quot;t&quot;]),
        &quot;cons_price_elasticity&quot;: xarray.DataArray([0.5, 0.6, 0.7], dims=[&quot;c&quot;]),
        &quot;cons_gdp_elasticity&quot;: xarray.DataArray([0.8, 0.9, 1.0], dims=[&quot;c&quot;]),
    })
    return ds

def test_consumption(secondary_product_dataset):
    &quot;&quot;&quot;Test the consumption function&quot;&quot;&quot;
    ds = secondary_product_dataset
    t = 1
    expected_result = xarray.DataArray([138.62896863, 1274.23051055, 7404.40635264], dims=[&quot;c&quot;])
    result = consumption(ds, t)
    xarray.testing.assert_allclose(result, expected_result)</code></pre>
</div>
<div id="parametrize" class="section level3">
<h3>Parametrize</h3>
<p><a href="https://docs.pytest.org/en/6.2.x/parametrize.html"
class="uri">https://docs.pytest.org/en/6.2.x/parametrize.html</a></p>
<blockquote>
<p>“The builtin pytest.mark.parametrize decorator enables
parametrization of arguments for a test function. Here is a typical
example of a test function that implements checking that a certain input
leads to an expected output:</p>
</blockquote>
<pre><code># content of test_expectation.py
import pytest
@pytest.mark.parametrize(&quot;test_input,expected&quot;, [(&quot;3+5&quot;, 8), (&quot;2+4&quot;, 6), (&quot;6*9&quot;, 42)])
def test_eval(test_input, expected):
    assert eval(test_input) == expected</code></pre>
</div>
<div id="pylint-and-pytest" class="section level3">
<h3>Pylint and pytest</h3>
<ul>
<li><p><a href="https://github.com/pylint-dev/pylint/issues/6531"
class="uri">https://github.com/pylint-dev/pylint/issues/6531</a></p>
<ul>
<li>mentioned in <a
href="https://stackoverflow.com/questions/46089480/pytest-fixtures-redefining-name-from-outer-scope-pylint"
class="uri">https://stackoverflow.com/questions/46089480/pytest-fixtures-redefining-name-from-outer-scope-pylint</a></li>
</ul></li>
</ul>
<p>Add this at the beginning of pytest files</p>
<pre><code># pylint: disable=redefined-outer-name</code></pre>
</div>
</div>
<div id="test-use-in-projects" class="section level2">
<h2>Test use in projects</h2>
<ul>
<li><p><a href="https://pypi.org/project/tabulate/">tabulate</a></p>
<blockquote>
<p>“uses pytest testing framework and <a
href="https://tox.wiki/en/latest/">tox</a> to automate testing in
different environments.”</p>
</blockquote></li>
</ul>
</div>
</div>
<div id="web" class="section level1">
<h1>Web</h1>
<div id="back-end-api" class="section level2">
<h2>Back-end API</h2>
<ul>
<li><p><a href="https://fastapi.tiangolo.com/"
class="uri">https://fastapi.tiangolo.com/</a> seems to be a recommended
way to create python APIs.</p></li>
<li><p>Django API</p></li>
<li><p>Flask API</p></li>
</ul>
</div>
<div id="frameworks" class="section level2">
<h2>Frameworks</h2>
<p><a
href="asynchrosnus://www.codementor.io/garethdwyer/flask-vs-django-why-flask-might-be-better-4xs7mdf8v">Flask
vs. Django</a></p>
<p>Note: <a
href="http://pgjones.gitlab.io/quart/flask_evolution.html#flask-evolution">Flask
Evolution into Quart</a> to support <a
href="http://pgjones.gitlab.io/quart/asyncio.html#asyncio">asyncio</a>
This last link contains a nice, simple example of how asyncio works with
a simulated delay to fetch a web page.</p>
</div>
</div>
<div id="workflows-and-pipelines" class="section level1">
<h1>Workflows and pipelines</h1>
<ul>
<li><p>Star history comparison of ploomber and snakemake <a
href="https://star-history.com/#snakemake/snakemake&amp;ploomber/ploomber&amp;Date"
class="uri">https://star-history.com/#snakemake/snakemake&amp;ploomber/ploomber&amp;Date</a></p></li>
<li><p>Ploomber <a href="https://github.com/ploomber/ploomber"
class="uri">https://github.com/ploomber/ploomber</a></p>
<ul>
<li>Comparison of open-source workflow management tools <a
href="https://ploomber.io/blog/survey/"
class="uri">https://ploomber.io/blog/survey/</a></li>
</ul></li>
<li><p>Snake make <a href="https://github.com/snakemake/snakemake"
class="uri">https://github.com/snakemake/snakemake</a></p></li>
</ul>
</div>
<div id="xarray" class="section level1">
<h1>Xarray</h1>
<p>Create a data array and plot it, example from the <a
href="https://docs.xarray.dev/en/stable/getting-started-guide/quick-overview.html#attributes">xarray
quick overview</a>:</p>
<pre><code>import numpy as np
import xarray as xr
import matplotlib.pyplot as plt
da2 = xr.DataArray(np.random.randn(2, 3), dims=(&quot;x&quot;, &quot;y&quot;), coords={&quot;x&quot;: [10, 20]})
da2.attrs[&quot;long_name&quot;] = &quot;random velocity&quot;
da2.attrs[&quot;units&quot;] = &quot;metres/sec&quot;
da2.attrs[&quot;description&quot;] = &quot;A random variable created as an example.&quot;
da2.attrs[&quot;random_attribute&quot;] = 123
da2.attrs
da2.plot()
plt.show()</code></pre>
<p>Create another data array with one dimension only and multiply it
with the two dimensional array</p>
<pre><code>da1 = xr.DataArray([1,2], coords={&quot;x&quot;:[10,20]})
da2 * da1</code></pre>
<div id="textual-definition-of-data-array-and-dataset"
class="section level2">
<h2>Textual definition of data array and dataset</h2>
<p><a
href="https://docs.xarray.dev/en/stable/user-guide/data-structures.html#dataarray">DataArray</a></p>
<pre><code>&gt; &quot;xarray.DataArray is xarray’s implementation of a labeled, multi-dimensional
&gt; array. It has several key properties:
&gt; 
&gt; - values: a numpy.ndarray holding the array’s values
&gt; 
&gt; - dims: dimension names for each axis (e.g., (&#39;x&#39;, &#39;y&#39;, &#39;z&#39;))
&gt; 
&gt; - coords: a dict-like container of arrays (coordinates) that label each point
&gt;   (e.g., 1-dimensional arrays of numbers, datetime objects or strings)
&gt; 
&gt; - attrs: dict to hold arbitrary metadata (attributes)
&gt; 
&gt; Xarray uses dims and coords to enable its core metadata aware operations.
&gt; Dimensions provide names that xarray uses instead of the axis argument found in
&gt; many numpy functions. Coordinates enable fast label based indexing and
&gt; alignment, building on the functionality of the index found on a pandas
&gt; DataFrame or Series.&quot;</code></pre>
<p><a
href="https://docs.xarray.dev/en/stable/user-guide/data-structures.html#dataset">Dataset</a></p>
<pre><code>&gt; &quot;xarray.Dataset is xarray’s multi-dimensional equivalent of a DataFrame. It is a
&gt; dict-like container of labeled arrays (DataArray objects) with aligned
&gt; dimensions. It is designed as an in-memory representation of the data model
&gt; from the netCDF file format.
&gt; 
&gt; In addition to the dict-like interface of the dataset itself, which can be used
&gt; to access any variable in a dataset, datasets have four key properties:
&gt; 
&gt; dims: a dictionary mapping from dimension names to the fixed length of each
&gt; dimension (e.g., {&#39;x&#39;: 6, &#39;y&#39;: 6, &#39;time&#39;: 8})
&gt; 
&gt; data_vars: a dict-like container of DataArrays corresponding to variables
&gt; 
&gt; coords: another dict-like container of DataArrays intended to label points
&gt; used in data_vars (e.g., arrays of numbers, datetime objects or strings)
&gt; attrs: dict to hold arbitrary metadata
&gt; 
&gt; The distinction between whether a variable falls in data or coordinates
&gt; (borrowed from CF conventions) is mostly semantic, and you can probably get
&gt; away with ignoring it if you like: dictionary like access on a dataset will
&gt; supply variables found in either category. However, xarray does make use of the
&gt; distinction for indexing and computations. Coordinates indicate
&gt; constant/fixed/independent quantities, unlike the varying/measured/dependent
&gt; quantities that belong in data.&quot;</code></pre>
<p><a
href="https://docs.xarray.dev/en/stable/user-guide/reshaping.html#converting-between-datasets-and-arrays">converting
between datasets and arrays</a></p>
<pre><code>&gt; &quot;This method broadcasts all data variables in the dataset against each other,
&gt; then concatenates them along a new dimension into a new array while
&gt; preserving coordinates.&quot;</code></pre>
</div>
<div id="convert-to-from-other-formats" class="section level2">
<h2>Convert to-from other formats</h2>
<div id="to-a-list" class="section level3">
<h3>To a list</h3>
<p>Convert a 1 dimensional data array to a list</p>
<pre><code>ds.country.values.tolist()</code></pre>
</div>
</div>
<div id="copy-shallow-and-deep" class="section level2">
<h2>Copy shallow and deep</h2>
<p>The documentation of the <a
href="https://docs.xarray.dev/en/stable/generated/xarray.DataArray.copy.html">DataArray.copy</a>
and <a
href="https://docs.xarray.dev/en/stable/generated/xarray.Dataset.copy.html">Dataset.copy</a>
methods show they both have a <code>deep</code> argument. If this
argument is set to <code>False</code> (the default) it will only return
a new view on the dataset. Illustration below, a dataset is passed to a
function that removes values above a threshold. When
<code>deep=False</code> the input data is changed as well even though we
used the <code>copy()</code> method. We really have to use
<code>copy(deep=True)</code> to make sure that the input data remains un
modified.</p>
<pre><code>import xarray
import numpy as np
ds = xarray.Dataset(
    {&quot;a&quot;: ((&quot;x&quot;, &quot;y&quot;), np.random.randn(2, 3))},
    coords={&quot;x&quot;: [10, 20], &quot;y&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]},
)
ds
def remove_x_larger_than(ds_in, threshold, deep):
    &quot;&quot;&quot;Remove values of x larger than the threshold&quot;&quot;&quot;
    ds_out = ds_in.copy(deep=deep)
    ds_out.loc[dict(x=ds_out.coords[&quot;x&quot;]&gt;threshold)] = np.nan
    return ds_out
remove_x_larger_than(ds, threshold=10, deep=True)
print(ds)
remove_x_larger_than(ds, threshold=10, deep=False)
print(ds)</code></pre>
</div>
<div id="create-a-dataset" class="section level2">
<h2>Create a dataset</h2>
<p>Round trip from pandas to xarray and back from the <a
href="https://docs.xarray.dev/en/stable/user-guide/pandas.html">xarray
user guide page on pandas</a>.</p>
<pre><code>import xarray
import numpy as np
ds = xarray.Dataset(
    {&quot;foo&quot;: ((&quot;x&quot;, &quot;y&quot;), np.random.randn(2, 3))},
    coords={
        &quot;x&quot;: [10, 20],
        &quot;y&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;],
        &quot;along_x&quot;: (&quot;x&quot;, np.random.randn(2)),
        &quot;scalar&quot;: 123,
    },
)
ds</code></pre>
<div id="dimensions" class="section level3">
<h3>Dimensions</h3>
<p>x and y are dimensions.</p>
</div>
<div id="attributes" class="section level3">
<h3>Attributes</h3>
<p>We can add attributes to qualify metadata.</p>
<pre><code>ds.attrs[&quot;product&quot;] = &quot;sponge&quot;</code></pre>
</div>
<div id="convert-xarray-to-pandas-and-back" class="section level3">
<h3>Convert xarray to pandas and back</h3>
<p>Convert the xarray dataset to a pandas data frame</p>
<pre><code>df = ds.to_dataframe()
df</code></pre>
<p>Convert the data frame back to a dataset</p>
<pre><code>xarray.Dataset.from_dataframe(df)</code></pre>
<blockquote>
<p>“Notice that that dimensions of variables in the Dataset have now
expanded after the round-trip conversion to a DataFrame. This is because
every object in a DataFrame must have the same indices, so we need to
broadcast the data of each array to the full size of the new MultiIndex.
Likewise, all the coordinates (other than indexes) ended up as
variables, because pandas does not distinguish non-index
coordinates.”</p>
</blockquote>
<p>You can also use</p>
<pre><code>xarray.DataArray(df)</code></pre>
</div>
<div id="create-an-empty-dataset-similar-to-existing-one"
class="section level3">
<h3>Create an empty dataset similar to existing one</h3>
<p>Fill an array with zero values, similar to an existing data array. Or
fill it with NA values.</p>
<pre><code>xarray.zeros_like(da)
xarray.full_like(da, fill_value=xarray.nan)</code></pre>
</div>
</div>
<div id="data-variables" class="section level2">
<h2>Data variables</h2>
<p>The equivalent to <code>df.columns</code> in pandas would be
<code>list(sawn.data_vars)</code> for an xarray dataset.
<code>ds.data_vars</code> displays the data variables with the beginning
of their content. If you loop on it it will just display a string</p>
<pre><code>for x in ds.data_vars:
    print(x, type(x))</code></pre>
<p>A list of variables</p>
<pre><code>list(sawn.data_vars)</code></pre>
</div>
<div id="groupby-operations-1" class="section level2">
<h2>Groupby operations</h2>
<p>Group the given variable by region, using a dataArray called “region”
which is stored inside the dataset</p>
<pre><code>region_data = gfpmx_data.country_groups.set_index(&#39;country&#39;)[&#39;region&#39;]
region_dataarray = xarray.DataArray.from_series(region_data)
aggregated_data = ds[var].loc[COUNTRIES, t].groupby(ds[&quot;region&quot;]).sum()
ds[var].loc[&quot;WORLD&quot;, t] = ds[var].loc[COUNTRIES, t].sum()
ds[var].loc[regions,t] = ds[var].loc[COUNTRIES,t].groupby(ds[&quot;region&quot;].loc[COUNTRIES]).sum()</code></pre>
</div>
<div id="indexing" class="section level2">
<h2>Indexing</h2>
<div id="loc-1" class="section level3">
<h3>.loc</h3>
<p>Example use with the GFPMx dataset</p>
<pre><code>ds[&quot;exp&quot;].loc[&quot;Czechia&quot;, ds.coords[&quot;year&quot;]&gt;2015]</code></pre>
</div>
<div id="assigning-values-with-indexing" class="section level3">
<h3>Assigning values with indexing</h3>
<p><a
href="https://docs.xarray.dev/en/stable/user-guide/indexing.html#assigning-values-with-indexing"
class="uri">https://docs.xarray.dev/en/stable/user-guide/indexing.html#assigning-values-with-indexing</a></p>
<blockquote>
<p>To select and assign values to a portion of a DataArray() you can use
indexing with <code>.loc</code> or <code>.where</code>.</p>
</blockquote>
<pre><code>import xarray
import matplotlib.pyplot as plt
ds = xarray.tutorial.open_dataset(&quot;air_temperature&quot;)
ds[&quot;empty&quot;] = xarray.full_like(ds.air.mean(&quot;time&quot;), fill_value=0)
ds[&quot;empty&quot;].loc[dict(lon=260, lat=30)] = 100
lc = ds.coords[&quot;lon&quot;]
la = ds.coords[&quot;lat&quot;]
ds[&quot;empty&quot;].loc[ 
dict(lon=lc[(lc &gt; 220) &amp; (lc &lt; 260)], lat=la[(la &gt; 20) &amp; (la &lt; 60)]) 
] = 100
# Plot
ds.empty.plot()
plt.show()
# Write to a csv file
ds.empty.to_dataframe().to_csv(&quot;/tmp/empty.csv&quot;)</code></pre>
<blockquote>
<p>“Warning Do not try to assign values when using any of the indexing
methods <code>.isel</code> or <code>.sel</code>:”</p>
</blockquote>
<pre><code>da = xarray.DataArray([0, 1, 2, 3], dims=[&quot;x&quot;])
# This will return an error 
da.isel(x=[0, 1, 2]) = -1
# SyntaxError: cannot assign to function call
# Do not do this
da.isel(x=[0, 1, 2])[1] = -1
# Use a dictionnary instead
da[dict(x=[1])] =  -1
# Also works with broadcasting
da[dict(x=[0, 1, 2])] =  -1</code></pre>
</div>
<div id="querying-index-variables" class="section level3">
<h3>Querying index variables</h3>
<p>Keep only data that is below the base year into the dataset.</p>
<pre><code>base_year = 2018
ds.sel(year = ds.year &lt;= base_year)
ds.query(year = &quot;year &lt;= 2018&quot;)
ds.query(year = &quot;year &lt;= @base_year&quot;)
# Returns an error
# SyntaxError: The &#39;@&#39; prefix is not allowed in top-level eval calls.
# please refer to your variables by name without the &#39;@&#39; prefix.</code></pre>
</div>
<div id="reindex" class="section level3">
<h3>Reindex</h3>
<p>Reindex an array to get the same coordinates as another one, with
empty values where values are missing.</p>
</div>
</div>
<div id="missing-data" class="section level2">
<h2>Missing data</h2>
<p>There is no isna() method in xarray. Check for missing data with the
isnull() method</p>
</div>
<div id="panel-data" class="section level2">
<h2>Panel data</h2>
<p><a
href="https://docs.xarray.dev/en/stable/user-guide/pandas.html#transitioning-from-pandas-panel-to-xarray">transitioning
from pandas panel to xarray</a></p>
<pre><code>&gt; &quot;As discussed elsewhere in the docs, there are two primary data structures
&gt; in xarray: DataArray and Dataset. You can imagine a DataArray as a
&gt; n-dimensional pandas Series (i.e. a single typed array), and a Dataset as the
&gt; DataFrame equivalent (i.e. a dict of aligned DataArray objects).
&gt; So you can represent a Panel, in two ways:
&gt; 
&gt;    As a 3-dimensional DataArray,
&gt; 
&gt;    Or as a Dataset containing a number of 2-dimensional DataArray objects.


&gt; &quot;Variables in Dataset objects can use a subset of its dimensions. For
&gt; example, you can have one dataset with Person x Score x Time, and another
&gt; with Person x Score.&quot;</code></pre>
</div>
<div id="plots" class="section level2">
<h2>Plots</h2>
<ul>
<li><p><a
href="https://docs.xarray.dev/en/stable/user-guide/plotting.html#introduction">Xarray
plotting introduction</a></p></li>
<li><p><a
href="https://docs.xarray.dev/en/stable/user-guide/plotting.html#scatter">Scatter
plots</a></p>
<blockquote>
<p>“For more advanced scatter plots, we recommend converting the
relevant data variables to a pandas DataFrame and using the extensive
plotting capabilities of seaborn.”</p>
</blockquote></li>
<li><p><a
href="https://docs.xarray.dev/en/stable/user-guide/plotting.html#faceting">Facetting</a></p>
<blockquote>
<p>“The easiest way to create faceted plots is to pass in row or col
arguments to the xarray plotting methods/functions. This returns a
xarray.plot.FacetGrid object.”</p>
</blockquote>
<p>spda.loc[dict(country=[‘Ukraine’, ‘Uzbekistan’])].plot(col=“country”)
# Plot by continents
gfpmxb2020.indround[“prod”].loc[~gfpmxb2020.indround.c].plot(col=“country”)</p></li>
</ul>
<div id="pandas-plots-from-xarray-datasets" class="section level3">
<h3>Pandas plots from xarray datasets</h3>
<p>Example using the GFPMx data structure to plot industrial roundwood
consumption, production and trade in Czechia:</p>
<pre><code>variables = [&quot;imp&quot;, &quot;cons&quot;, &quot;exp&quot;, &quot;prod&quot;]
# Select inside the dataset
gfpmx[&quot;indround&quot;].loc[{&quot;country&quot;:&quot;Czechia&quot;}][variables].to_dataframe()[variables].plot()
# Convert to data frame first then plot
gfpmx[&quot;indround&quot;].to_dataframe().loc[&quot;Czechia&quot;][variables].plot()</code></pre>
</div>
</div>
<div id="xarray-io" class="section level2">
<h2>Xarray IO</h2>
<ul>
<li><p>See the general section on IO and file formats. The subsection on
netcdf files refers to xarray.</p></li>
<li><p>See also the conversion section for conversion to other in memory
formats such as lists or pandas data frames.</p></li>
</ul>
</div>
</div>
<div id="zz-media-and-organizations" class="section level1">
<h1>ZZ Media and organizations</h1>
<div id="blogs" class="section level2">
<h2>Blogs</h2>
<ul>
<li><p>Julio Biason <a
href="https://blog.juliobiason.me/thoughts/things-i-learnt-the-hard-way/">Things
I Learnt The Hard Way (in 30 Years of Software Development)</a></p></li>
<li><p>Daniel Lemire <a
href="https://lemire.me/blog/2016/06/21/i-do-not-use-a-debugger/">I do
not use a debugger</a></p>
<blockquote>
<p>“Debuggers don’t remove bugs. They only show them in slow
motion.”</p>
</blockquote>
<p><a href="https://lwn.net/2000/0914/a/lt-debugger.php3">Linus Toarvald
doesn’t use a debugger</a></p></li>
<li><p>Wes McKinney</p>
<ul>
<li><p>2017 <a
href="https://wesmckinney.com/blog/apache-arrow-pandas-internals/">Apache
Arrow and the 10 things I hate about pandas</a></p>
<blockquote>
<p>“pandas rule of thumb: have 5 to 10 times as much RAM as the size of
your dataset”</p>
</blockquote></li>
<li><p>2018 <a
href="https://wesmckinney.com/blog/announcing-ursalabs/">Announcing
Ursalabs</a></p>
<blockquote>
<p>“It has long been a frustration of mine that it isn’t easier to share
code and systems between R and Python. This is part of why working on
Arrow has been so important for me; it provides a path to sharing of
systems code outside of Python by enabling free interoperability at the
data level.”</p>
</blockquote>
<blockquote>
<p>“Critically, RStudio has avoided the “<strong>startup trap</strong>”
and managed to build a sustainable business while still investing the
vast majority of its engineering resources in <strong>open source
development</strong>. Nearly 9 years have passed since J.J. started
building the RStudio IDE, but in many ways he and Hadley and others feel
like they are just getting started.”</p>
</blockquote></li>
</ul></li>
<li><p>Dotan Nahum <a
href="https://jondot.medium.com/functional-programming-with-python-for-people-without-time-1eebdbd9526c">Functional
Programming with Python for People Without Time</a></p>
<blockquote>
<p>“Cracks in the Ice - We ended the previous part with stating that
with a good measure of abstraction, functional programming doesn’t offer
a considerable advantage over the “traditional” way of design, object
oriented. It’s a lie. […] In our pipeline example above with our
Executors — how do you feed in the output of one executor as the input
for the next one? well, you have to build that infrastructure. With
functional programming, those abstractions are not abstractions that you
have to custom build. They’re part of the language, mindset, and
ecosystem. Generically speaking — it’s all about impedence mismatch and
leaky abstractions and when it comes to data and functions; there’s no
mismatch because it’s built up from the core. The thesis is — that to
build a functional programming approach over an object-oriented
playground — is going to crash and burn at one point or another: be it
bad modeling of abstractions, performance problems, bad developer
ergonomics, and the worst — wrong mindset. Being able to model problems
and solutions in a functional way, transcends above traditional
abstraction; the object-oriented approach, in comparison, is crude,
inefficient and prone to maintenance problems.”</p>
</blockquote></li>
<li><p>Christopher Rackauckas <a
href="https://www.stochasticlifestyle.com/why-numba-and-cython-are-not-substitutes-for-julia/">Why
numba and cython are no substitute for Julia</a> discusses the
advantages of the Julia language over Python for large code
bases.</p></li>
<li><p>Ethan Rosenthal <a
href="https://www.ethanrosenthal.com/2022/02/01/everything-gets-a-package/">Everything
Gets a Package: My Python Data Science Setup</a></p></li>
<li><p><a
href="https://bashtage.github.io/linearmodels/panel/examples/data-formats.html">Data
Formats for Panel Data Analysis</a></p></li>
</ul>
<blockquote>
<p>There are two primary methods to express data:</p>
<ul>
<li><p>MultiIndex DataFrames where the outer index is the entity and the
inner is the time index. This requires using pandas.</p></li>
<li><p>3D structures were dimension 0 (outer) is variable, dimension 1
is time index and dimension 2 is the entity index. It is also possible
to use a 2D data structure with dimensions (t, n) which is treated as a
3D data structure having dimensions (1, t, n). These 3D data structures
can be pandas, NumPy or xarray.</p></li>
</ul>
</blockquote>
<ul>
<li><a href="https://python.quantecon.org/pandas_panel.html">Pandas for
panel data</a></li>
</ul>
<p>Explains multi index with stacking and unstacking.</p>
<ul>
<li><a
href="https://www.zverovich.net/2016/06/16/rst-vs-markdown.html">Sphinx
reStructuredText vs markdown for project documentation</a></li>
</ul>
</div>
<div id="foundations" class="section level2">
<h2>Foundations</h2>
<ul>
<li><p><a href="https://www.coin-or.org/projects/">COIN-OR project</a>
“open source for the operations research community”</p>
<blockquote>
<p>“Without open source implementations of existing algorithms, testing
new ideas built on existing ones typically requires the time-consuming
and error-prone process of re-implementing (and re-debugging and
re-testing) the original algorithm. If the original algorithm were
publicly available in a community repository, imagine the productivity
gains from software reuse! Science evolves when previous results can be
easily replicated”</p>
</blockquote></li>
<li><p><a href="https://www.python.org/psf-landing/">Python software
foundation</a></p>
<blockquote>
<p>“We support and maintain python.org, The Python Package Index, Python
Documentation, and many other services the Python Community relies
on.”</p>
</blockquote></li>
</ul>
</div>
<div id="interviews" class="section level2">
<h2>Interviews</h2>
<p><a
href="https://mappingthejourney.com/single-post/2017/06/21/episode-2-interview-with-alex-martelli-python-guru/">Interview
with Alex Martelli</a></p>
<blockquote>
<p>“Larry Page in his dormitory at Stanford had written or tried to
write a web spider to get a copy of some subset of the web on his
computers so he could try his famous Page algorithm. He was trying to
use the brand-new language Java in 1.0 beta version, and it kept
crashing. So he asked for help from his roommate and his roommate took a
look at said ‘oh you’re using that Java disaster’. Of course, it crashed
and did it in 100 lines of Python. It runs perfectly, and that’s how
Google became possible through 100 lines of Python. But I had no idea
until about five years ago that it had played so crucial role so early
on.”</p>
</blockquote>
<blockquote>
<p>” Similarly, if I hadn’t heard it from the mouth of Guido himself, I
would never have known that Python was at the heart of the web. The very
first Web server and web browser were written by the inventor of the
World Wide Web, HTTP, and HTML in Python. He wasn’t really a programmer;
he was a physicist and Python was far easier to use than anything
else.”</p>
</blockquote>
</div>
<div id="podcasts" class="section level2">
<h2>Podcasts</h2>
<p><a href="https://talkpython.fm/">talk python to me</a></p>
<ul>
<li><p><a
href="https://talkpython.fm/episodes/show/193/data-science-year-in-review-2018-edition">Data
science year in review</a></p></li>
<li><p>Interesting how Samuel Colvin talks about serialization <a
href="https://talkpython.fm/episodes/show/313/automate%20your%20data%20exchange%20with%20pydantic">automate
your data exchange with pydantic</a></p></li>
</ul>
</div>
<div id="teaching" class="section level2">
<h2>Teaching</h2>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
